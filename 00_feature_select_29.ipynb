{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_comp import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Makes sure we see all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute age categorisation: 0 minutes and 0 seconds\n",
      "Elapsed time to compute correct systematic error: 0 minutes and 9 seconds\n",
      "Elapsed time to compute load column names: 0 minutes and 0 seconds\n",
      "Elapsed time to compute categorisation of outcome column: 0 minutes and 3 seconds\n",
      "Elapsed time to compute change values in catagorical columns: 1 minutes and 34 seconds\n",
      "Elapsed time to compute OneHotEncoding: 0 minutes and 1 seconds\n",
      "Elapsed time to compute Full process: 1 minutes and 47 seconds\n",
      "(37681, 430)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q4- (3 to 6 years old) In each of the following age groups, how many children live totally or partially with you?</th>\n",
       "      <th>Q4- (7 to 12 years old) In each of the following age groups, how many children live totally or partially with you?</th>\n",
       "      <th>Q4- (13 to 17 years old) In each of the following age groups, how many children live totally or partially with you?</th>\n",
       "      <th>Q4- (18 years and over) In each of the following age groups, how many children live totally or partially with you?</th>\n",
       "      <th>outcome</th>\n",
       "      <th>(Q1- Your sex?_A man,)</th>\n",
       "      <th>(Q1- Your sex?_A woman,)</th>\n",
       "      <th>(Q1- Your sex?_nan,)</th>\n",
       "      <th>(Q2- How old are you?_18 - 30,)</th>\n",
       "      <th>(Q2- How old are you?_30 - 39,)</th>\n",
       "      <th>(Q2- How old are you?_40 - 44,)</th>\n",
       "      <th>(Q2- How old are you?_45 - 49,)</th>\n",
       "      <th>(Q2- How old are you?_50 - 55,)</th>\n",
       "      <th>(Q2- How old are you?_56 - 70,)</th>\n",
       "      <th>(Q2- How old are you?_nan,)</th>\n",
       "      <th>(STATUS_AM Technicians,)</th>\n",
       "      <th>(STATUS_Employees,)</th>\n",
       "      <th>(STATUS_Frames,)</th>\n",
       "      <th>(STATUS_Workers,)</th>\n",
       "      <th>(STATUS_nan,)</th>\n",
       "      <th>(In which sector of activity do you work?_Construction,)</th>\n",
       "      <th>(In which sector of activity do you work?_Design office and engineering,)</th>\n",
       "      <th>(In which sector of activity do you work?_Human health and social action,)</th>\n",
       "      <th>(In which sector of activity do you work?_Industry,)</th>\n",
       "      <th>(In which sector of activity do you work?_Other businesses,)</th>\n",
       "      <th>(In which sector of activity do you work?_Retail business,)</th>\n",
       "      <th>(In which sector of activity do you work?_Services,)</th>\n",
       "      <th>(In which sector of activity do you work?_Transport, energy, telecommunications,)</th>\n",
       "      <th>(In which sector of activity do you work?_Wholesale trade (all businesses in 206),)</th>\n",
       "      <th>(In which sector of activity do you work?_nan,)</th>\n",
       "      <th>(What is the size of your business (in total, all locations combined)? 2009 fake_10 to 49 employees,)</th>\n",
       "      <th>(What is the size of your business (in total, all locations combined)? 2009 fake_250 to 999 employees,)</th>\n",
       "      <th>(What is the size of your business (in total, all locations combined)? 2009 fake_50 to 249 employees,)</th>\n",
       "      <th>(What is the size of your business (in total, all locations combined)? 2009 fake_Less than 10 employees,)</th>\n",
       "      <th>(What is the size of your business (in total, all locations combined)? 2009 fake_nan,)</th>\n",
       "      <th>(Q5- Apart from your children, do you have a dependent or sick family member(s) whom you take care of regularly?_No,)</th>\n",
       "      <th>(Q5- Apart from your children, do you have a dependent or sick family member(s) whom you take care of regularly?_Yes, who lives elsewhere,)</th>\n",
       "      <th>(Q5- Apart from your children, do you have a dependent or sick family member(s) whom you take care of regularly?_Yes, who lives with me,)</th>\n",
       "      <th>(Q5- Apart from your children, do you have a dependent or sick family member(s) whom you take care of regularly?_nan,)</th>\n",
       "      <th>(Would you say that over the last 12 months, your company's activity has:_Accelerated,)</th>\n",
       "      <th>(Would you say that over the last 12 months, your company's activity has:_Do not know,)</th>\n",
       "      <th>(Would you say that over the last 12 months, your company's activity has:_Slow down,)</th>\n",
       "      <th>(Would you say that over the last 12 months, your company's activity has:_Stabilized,)</th>\n",
       "      <th>(Would you say that over the last 12 months, your company's activity has:_nan,)</th>\n",
       "      <th>(Q9- Are you working?_Full time,)</th>\n",
       "      <th>(Q9- Are you working?_Part time,)</th>\n",
       "      <th>(Q9- Are you working?_nan,)</th>\n",
       "      <th>(Q10- Do you have shift work (work organized in successive teams, which take turns at the same workstations) with alternating hours?_No,)</th>\n",
       "      <th>(Q10- Do you have shift work (work organized in successive teams, which take turns at the same workstations) with alternating hours?_Yes,)</th>\n",
       "      <th>(Q10- Do you have shift work (work organized in successive teams, which take turns at the same workstations) with alternating hours?_nan,)</th>\n",
       "      <th>(Q12- Do you work most often?_At customers,)</th>\n",
       "      <th>(Q12- Do you work most often?_At home teleworking,)</th>\n",
       "      <th>(Q12- Do you work most often?_In a commercial premises or agency,)</th>\n",
       "      <th>(Q12- Do you work most often?_In a shared office (3 to 5 people),)</th>\n",
       "      <th>(Q12- Do you work most often?_In a shared work space - co-working,)</th>\n",
       "      <th>(Q12- Do you work most often?_In a vehicle,)</th>\n",
       "      <th>(Q12- Do you work most often?_In a workshop, a technical room,)</th>\n",
       "      <th>(Q12- Do you work most often?_In an office alone or in pairs,)</th>\n",
       "      <th>(Q12- Do you work most often?_In an open space, a tray,)</th>\n",
       "      <th>(Q12- Do you work most often?_Outside-outside,)</th>\n",
       "      <th>(Q12- Do you work most often?_nan,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To remain standing for a long time or in an awkward posture_Most of the time,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To remain standing for a long time or in an awkward posture_Never,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To remain standing for a long time or in an awkward posture_Occasionally,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To remain standing for a long time or in an awkward posture_Rarely,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To remain standing for a long time or in an awkward posture_nan,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To carry or move heavy loads_Most of the time,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To carry or move heavy loads_Never,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To carry or move heavy loads_Occasionally,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To carry or move heavy loads_Rarely,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To carry or move heavy loads_nan,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To perform repetitive gestures_Most of the time,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To perform repetitive gestures_Never,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To perform repetitive gestures_Occasionally,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To perform repetitive gestures_Rarely,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To perform repetitive gestures_nan,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To work on screen_Most of the time,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To work on screen_Never,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To work on screen_Occasionally,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To work on screen_Rarely,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To work on screen_nan,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-Working in the cold / in the heat_Most of the time,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-Working in the cold / in the heat_Never,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-Working in the cold / in the heat_Occasionally,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-Working in the cold / in the heat_Rarely,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-Working in the cold / in the heat_nan,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To work in noise_Most of the time,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To work in noise_Never,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To work in noise_Occasionally,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To work in noise_Rarely,)</th>\n",
       "      <th>(Q13- Is the performance of your work taxing on you?-To work in noise_nan,)</th>\n",
       "      <th>(Q14- During your work, are you in a situation? (Of-breathe toxic products or dust_No,)</th>\n",
       "      <th>(Q14- During your work, are you in a situation? (Of-breathe toxic products or dust_Yes,)</th>\n",
       "      <th>(Q14- During your work, are you in a situation? (Of-breathe toxic products or dust_nan,)</th>\n",
       "      <th>(Q14- During your work, are you in a situation? (Of-handle toxic or dangerous products_No,)</th>\n",
       "      <th>(Q14- During your work, are you in a situation? (Of-handle toxic or dangerous products_Yes,)</th>\n",
       "      <th>(Q14- During your work, are you in a situation? (Of-handle toxic or dangerous products_nan,)</th>\n",
       "      <th>(Q14- During your work, are you in a situation? (Of-risk a serious fall_No,)</th>\n",
       "      <th>(Q14- During your work, are you in a situation? (Of-risk a serious fall_Yes,)</th>\n",
       "      <th>(Q14- During your work, are you in a situation? (Of-risk a serious fall_nan,)</th>\n",
       "      <th>(Q14- During your work, are you in a situation? (Of-working on machinery that could expose you to injury_No,)</th>\n",
       "      <th>(Q14- During your work, are you in a situation? (Of-working on machinery that could expose you to injury_Yes,)</th>\n",
       "      <th>(Q14- During your work, are you in a situation? (Of-working on machinery that could expose you to injury_nan,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My work allows me to learn new things_Completetly,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My work allows me to learn new things_Not at all,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My work allows me to learn new things_Rather,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My work allows me to learn new things_Rather not,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My work allows me to learn new things_nan,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My job requires working very quickly or very intensely_Completetly,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My job requires working very quickly or very intensely_Not at all,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My job requires working very quickly or very intensely_Rather,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My job requires working very quickly or very intensely_Rather not,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My job requires working very quickly or very intensely_nan,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My job requires long periods of concentration_Completetly,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My job requires long periods of concentration_Not at all,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My job requires long periods of concentration_Rather,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My job requires long periods of concentration_Rather not,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My job requires long periods of concentration_nan,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My job is physically tiring_Completetly,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My job is physically tiring_Not at all,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My job is physically tiring_Rather,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My job is physically tiring_Rather not,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My job is physically tiring_nan,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My work is nervously tiring_Completetly,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My work is nervously tiring_Not at all,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My work is nervously tiring_Rather,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My work is nervously tiring_Rather not,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My work is nervously tiring_nan,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I am satisfied with my work_Completetly,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I am satisfied with my work_Not at all,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I am satisfied with my work_Rather,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I am satisfied with my work_Rather not,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I am satisfied with my work_nan,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-In my job I have the opportunity to make decisions_Completetly,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-In my job I have the opportunity to make decisions_Not at all,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-In my job I have the opportunity to make decisions_Rather,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-In my job I have the opportunity to make decisions_Rather not,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-In my job I have the opportunity to make decisions_nan,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-At times, I have difficulty managing priorities_Completetly,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-At times, I have difficulty managing priorities_Not at all,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-At times, I have difficulty managing priorities_Rather,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-At times, I have difficulty managing priorities_Rather not,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-At times, I have difficulty managing priorities_nan,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I feel recognized by my hierarchy_Completetly,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I feel recognized by my hierarchy_Not at all,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I feel recognized by my hierarchy_Rather,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I feel recognized by my hierarchy_Rather not,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I feel recognized by my hierarchy_nan,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I have the opportunity to develop my professional skills_Completetly,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I have the opportunity to develop my professional skills_Not at all,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I have the opportunity to develop my professional skills_Rather,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I have the opportunity to develop my professional skills_Rather not,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I have the opportunity to develop my professional skills_nan,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-There is good understanding where I work_Completetly,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-There is good understanding where I work_Not at all,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-There is good understanding where I work_Rather,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-There is good understanding where I work_Rather not,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-There is good understanding where I work_nan,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I have a well-suited workstation_Completetly,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I have a well-suited workstation_Not at all,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I have a well-suited workstation_Rather,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I have a well-suited workstation_Rather not,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I have a well-suited workstation_nan,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I systematically seek to improve the way I work_Completetly,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I systematically seek to improve the way I work_Not at all,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I systematically seek to improve the way I work_Rather,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I systematically seek to improve the way I work_Rather not,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-I systematically seek to improve the way I work_nan,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My company takes care of the well-being of its employees_Completetly,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My company takes care of the well-being of its employees_Not at all,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My company takes care of the well-being of its employees_Rather,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My company takes care of the well-being of its employees_Rather not,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-My company takes care of the well-being of its employees_nan,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-Security is a priority for my business_Completetly,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-Security is a priority for my business_Not at all,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-Security is a priority for my business_Rather,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-Security is a priority for my business_Rather not,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-Security is a priority for my business_nan,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-In the event of a problem, I can count on my supervisor_Completetly,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-In the event of a problem, I can count on my supervisor_Not at all,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-In the event of a problem, I can count on my supervisor_Rather,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-In the event of a problem, I can count on my supervisor_Rather not,)</th>\n",
       "      <th>(Q15- Indicate whether each of the following sentences suits you-In the event of a problem, I can count on my supervisor_nan,)</th>\n",
       "      <th>(Would you say that over the last 12 months, your pace of work has:_Accelerated,)</th>\n",
       "      <th>(Would you say that over the last 12 months, your pace of work has:_Do not know,)</th>\n",
       "      <th>(Would you say that over the last 12 months, your pace of work has:_Slow motion,)</th>\n",
       "      <th>(Would you say that over the last 12 months, your pace of work has:_Stabilized,)</th>\n",
       "      <th>(Would you say that over the last 12 months, your pace of work has:_nan,)</th>\n",
       "      <th>(Q16- And for each of these sentences?-I would recommend my company to a friend_Completetly,)</th>\n",
       "      <th>(Q16- And for each of these sentences?-I would recommend my company to a friend_Not at all,)</th>\n",
       "      <th>(Q16- And for each of these sentences?-I would recommend my company to a friend_Rather,)</th>\n",
       "      <th>(Q16- And for each of these sentences?-I would recommend my company to a friend_Rather not,)</th>\n",
       "      <th>(Q16- And for each of these sentences?-I would recommend my company to a friend_nan,)</th>\n",
       "      <th>(Q16- And for each of these sentences?-I am proud to work in my company_Completetly,)</th>\n",
       "      <th>(Q16- And for each of these sentences?-I am proud to work in my company_Not at all,)</th>\n",
       "      <th>(Q16- And for each of these sentences?-I am proud to work in my company_Rather,)</th>\n",
       "      <th>(Q16- And for each of these sentences?-I am proud to work in my company_Rather not,)</th>\n",
       "      <th>(Q16- And for each of these sentences?-I am proud to work in my company_nan,)</th>\n",
       "      <th>(Q17- At work, does it happen to you: (D-have decreased alertness, lack of attention_Never,)</th>\n",
       "      <th>(Q17- At work, does it happen to you: (D-have decreased alertness, lack of attention_Often,)</th>\n",
       "      <th>(Q17- At work, does it happen to you: (D-have decreased alertness, lack of attention_Sometimes,)</th>\n",
       "      <th>(Q17- At work, does it happen to you: (D-have decreased alertness, lack of attention_Very Often,)</th>\n",
       "      <th>(Q17- At work, does it happen to you: (D-have decreased alertness, lack of attention_nan,)</th>\n",
       "      <th>(Q17- At work, does it happen to you: (D-e receiving hurtful or aggressive remarks within the company_Never,)</th>\n",
       "      <th>(Q17- At work, does it happen to you: (D-e receiving hurtful or aggressive remarks within the company_Often,)</th>\n",
       "      <th>(Q17- At work, does it happen to you: (D-e receiving hurtful or aggressive remarks within the company_Sometimes,)</th>\n",
       "      <th>(Q17- At work, does it happen to you: (D-e receiving hurtful or aggressive remarks within the company_Very Often,)</th>\n",
       "      <th>(Q17- At work, does it happen to you: (D-e receiving hurtful or aggressive remarks within the company_nan,)</th>\n",
       "      <th>(Q17- At work, does it happen to you: (D-being insulted or attacked by the public or customers_Never,)</th>\n",
       "      <th>(Q17- At work, does it happen to you: (D-being insulted or attacked by the public or customers_Often,)</th>\n",
       "      <th>(Q17- At work, does it happen to you: (D-being insulted or attacked by the public or customers_Sometimes,)</th>\n",
       "      <th>(Q17- At work, does it happen to you: (D-being insulted or attacked by the public or customers_Very Often,)</th>\n",
       "      <th>(Q17- At work, does it happen to you: (D-being insulted or attacked by the public or customers_nan,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-'work organization_Satisfying,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-'work organization_Unsatisfactory,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-'work organization_nan,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-clarity of your role in the companyÔøΩs activity_Satisfying,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-clarity of your role in the companyÔøΩs activity_Unsatisfactory,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-clarity of your role in the companyÔøΩs activity_nan,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-access to professional training_Satisfying,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-access to professional training_Unsatisfactory,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-access to professional training_nan,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a relationship with your direct superior_Satisfying,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a relationship with your direct superior_Unsatisfactory,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a relationship with your direct superior_nan,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-atmosphere in your team_Satisfying,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-atmosphere in your team_Unsatisfactory,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-atmosphere in your team_nan,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-tools or your workstation_Satisfying,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-tools or your workstation_Unsatisfactory,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-tools or your workstation_nan,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-the prospects for development_Satisfying,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-the prospects for development_Unsatisfactory,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-the prospects for development_nan,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-relationships between services_Satisfying,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-relationships between services_Unsatisfactory,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-relationships between services_nan,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-e management_Satisfying,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-e management_Unsatisfactory,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-e management_nan,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a communication and understanding of business strategy_Satisfying,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a communication and understanding of business strategy_Unsatisfactory,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a communication and understanding of business strategy_nan,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-recognition at work_Satisfying,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-recognition at work_Unsatisfactory,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-recognition at work_nan,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-has mastery of your position (responsibility, means, skills_Satisfying,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-has mastery of your position (responsibility, means, skills_Unsatisfactory,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-has mastery of your position (responsibility, means, skills_nan,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-moments of conviviality_Satisfying,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-moments of conviviality_Unsatisfactory,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-moments of conviviality_nan,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a balance between private life and professional life_Satisfying,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a balance between private life and professional life_Unsatisfactory,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a balance between private life and professional life_nan,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-The services provided by the company (crÔøΩche, concierge, gym, etc.)_Satisfying,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-The services provided by the company (crÔøΩche, concierge, gym, etc.)_Unsatisfactory,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-The services provided by the company (crÔøΩche, concierge, gym, etc.)_nan,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a social protection (mutual health, insurance) offered by your company_Satisfying,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a social protection (mutual health, insurance) offered by your company_Unsatisfactory,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a social protection (mutual health, insurance) offered by your company_nan,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-working hours_Satisfying,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-working hours_Unsatisfactory,)</th>\n",
       "      <th>(Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-working hours_nan,)</th>\n",
       "      <th>(Q22- Over the last 12 months have you personally experienced one or more of the following events:-Loss of job (yourself or your spouse)_I adhere to the directions chosen by my company,)</th>\n",
       "      <th>(Q22- Over the last 12 months have you personally experienced one or more of the following events:-Loss of job (yourself or your spouse)_I am involved upstream, we integrate my point of view,)</th>\n",
       "      <th>(Q22- Over the last 12 months have you personally experienced one or more of the following events:-Loss of job (yourself or your spouse)_I benefit from support in implementation (training, communication, etc.),)</th>\n",
       "      <th>(Q22- Over the last 12 months have you personally experienced one or more of the following events:-Loss of job (yourself or your spouse)_I make sure to adapt,)</th>\n",
       "      <th>(Q22- Over the last 12 months have you personally experienced one or more of the following events:-Loss of job (yourself or your spouse)_I understand they are necessary,)</th>\n",
       "      <th>(Q22- Over the last 12 months have you personally experienced one or more of the following events:-Loss of job (yourself or your spouse)_They come back too often,)</th>\n",
       "      <th>(Q22- Over the last 12 months have you personally experienced one or more of the following events:-Loss of job (yourself or your spouse)_nan,)</th>\n",
       "      <th>(Q22- Over the last 12 months have you personally experienced one or more of the following events:-An imposed change of position or profession_I adhere to the directions chosen by my company,)</th>\n",
       "      <th>(Q22- Over the last 12 months have you personally experienced one or more of the following events:-An imposed change of position or profession_I am involved upstream, we integrate my point of view,)</th>\n",
       "      <th>(Q22- Over the last 12 months have you personally experienced one or more of the following events:-An imposed change of position or profession_I benefit from support in implementation (training, communication, etc.),)</th>\n",
       "      <th>(Q22- Over the last 12 months have you personally experienced one or more of the following events:-An imposed change of position or profession_They come back too often,)</th>\n",
       "      <th>(Q22- Over the last 12 months have you personally experienced one or more of the following events:-An imposed change of position or profession_nan,)</th>\n",
       "      <th>(Q22- Over the last 12 months have you personally experienced one or more of the following events:-A restructuring or reorganization of your service or business_I am involved upstream, we integrate my point of view,)</th>\n",
       "      <th>(Q22- Over the last 12 months have you personally experienced one or more of the following events:-A restructuring or reorganization of your service or business_I benefit from support in implementation (training, communication, etc.),)</th>\n",
       "      <th>(Q22- Over the last 12 months have you personally experienced one or more of the following events:-A restructuring or reorganization of your service or business_They come back too often,)</th>\n",
       "      <th>(Q22- Over the last 12 months have you personally experienced one or more of the following events:-A restructuring or reorganization of your service or business_nan,)</th>\n",
       "      <th>(Q22- Over the last 12 months have you personally experienced one or more of the following events:-A social plan, layoffs in your company_I benefit from support in implementation (training, communication, etc.),)</th>\n",
       "      <th>(Q22- Over the last 12 months have you personally experienced one or more of the following events:-A social plan, layoffs in your company_They come back too often,)</th>\n",
       "      <th>(Q22- Over the last 12 months have you personally experienced one or more of the following events:-A social plan, layoffs in your company_nan,)</th>\n",
       "      <th>(Q22- Over the last 12 months have you personally experienced one or more of the following events:-One or more periods of technical unemployment_nan,)</th>\n",
       "      <th>(Q23- Do you have difficulty reconciling your work with your other personal or family commitments?-Yes quite_No not at all,)</th>\n",
       "      <th>(Q23- Do you have difficulty reconciling your work with your other personal or family commitments?-Yes quite_No, rather not,)</th>\n",
       "      <th>(Q23- Do you have difficulty reconciling your work with your other personal or family commitments?-Yes quite_Yes quite,)</th>\n",
       "      <th>(Q23- Do you have difficulty reconciling your work with your other personal or family commitments?-Yes quite_Yes, rather,)</th>\n",
       "      <th>(Q23- Do you have difficulty reconciling your work with your other personal or family commitments?-Yes quite_nan,)</th>\n",
       "      <th>(Q25-Your workplace-home transportation time (round trip) is:_Between 1 hour and 2 hours per day,)</th>\n",
       "      <th>(Q25-Your workplace-home transportation time (round trip) is:_From 2 hours to 3 hours per day,)</th>\n",
       "      <th>(Q25-Your workplace-home transportation time (round trip) is:_Less than 1 hour per day,)</th>\n",
       "      <th>(Q25-Your workplace-home transportation time (round trip) is:_More than 3 hours per day,)</th>\n",
       "      <th>(Q25-Your workplace-home transportation time (round trip) is:_nan,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-Your professional situation_Confident,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-Your professional situation_Not confident at all,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-Your professional situation_Not very confident,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-Your professional situation_Very confident,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-Your professional situation_nan,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-The financial situation of your household_Confident,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-The financial situation of your household_Not confident at all,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-The financial situation of your household_Not very confident,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-The financial situation of your household_Very confident,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-The financial situation of your household_nan,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-Your housing conditions_Confident,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-Your housing conditions_Not confident at all,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-Your housing conditions_Not very confident,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-Your housing conditions_Very confident,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-Your housing conditions_nan,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-Your emotional life_Confident,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-Your emotional life_Not confident at all,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-Your emotional life_Not very confident,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-Your emotional life_Very confident,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-Your emotional life_nan,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-Your health_Confident,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-Your health_Not confident at all,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-Your health_Not very confident,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-Your health_Very confident,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-Your health_nan,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-The future of your child(ren)_Confident,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-The future of your child(ren)_Not confident at all,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-The future of your child(ren)_Not very confident,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-The future of your child(ren)_Very confident,)</th>\n",
       "      <th>(Q31- When you think about the next 3 years, for each of the following points are you:-The future of your child(ren)_nan,)</th>\n",
       "      <th>(Q34- In your personal life, would you say:-I feel well surrounded_Completetly,)</th>\n",
       "      <th>(Q34- In your personal life, would you say:-I feel well surrounded_Not at all,)</th>\n",
       "      <th>(Q34- In your personal life, would you say:-I feel well surrounded_Rather,)</th>\n",
       "      <th>(Q34- In your personal life, would you say:-I feel well surrounded_Rather not,)</th>\n",
       "      <th>(Q34- In your personal life, would you say:-I feel well surrounded_nan,)</th>\n",
       "      <th>(Q34- In your personal life, would you say:-One of my loved ones (child/parent/spouse) is causing me a lot of worry_Completetly,)</th>\n",
       "      <th>(Q34- In your personal life, would you say:-One of my loved ones (child/parent/spouse) is causing me a lot of worry_Not at all,)</th>\n",
       "      <th>(Q34- In your personal life, would you say:-One of my loved ones (child/parent/spouse) is causing me a lot of worry_Rather,)</th>\n",
       "      <th>(Q34- In your personal life, would you say:-One of my loved ones (child/parent/spouse) is causing me a lot of worry_Rather not,)</th>\n",
       "      <th>(Q34- In your personal life, would you say:-One of my loved ones (child/parent/spouse) is causing me a lot of worry_nan,)</th>\n",
       "      <th>(Q34- In your personal life, would you say:-I have personal concerns (emotional life, money, health_Completetly,)</th>\n",
       "      <th>(Q34- In your personal life, would you say:-I have personal concerns (emotional life, money, health_Not at all,)</th>\n",
       "      <th>(Q34- In your personal life, would you say:-I have personal concerns (emotional life, money, health_Rather,)</th>\n",
       "      <th>(Q34- In your personal life, would you say:-I have personal concerns (emotional life, money, health_Rather not,)</th>\n",
       "      <th>(Q34- In your personal life, would you say:-I have personal concerns (emotional life, money, health_nan,)</th>\n",
       "      <th>(Q34- In your personal life, would you say:-If there is a problem I can talk to a loved one_Completetly,)</th>\n",
       "      <th>(Q34- In your personal life, would you say:-If there is a problem I can talk to a loved one_Not at all,)</th>\n",
       "      <th>(Q34- In your personal life, would you say:-If there is a problem I can talk to a loved one_Rather,)</th>\n",
       "      <th>(Q34- In your personal life, would you say:-If there is a problem I can talk to a loved one_Rather not,)</th>\n",
       "      <th>(Q34- In your personal life, would you say:-If there is a problem I can talk to a loved one_nan,)</th>\n",
       "      <th>(Q37- How do you rate your state of health in general?_AVERAGE,)</th>\n",
       "      <th>(Q37- How do you rate your state of health in general?_Bad,)</th>\n",
       "      <th>(Q37- How do you rate your state of health in general?_Good,)</th>\n",
       "      <th>(Q37- How do you rate your state of health in general?_Very bad,)</th>\n",
       "      <th>(Q37- How do you rate your state of health in general?_Very good,)</th>\n",
       "      <th>(Q37- How do you rate your state of health in general?_nan,)</th>\n",
       "      <th>(Q38- Did you:-A chronic illness (a long-term illness or one that recurs frequently_No,)</th>\n",
       "      <th>(Q38- Did you:-A chronic illness (a long-term illness or one that recurs frequently_Yes,)</th>\n",
       "      <th>(Q38- Did you:-A chronic illness (a long-term illness or one that recurs frequently_nan,)</th>\n",
       "      <th>(Q38- Did you:-Disabilities_No,)</th>\n",
       "      <th>(Q38- Did you:-Disabilities_Yes,)</th>\n",
       "      <th>(Q38- Did you:-Disabilities_nan,)</th>\n",
       "      <th>(Q42-During the last 12 months have you had a work accident?_No,)</th>\n",
       "      <th>(Q42-During the last 12 months have you had a work accident?_Yes,)</th>\n",
       "      <th>(Q42-During the last 12 months have you had a work accident?_nan,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the head_Never,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the head_Often,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the head_Permanently,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the head_Sometimes,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the head_nan,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the neck, shoulder, arm_Never,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the neck, shoulder, arm_Often,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the neck, shoulder, arm_Permanently,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the neck, shoulder, arm_Sometimes,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the neck, shoulder, arm_nan,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the back_Never,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the back_Often,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the back_Permanently,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the back_Sometimes,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the back_nan,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the leg, foot, knee_Never,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the leg, foot, knee_Often,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the leg, foot, knee_Permanently,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the leg, foot, knee_Sometimes,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the leg, foot, knee_nan,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in other parts of the body_Never,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in other parts of the body_Often,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in other parts of the body_Permanently,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in other parts of the body_Sometimes,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in other parts of the body_nan,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-to the eyes_Never,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-to the eyes_Often,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-to the eyes_Permanently,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-to the eyes_Sometimes,)</th>\n",
       "      <th>(Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-to the eyes_nan,)</th>\n",
       "      <th>(Q57- How do you most frequently eat your midday meal?_By bringing your meal from home,)</th>\n",
       "      <th>(Q57- How do you most frequently eat your midday meal?_In the canteen or company restaurant,)</th>\n",
       "      <th>(Q57- How do you most frequently eat your midday meal?_When going to a restaurant, brasserie, snack bar,)</th>\n",
       "      <th>(Q57- How do you most frequently eat your midday meal?_When returning home,)</th>\n",
       "      <th>(Q57- How do you most frequently eat your midday meal?_While eating a sandwich,)</th>\n",
       "      <th>(Q57- How do you most frequently eat your midday meal?_nan,)</th>\n",
       "      <th>(Q58- For each of these drinks, indicate whether you consume them:-Every day_Alcoholic beverages,)</th>\n",
       "      <th>(Q58- For each of these drinks, indicate whether you consume them:-Every day_Energy drinks (like Red Bull or Monster),)</th>\n",
       "      <th>(Q58- For each of these drinks, indicate whether you consume them:-Every day_Sodas,)</th>\n",
       "      <th>(Q58- For each of these drinks, indicate whether you consume them:-Every day_None,)</th>\n",
       "      <th>(Q58- For each of these drinks, indicate whether you consume them:-Every day_nan,)</th>\n",
       "      <th>(Q58- For each of these drinks, indicate whether you consume them:-At least once a week_Alcoholic beverages,)</th>\n",
       "      <th>(Q58- For each of these drinks, indicate whether you consume them:-At least once a week_Energy drinks (like Red Bull or Monster),)</th>\n",
       "      <th>(Q58- For each of these drinks, indicate whether you consume them:-At least once a week_Sodas,)</th>\n",
       "      <th>(Q58- For each of these drinks, indicate whether you consume them:-At least once a week_None,)</th>\n",
       "      <th>(Q58- For each of these drinks, indicate whether you consume them:-At least once a week_nan,)</th>\n",
       "      <th>(Q60- Are you a smoker?_No,)</th>\n",
       "      <th>(Q60- Are you a smoker?_Yes,)</th>\n",
       "      <th>(Q60- Are you a smoker?_nan,)</th>\n",
       "      <th>(Q61- Do you smoke cannabis, hashish, marijuana?_Every day or almost,)</th>\n",
       "      <th>(Q61- Do you smoke cannabis, hashish, marijuana?_Less than once a month,)</th>\n",
       "      <th>(Q61- Do you smoke cannabis, hashish, marijuana?_Never,)</th>\n",
       "      <th>(Q61- Do you smoke cannabis, hashish, marijuana?_Once a month,)</th>\n",
       "      <th>(Q61- Do you smoke cannabis, hashish, marijuana?_Once a week,)</th>\n",
       "      <th>(Q61- Do you smoke cannabis, hashish, marijuana?_nan,)</th>\n",
       "      <th>(Q62- Do you take sleeping pills, anxiolytics or anti-depressants:_At least once a week,)</th>\n",
       "      <th>(Q62- Do you take sleeping pills, anxiolytics or anti-depressants:_Less than once a month,)</th>\n",
       "      <th>(Q62- Do you take sleeping pills, anxiolytics or anti-depressants:_Never,)</th>\n",
       "      <th>(Q62- Do you take sleeping pills, anxiolytics or anti-depressants:_Once a month,)</th>\n",
       "      <th>(Q62- Do you take sleeping pills, anxiolytics or anti-depressants:_Several times a month,)</th>\n",
       "      <th>(Q62- Do you take sleeping pills, anxiolytics or anti-depressants:_nan,)</th>\n",
       "      <th>(Q63- Over the past 12 months have you experienced the following difficulties?-Sleep disorders (difficulty falling asleep, waking up at night, waking up early without being able to go back to sleep, etc.)_Never,)</th>\n",
       "      <th>(Q63- Over the past 12 months have you experienced the following difficulties?-Sleep disorders (difficulty falling asleep, waking up at night, waking up early without being able to go back to sleep, etc.)_often,)</th>\n",
       "      <th>(Q63- Over the past 12 months have you experienced the following difficulties?-Sleep disorders (difficulty falling asleep, waking up at night, waking up early without being able to go back to sleep, etc.)_permanently,)</th>\n",
       "      <th>(Q63- Over the past 12 months have you experienced the following difficulties?-Sleep disorders (difficulty falling asleep, waking up at night, waking up early without being able to go back to sleep, etc.)_sometimes,)</th>\n",
       "      <th>(Q63- Over the past 12 months have you experienced the following difficulties?-Sleep disorders (difficulty falling asleep, waking up at night, waking up early without being able to go back to sleep, etc.)_nan,)</th>\n",
       "      <th>(Q63- Over the past 12 months have you experienced the following difficulties?-A lack of tone_Never,)</th>\n",
       "      <th>(Q63- Over the past 12 months have you experienced the following difficulties?-A lack of tone_often,)</th>\n",
       "      <th>(Q63- Over the past 12 months have you experienced the following difficulties?-A lack of tone_permanently,)</th>\n",
       "      <th>(Q63- Over the past 12 months have you experienced the following difficulties?-A lack of tone_sometimes,)</th>\n",
       "      <th>(Q63- Over the past 12 months have you experienced the following difficulties?-A lack of tone_nan,)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q4- (3 to 6 years old) In each of the following age groups, how many children live totally or partially with you?  \\\n",
       "0                                                  1                                                                   \n",
       "1                                                  0                                                                   \n",
       "2                                                  0                                                                   \n",
       "3                                                  0                                                                   \n",
       "4                                                  0                                                                   \n",
       "\n",
       "   Q4- (7 to 12 years old) In each of the following age groups, how many children live totally or partially with you?  \\\n",
       "0                                                2.0                                                                    \n",
       "1                                                0.0                                                                    \n",
       "2                                                0.0                                                                    \n",
       "3                                                0.0                                                                    \n",
       "4                                                0.0                                                                    \n",
       "\n",
       "   Q4- (13 to 17 years old) In each of the following age groups, how many children live totally or partially with you?  \\\n",
       "0                                                  0                                                                     \n",
       "1                                                  0                                                                     \n",
       "2                                                  1                                                                     \n",
       "3                                                  0                                                                     \n",
       "4                                                  0                                                                     \n",
       "\n",
       "   Q4- (18 years and over) In each of the following age groups, how many children live totally or partially with you?  \\\n",
       "0                                                  0                                                                    \n",
       "1                                                  0                                                                    \n",
       "2                                                  1                                                                    \n",
       "3                                                  0                                                                    \n",
       "4                                                  0                                                                    \n",
       "\n",
       "   outcome  (Q1- Your sex?_A man,)  (Q1- Your sex?_A woman,)  \\\n",
       "0        2                       1                         0   \n",
       "1        1                       1                         0   \n",
       "2        3                       0                         1   \n",
       "3        0                       1                         0   \n",
       "4        2                       1                         0   \n",
       "\n",
       "   (Q1- Your sex?_nan,)  (Q2- How old are you?_18 - 30,)  \\\n",
       "0                     0                                0   \n",
       "1                     0                                1   \n",
       "2                     0                                0   \n",
       "3                     0                                0   \n",
       "4                     0                                0   \n",
       "\n",
       "   (Q2- How old are you?_30 - 39,)  (Q2- How old are you?_40 - 44,)  \\\n",
       "0                                1                                0   \n",
       "1                                0                                0   \n",
       "2                                0                                0   \n",
       "3                                1                                0   \n",
       "4                                0                                0   \n",
       "\n",
       "   (Q2- How old are you?_45 - 49,)  (Q2- How old are you?_50 - 55,)  \\\n",
       "0                                0                                0   \n",
       "1                                0                                0   \n",
       "2                                1                                0   \n",
       "3                                0                                0   \n",
       "4                                0                                0   \n",
       "\n",
       "   (Q2- How old are you?_56 - 70,)  (Q2- How old are you?_nan,)  \\\n",
       "0                                0                            0   \n",
       "1                                0                            0   \n",
       "2                                0                            0   \n",
       "3                                0                            0   \n",
       "4                                1                            0   \n",
       "\n",
       "   (STATUS_AM Technicians,)  (STATUS_Employees,)  (STATUS_Frames,)  \\\n",
       "0                         1                    0                 0   \n",
       "1                         0                    0                 1   \n",
       "2                         0                    1                 0   \n",
       "3                         0                    0                 1   \n",
       "4                         0                    0                 0   \n",
       "\n",
       "   (STATUS_Workers,)  (STATUS_nan,)  \\\n",
       "0                  0              0   \n",
       "1                  0              0   \n",
       "2                  0              0   \n",
       "3                  0              0   \n",
       "4                  1              0   \n",
       "\n",
       "   (In which sector of activity do you work?_Construction,)  \\\n",
       "0                                                  0          \n",
       "1                                                  0          \n",
       "2                                                  0          \n",
       "3                                                  0          \n",
       "4                                                  0          \n",
       "\n",
       "   (In which sector of activity do you work?_Design office and engineering,)  \\\n",
       "0                                                  0                           \n",
       "1                                                  0                           \n",
       "2                                                  0                           \n",
       "3                                                  0                           \n",
       "4                                                  0                           \n",
       "\n",
       "   (In which sector of activity do you work?_Human health and social action,)  \\\n",
       "0                                                  0                            \n",
       "1                                                  0                            \n",
       "2                                                  0                            \n",
       "3                                                  0                            \n",
       "4                                                  0                            \n",
       "\n",
       "   (In which sector of activity do you work?_Industry,)  \\\n",
       "0                                                  0      \n",
       "1                                                  0      \n",
       "2                                                  0      \n",
       "3                                                  0      \n",
       "4                                                  1      \n",
       "\n",
       "   (In which sector of activity do you work?_Other businesses,)  \\\n",
       "0                                                  0              \n",
       "1                                                  0              \n",
       "2                                                  0              \n",
       "3                                                  0              \n",
       "4                                                  0              \n",
       "\n",
       "   (In which sector of activity do you work?_Retail business,)  \\\n",
       "0                                                  0             \n",
       "1                                                  0             \n",
       "2                                                  0             \n",
       "3                                                  0             \n",
       "4                                                  0             \n",
       "\n",
       "   (In which sector of activity do you work?_Services,)  \\\n",
       "0                                                  0      \n",
       "1                                                  0      \n",
       "2                                                  0      \n",
       "3                                                  0      \n",
       "4                                                  0      \n",
       "\n",
       "   (In which sector of activity do you work?_Transport, energy, telecommunications,)  \\\n",
       "0                                                  0                                   \n",
       "1                                                  0                                   \n",
       "2                                                  0                                   \n",
       "3                                                  0                                   \n",
       "4                                                  0                                   \n",
       "\n",
       "   (In which sector of activity do you work?_Wholesale trade (all businesses in 206),)  \\\n",
       "0                                                  1                                     \n",
       "1                                                  1                                     \n",
       "2                                                  1                                     \n",
       "3                                                  1                                     \n",
       "4                                                  0                                     \n",
       "\n",
       "   (In which sector of activity do you work?_nan,)  \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "\n",
       "   (What is the size of your business (in total, all locations combined)? 2009 fake_10 to 49 employees,)  \\\n",
       "0                                                  0                                                       \n",
       "1                                                  0                                                       \n",
       "2                                                  0                                                       \n",
       "3                                                  0                                                       \n",
       "4                                                  1                                                       \n",
       "\n",
       "   (What is the size of your business (in total, all locations combined)? 2009 fake_250 to 999 employees,)  \\\n",
       "0                                                  1                                                         \n",
       "1                                                  0                                                         \n",
       "2                                                  0                                                         \n",
       "3                                                  0                                                         \n",
       "4                                                  0                                                         \n",
       "\n",
       "   (What is the size of your business (in total, all locations combined)? 2009 fake_50 to 249 employees,)  \\\n",
       "0                                                  0                                                        \n",
       "1                                                  1                                                        \n",
       "2                                                  0                                                        \n",
       "3                                                  1                                                        \n",
       "4                                                  0                                                        \n",
       "\n",
       "   (What is the size of your business (in total, all locations combined)? 2009 fake_Less than 10 employees,)  \\\n",
       "0                                                  0                                                           \n",
       "1                                                  0                                                           \n",
       "2                                                  1                                                           \n",
       "3                                                  0                                                           \n",
       "4                                                  0                                                           \n",
       "\n",
       "   (What is the size of your business (in total, all locations combined)? 2009 fake_nan,)  \\\n",
       "0                                                  0                                        \n",
       "1                                                  0                                        \n",
       "2                                                  0                                        \n",
       "3                                                  0                                        \n",
       "4                                                  0                                        \n",
       "\n",
       "   (Q5- Apart from your children, do you have a dependent or sick family member(s) whom you take care of regularly?_No,)  \\\n",
       "0                                                  1                                                                       \n",
       "1                                                  1                                                                       \n",
       "2                                                  1                                                                       \n",
       "3                                                  1                                                                       \n",
       "4                                                  1                                                                       \n",
       "\n",
       "   (Q5- Apart from your children, do you have a dependent or sick family member(s) whom you take care of regularly?_Yes, who lives elsewhere,)  \\\n",
       "0                                                  0                                                                                             \n",
       "1                                                  0                                                                                             \n",
       "2                                                  0                                                                                             \n",
       "3                                                  0                                                                                             \n",
       "4                                                  0                                                                                             \n",
       "\n",
       "   (Q5- Apart from your children, do you have a dependent or sick family member(s) whom you take care of regularly?_Yes, who lives with me,)  \\\n",
       "0                                                  0                                                                                           \n",
       "1                                                  0                                                                                           \n",
       "2                                                  0                                                                                           \n",
       "3                                                  0                                                                                           \n",
       "4                                                  0                                                                                           \n",
       "\n",
       "   (Q5- Apart from your children, do you have a dependent or sick family member(s) whom you take care of regularly?_nan,)  \\\n",
       "0                                                  0                                                                        \n",
       "1                                                  0                                                                        \n",
       "2                                                  0                                                                        \n",
       "3                                                  0                                                                        \n",
       "4                                                  0                                                                        \n",
       "\n",
       "   (Would you say that over the last 12 months, your company's activity has:_Accelerated,)  \\\n",
       "0                                                  0                                         \n",
       "1                                                  0                                         \n",
       "2                                                  0                                         \n",
       "3                                                  0                                         \n",
       "4                                                  0                                         \n",
       "\n",
       "   (Would you say that over the last 12 months, your company's activity has:_Do not know,)  \\\n",
       "0                                                  0                                         \n",
       "1                                                  0                                         \n",
       "2                                                  0                                         \n",
       "3                                                  0                                         \n",
       "4                                                  0                                         \n",
       "\n",
       "   (Would you say that over the last 12 months, your company's activity has:_Slow down,)  \\\n",
       "0                                                  0                                       \n",
       "1                                                  0                                       \n",
       "2                                                  0                                       \n",
       "3                                                  0                                       \n",
       "4                                                  0                                       \n",
       "\n",
       "   (Would you say that over the last 12 months, your company's activity has:_Stabilized,)  \\\n",
       "0                                                  0                                        \n",
       "1                                                  0                                        \n",
       "2                                                  0                                        \n",
       "3                                                  0                                        \n",
       "4                                                  0                                        \n",
       "\n",
       "   (Would you say that over the last 12 months, your company's activity has:_nan,)  \\\n",
       "0                                                  1                                 \n",
       "1                                                  1                                 \n",
       "2                                                  1                                 \n",
       "3                                                  1                                 \n",
       "4                                                  1                                 \n",
       "\n",
       "   (Q9- Are you working?_Full time,)  (Q9- Are you working?_Part time,)  \\\n",
       "0                                  1                                  0   \n",
       "1                                  1                                  0   \n",
       "2                                  1                                  0   \n",
       "3                                  1                                  0   \n",
       "4                                  1                                  0   \n",
       "\n",
       "   (Q9- Are you working?_nan,)  \\\n",
       "0                            0   \n",
       "1                            0   \n",
       "2                            0   \n",
       "3                            0   \n",
       "4                            0   \n",
       "\n",
       "   (Q10- Do you have shift work (work organized in successive teams, which take turns at the same workstations) with alternating hours?_No,)  \\\n",
       "0                                                  1                                                                                           \n",
       "1                                                  1                                                                                           \n",
       "2                                                  1                                                                                           \n",
       "3                                                  1                                                                                           \n",
       "4                                                  0                                                                                           \n",
       "\n",
       "   (Q10- Do you have shift work (work organized in successive teams, which take turns at the same workstations) with alternating hours?_Yes,)  \\\n",
       "0                                                  0                                                                                            \n",
       "1                                                  0                                                                                            \n",
       "2                                                  0                                                                                            \n",
       "3                                                  0                                                                                            \n",
       "4                                                  1                                                                                            \n",
       "\n",
       "   (Q10- Do you have shift work (work organized in successive teams, which take turns at the same workstations) with alternating hours?_nan,)  \\\n",
       "0                                                  0                                                                                            \n",
       "1                                                  0                                                                                            \n",
       "2                                                  0                                                                                            \n",
       "3                                                  0                                                                                            \n",
       "4                                                  0                                                                                            \n",
       "\n",
       "   (Q12- Do you work most often?_At customers,)  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "\n",
       "   (Q12- Do you work most often?_At home teleworking,)  \\\n",
       "0                                                  0     \n",
       "1                                                  0     \n",
       "2                                                  1     \n",
       "3                                                  0     \n",
       "4                                                  0     \n",
       "\n",
       "   (Q12- Do you work most often?_In a commercial premises or agency,)  \\\n",
       "0                                                  0                    \n",
       "1                                                  0                    \n",
       "2                                                  0                    \n",
       "3                                                  0                    \n",
       "4                                                  0                    \n",
       "\n",
       "   (Q12- Do you work most often?_In a shared office (3 to 5 people),)  \\\n",
       "0                                                  1                    \n",
       "1                                                  1                    \n",
       "2                                                  0                    \n",
       "3                                                  1                    \n",
       "4                                                  0                    \n",
       "\n",
       "   (Q12- Do you work most often?_In a shared work space - co-working,)  \\\n",
       "0                                                  0                     \n",
       "1                                                  0                     \n",
       "2                                                  0                     \n",
       "3                                                  0                     \n",
       "4                                                  0                     \n",
       "\n",
       "   (Q12- Do you work most often?_In a vehicle,)  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "\n",
       "   (Q12- Do you work most often?_In a workshop, a technical room,)  \\\n",
       "0                                                  0                 \n",
       "1                                                  0                 \n",
       "2                                                  0                 \n",
       "3                                                  0                 \n",
       "4                                                  1                 \n",
       "\n",
       "   (Q12- Do you work most often?_In an office alone or in pairs,)  \\\n",
       "0                                                  0                \n",
       "1                                                  0                \n",
       "2                                                  0                \n",
       "3                                                  0                \n",
       "4                                                  0                \n",
       "\n",
       "   (Q12- Do you work most often?_In an open space, a tray,)  \\\n",
       "0                                                  0          \n",
       "1                                                  0          \n",
       "2                                                  0          \n",
       "3                                                  0          \n",
       "4                                                  0          \n",
       "\n",
       "   (Q12- Do you work most often?_Outside-outside,)  \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "\n",
       "   (Q12- Do you work most often?_nan,)  \\\n",
       "0                                    0   \n",
       "1                                    0   \n",
       "2                                    0   \n",
       "3                                    0   \n",
       "4                                    0   \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To remain standing for a long time or in an awkward posture_Most of the time,)  \\\n",
       "0                                                  0                                                                                     \n",
       "1                                                  0                                                                                     \n",
       "2                                                  0                                                                                     \n",
       "3                                                  0                                                                                     \n",
       "4                                                  1                                                                                     \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To remain standing for a long time or in an awkward posture_Never,)  \\\n",
       "0                                                  1                                                                          \n",
       "1                                                  0                                                                          \n",
       "2                                                  0                                                                          \n",
       "3                                                  0                                                                          \n",
       "4                                                  0                                                                          \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To remain standing for a long time or in an awkward posture_Occasionally,)  \\\n",
       "0                                                  0                                                                                 \n",
       "1                                                  0                                                                                 \n",
       "2                                                  0                                                                                 \n",
       "3                                                  0                                                                                 \n",
       "4                                                  0                                                                                 \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To remain standing for a long time or in an awkward posture_Rarely,)  \\\n",
       "0                                                  0                                                                           \n",
       "1                                                  1                                                                           \n",
       "2                                                  1                                                                           \n",
       "3                                                  0                                                                           \n",
       "4                                                  0                                                                           \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To remain standing for a long time or in an awkward posture_nan,)  \\\n",
       "0                                                  0                                                                        \n",
       "1                                                  0                                                                        \n",
       "2                                                  0                                                                        \n",
       "3                                                  1                                                                        \n",
       "4                                                  0                                                                        \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To carry or move heavy loads_Most of the time,)  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To carry or move heavy loads_Never,)  \\\n",
       "0                                                  1                                           \n",
       "1                                                  1                                           \n",
       "2                                                  0                                           \n",
       "3                                                  0                                           \n",
       "4                                                  0                                           \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To carry or move heavy loads_Occasionally,)  \\\n",
       "0                                                  0                                                  \n",
       "1                                                  0                                                  \n",
       "2                                                  0                                                  \n",
       "3                                                  0                                                  \n",
       "4                                                  0                                                  \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To carry or move heavy loads_Rarely,)  \\\n",
       "0                                                  0                                            \n",
       "1                                                  0                                            \n",
       "2                                                  1                                            \n",
       "3                                                  0                                            \n",
       "4                                                  0                                            \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To carry or move heavy loads_nan,)  \\\n",
       "0                                                  0                                         \n",
       "1                                                  0                                         \n",
       "2                                                  0                                         \n",
       "3                                                  0                                         \n",
       "4                                                  0                                         \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To perform repetitive gestures_Most of the time,)  \\\n",
       "0                                                  0                                                        \n",
       "1                                                  0                                                        \n",
       "2                                                  0                                                        \n",
       "3                                                  1                                                        \n",
       "4                                                  1                                                        \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To perform repetitive gestures_Never,)  \\\n",
       "0                                                  0                                             \n",
       "1                                                  0                                             \n",
       "2                                                  0                                             \n",
       "3                                                  0                                             \n",
       "4                                                  0                                             \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To perform repetitive gestures_Occasionally,)  \\\n",
       "0                                                  0                                                    \n",
       "1                                                  0                                                    \n",
       "2                                                  0                                                    \n",
       "3                                                  0                                                    \n",
       "4                                                  0                                                    \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To perform repetitive gestures_Rarely,)  \\\n",
       "0                                                  1                                              \n",
       "1                                                  1                                              \n",
       "2                                                  1                                              \n",
       "3                                                  0                                              \n",
       "4                                                  0                                              \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To perform repetitive gestures_nan,)  \\\n",
       "0                                                  0                                           \n",
       "1                                                  0                                           \n",
       "2                                                  0                                           \n",
       "3                                                  0                                           \n",
       "4                                                  0                                           \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To work on screen_Most of the time,)  \\\n",
       "0                                                  1                                           \n",
       "1                                                  1                                           \n",
       "2                                                  0                                           \n",
       "3                                                  1                                           \n",
       "4                                                  1                                           \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To work on screen_Never,)  \\\n",
       "0                                                  0                                \n",
       "1                                                  0                                \n",
       "2                                                  1                                \n",
       "3                                                  0                                \n",
       "4                                                  0                                \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To work on screen_Occasionally,)  \\\n",
       "0                                                  0                                       \n",
       "1                                                  0                                       \n",
       "2                                                  0                                       \n",
       "3                                                  0                                       \n",
       "4                                                  0                                       \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To work on screen_Rarely,)  \\\n",
       "0                                                  0                                 \n",
       "1                                                  0                                 \n",
       "2                                                  0                                 \n",
       "3                                                  0                                 \n",
       "4                                                  0                                 \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To work on screen_nan,)  \\\n",
       "0                                                  0                              \n",
       "1                                                  0                              \n",
       "2                                                  0                              \n",
       "3                                                  0                              \n",
       "4                                                  0                              \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-Working in the cold / in the heat_Most of the time,)  \\\n",
       "0                                                  1                                                           \n",
       "1                                                  0                                                           \n",
       "2                                                  0                                                           \n",
       "3                                                  0                                                           \n",
       "4                                                  1                                                           \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-Working in the cold / in the heat_Never,)  \\\n",
       "0                                                  0                                                \n",
       "1                                                  1                                                \n",
       "2                                                  1                                                \n",
       "3                                                  0                                                \n",
       "4                                                  0                                                \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-Working in the cold / in the heat_Occasionally,)  \\\n",
       "0                                                  0                                                       \n",
       "1                                                  0                                                       \n",
       "2                                                  0                                                       \n",
       "3                                                  0                                                       \n",
       "4                                                  0                                                       \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-Working in the cold / in the heat_Rarely,)  \\\n",
       "0                                                  0                                                 \n",
       "1                                                  0                                                 \n",
       "2                                                  0                                                 \n",
       "3                                                  1                                                 \n",
       "4                                                  0                                                 \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-Working in the cold / in the heat_nan,)  \\\n",
       "0                                                  0                                              \n",
       "1                                                  0                                              \n",
       "2                                                  0                                              \n",
       "3                                                  0                                              \n",
       "4                                                  0                                              \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To work in noise_Most of the time,)  \\\n",
       "0                                                  0                                          \n",
       "1                                                  1                                          \n",
       "2                                                  0                                          \n",
       "3                                                  0                                          \n",
       "4                                                  1                                          \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To work in noise_Never,)  \\\n",
       "0                                                  1                               \n",
       "1                                                  0                               \n",
       "2                                                  1                               \n",
       "3                                                  0                               \n",
       "4                                                  0                               \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To work in noise_Occasionally,)  \\\n",
       "0                                                  0                                      \n",
       "1                                                  0                                      \n",
       "2                                                  0                                      \n",
       "3                                                  0                                      \n",
       "4                                                  0                                      \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To work in noise_Rarely,)  \\\n",
       "0                                                  0                                \n",
       "1                                                  0                                \n",
       "2                                                  0                                \n",
       "3                                                  1                                \n",
       "4                                                  0                                \n",
       "\n",
       "   (Q13- Is the performance of your work taxing on you?-To work in noise_nan,)  \\\n",
       "0                                                  0                             \n",
       "1                                                  0                             \n",
       "2                                                  0                             \n",
       "3                                                  0                             \n",
       "4                                                  0                             \n",
       "\n",
       "   (Q14- During your work, are you in a situation? (Of-breathe toxic products or dust_No,)  \\\n",
       "0                                                  1                                         \n",
       "1                                                  1                                         \n",
       "2                                                  1                                         \n",
       "3                                                  1                                         \n",
       "4                                                  0                                         \n",
       "\n",
       "   (Q14- During your work, are you in a situation? (Of-breathe toxic products or dust_Yes,)  \\\n",
       "0                                                  0                                          \n",
       "1                                                  0                                          \n",
       "2                                                  0                                          \n",
       "3                                                  0                                          \n",
       "4                                                  1                                          \n",
       "\n",
       "   (Q14- During your work, are you in a situation? (Of-breathe toxic products or dust_nan,)  \\\n",
       "0                                                  0                                          \n",
       "1                                                  0                                          \n",
       "2                                                  0                                          \n",
       "3                                                  0                                          \n",
       "4                                                  0                                          \n",
       "\n",
       "   (Q14- During your work, are you in a situation? (Of-handle toxic or dangerous products_No,)  \\\n",
       "0                                                  1                                             \n",
       "1                                                  1                                             \n",
       "2                                                  1                                             \n",
       "3                                                  1                                             \n",
       "4                                                  0                                             \n",
       "\n",
       "   (Q14- During your work, are you in a situation? (Of-handle toxic or dangerous products_Yes,)  \\\n",
       "0                                                  0                                              \n",
       "1                                                  0                                              \n",
       "2                                                  0                                              \n",
       "3                                                  0                                              \n",
       "4                                                  1                                              \n",
       "\n",
       "   (Q14- During your work, are you in a situation? (Of-handle toxic or dangerous products_nan,)  \\\n",
       "0                                                  0                                              \n",
       "1                                                  0                                              \n",
       "2                                                  0                                              \n",
       "3                                                  0                                              \n",
       "4                                                  0                                              \n",
       "\n",
       "   (Q14- During your work, are you in a situation? (Of-risk a serious fall_No,)  \\\n",
       "0                                                  1                              \n",
       "1                                                  1                              \n",
       "2                                                  1                              \n",
       "3                                                  1                              \n",
       "4                                                  0                              \n",
       "\n",
       "   (Q14- During your work, are you in a situation? (Of-risk a serious fall_Yes,)  \\\n",
       "0                                                  0                               \n",
       "1                                                  0                               \n",
       "2                                                  0                               \n",
       "3                                                  0                               \n",
       "4                                                  1                               \n",
       "\n",
       "   (Q14- During your work, are you in a situation? (Of-risk a serious fall_nan,)  \\\n",
       "0                                                  0                               \n",
       "1                                                  0                               \n",
       "2                                                  0                               \n",
       "3                                                  0                               \n",
       "4                                                  0                               \n",
       "\n",
       "   (Q14- During your work, are you in a situation? (Of-working on machinery that could expose you to injury_No,)  \\\n",
       "0                                                  1                                                               \n",
       "1                                                  0                                                               \n",
       "2                                                  1                                                               \n",
       "3                                                  1                                                               \n",
       "4                                                  0                                                               \n",
       "\n",
       "   (Q14- During your work, are you in a situation? (Of-working on machinery that could expose you to injury_Yes,)  \\\n",
       "0                                                  0                                                                \n",
       "1                                                  1                                                                \n",
       "2                                                  0                                                                \n",
       "3                                                  0                                                                \n",
       "4                                                  1                                                                \n",
       "\n",
       "   (Q14- During your work, are you in a situation? (Of-working on machinery that could expose you to injury_nan,)  \\\n",
       "0                                                  0                                                                \n",
       "1                                                  0                                                                \n",
       "2                                                  0                                                                \n",
       "3                                                  0                                                                \n",
       "4                                                  0                                                                \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My work allows me to learn new things_Completetly,)  \\\n",
       "0                                                  0                                                                      \n",
       "1                                                  0                                                                      \n",
       "2                                                  1                                                                      \n",
       "3                                                  0                                                                      \n",
       "4                                                  0                                                                      \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My work allows me to learn new things_Not at all,)  \\\n",
       "0                                                  0                                                                     \n",
       "1                                                  0                                                                     \n",
       "2                                                  0                                                                     \n",
       "3                                                  0                                                                     \n",
       "4                                                  0                                                                     \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My work allows me to learn new things_Rather,)  \\\n",
       "0                                                  1                                                                 \n",
       "1                                                  1                                                                 \n",
       "2                                                  0                                                                 \n",
       "3                                                  0                                                                 \n",
       "4                                                  1                                                                 \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My work allows me to learn new things_Rather not,)  \\\n",
       "0                                                  0                                                                     \n",
       "1                                                  0                                                                     \n",
       "2                                                  0                                                                     \n",
       "3                                                  1                                                                     \n",
       "4                                                  0                                                                     \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My work allows me to learn new things_nan,)  \\\n",
       "0                                                  0                                                              \n",
       "1                                                  0                                                              \n",
       "2                                                  0                                                              \n",
       "3                                                  0                                                              \n",
       "4                                                  0                                                              \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My job requires working very quickly or very intensely_Completetly,)  \\\n",
       "0                                                  0                                                                                       \n",
       "1                                                  0                                                                                       \n",
       "2                                                  0                                                                                       \n",
       "3                                                  1                                                                                       \n",
       "4                                                  0                                                                                       \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My job requires working very quickly or very intensely_Not at all,)  \\\n",
       "0                                                  0                                                                                      \n",
       "1                                                  0                                                                                      \n",
       "2                                                  0                                                                                      \n",
       "3                                                  0                                                                                      \n",
       "4                                                  0                                                                                      \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My job requires working very quickly or very intensely_Rather,)  \\\n",
       "0                                                  1                                                                                  \n",
       "1                                                  1                                                                                  \n",
       "2                                                  0                                                                                  \n",
       "3                                                  0                                                                                  \n",
       "4                                                  1                                                                                  \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My job requires working very quickly or very intensely_Rather not,)  \\\n",
       "0                                                  0                                                                                      \n",
       "1                                                  0                                                                                      \n",
       "2                                                  1                                                                                      \n",
       "3                                                  0                                                                                      \n",
       "4                                                  0                                                                                      \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My job requires working very quickly or very intensely_nan,)  \\\n",
       "0                                                  0                                                                               \n",
       "1                                                  0                                                                               \n",
       "2                                                  0                                                                               \n",
       "3                                                  0                                                                               \n",
       "4                                                  0                                                                               \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My job requires long periods of concentration_Completetly,)  \\\n",
       "0                                                  0                                                                              \n",
       "1                                                  0                                                                              \n",
       "2                                                  0                                                                              \n",
       "3                                                  1                                                                              \n",
       "4                                                  0                                                                              \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My job requires long periods of concentration_Not at all,)  \\\n",
       "0                                                  0                                                                             \n",
       "1                                                  0                                                                             \n",
       "2                                                  0                                                                             \n",
       "3                                                  0                                                                             \n",
       "4                                                  0                                                                             \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My job requires long periods of concentration_Rather,)  \\\n",
       "0                                                  1                                                                         \n",
       "1                                                  1                                                                         \n",
       "2                                                  1                                                                         \n",
       "3                                                  0                                                                         \n",
       "4                                                  1                                                                         \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My job requires long periods of concentration_Rather not,)  \\\n",
       "0                                                  0                                                                             \n",
       "1                                                  0                                                                             \n",
       "2                                                  0                                                                             \n",
       "3                                                  0                                                                             \n",
       "4                                                  0                                                                             \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My job requires long periods of concentration_nan,)  \\\n",
       "0                                                  0                                                                      \n",
       "1                                                  0                                                                      \n",
       "2                                                  0                                                                      \n",
       "3                                                  0                                                                      \n",
       "4                                                  0                                                                      \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My job is physically tiring_Completetly,)  \\\n",
       "0                                                  0                                                            \n",
       "1                                                  0                                                            \n",
       "2                                                  0                                                            \n",
       "3                                                  0                                                            \n",
       "4                                                  1                                                            \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My job is physically tiring_Not at all,)  \\\n",
       "0                                                  0                                                           \n",
       "1                                                  0                                                           \n",
       "2                                                  0                                                           \n",
       "3                                                  0                                                           \n",
       "4                                                  0                                                           \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My job is physically tiring_Rather,)  \\\n",
       "0                                                  0                                                       \n",
       "1                                                  0                                                       \n",
       "2                                                  0                                                       \n",
       "3                                                  1                                                       \n",
       "4                                                  0                                                       \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My job is physically tiring_Rather not,)  \\\n",
       "0                                                  1                                                           \n",
       "1                                                  1                                                           \n",
       "2                                                  1                                                           \n",
       "3                                                  0                                                           \n",
       "4                                                  0                                                           \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My job is physically tiring_nan,)  \\\n",
       "0                                                  0                                                    \n",
       "1                                                  0                                                    \n",
       "2                                                  0                                                    \n",
       "3                                                  0                                                    \n",
       "4                                                  0                                                    \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My work is nervously tiring_Completetly,)  \\\n",
       "0                                                  0                                                            \n",
       "1                                                  1                                                            \n",
       "2                                                  0                                                            \n",
       "3                                                  1                                                            \n",
       "4                                                  1                                                            \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My work is nervously tiring_Not at all,)  \\\n",
       "0                                                  0                                                           \n",
       "1                                                  0                                                           \n",
       "2                                                  0                                                           \n",
       "3                                                  0                                                           \n",
       "4                                                  0                                                           \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My work is nervously tiring_Rather,)  \\\n",
       "0                                                  1                                                       \n",
       "1                                                  0                                                       \n",
       "2                                                  0                                                       \n",
       "3                                                  0                                                       \n",
       "4                                                  0                                                       \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My work is nervously tiring_Rather not,)  \\\n",
       "0                                                  0                                                           \n",
       "1                                                  0                                                           \n",
       "2                                                  1                                                           \n",
       "3                                                  0                                                           \n",
       "4                                                  0                                                           \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My work is nervously tiring_nan,)  \\\n",
       "0                                                  0                                                    \n",
       "1                                                  0                                                    \n",
       "2                                                  0                                                    \n",
       "3                                                  0                                                    \n",
       "4                                                  0                                                    \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I am satisfied with my work_Completetly,)  \\\n",
       "0                                                  0                                                            \n",
       "1                                                  0                                                            \n",
       "2                                                  0                                                            \n",
       "3                                                  0                                                            \n",
       "4                                                  0                                                            \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I am satisfied with my work_Not at all,)  \\\n",
       "0                                                  0                                                           \n",
       "1                                                  0                                                           \n",
       "2                                                  0                                                           \n",
       "3                                                  0                                                           \n",
       "4                                                  0                                                           \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I am satisfied with my work_Rather,)  \\\n",
       "0                                                  1                                                       \n",
       "1                                                  1                                                       \n",
       "2                                                  1                                                       \n",
       "3                                                  1                                                       \n",
       "4                                                  1                                                       \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I am satisfied with my work_Rather not,)  \\\n",
       "0                                                  0                                                           \n",
       "1                                                  0                                                           \n",
       "2                                                  0                                                           \n",
       "3                                                  0                                                           \n",
       "4                                                  0                                                           \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I am satisfied with my work_nan,)  \\\n",
       "0                                                  0                                                    \n",
       "1                                                  0                                                    \n",
       "2                                                  0                                                    \n",
       "3                                                  0                                                    \n",
       "4                                                  0                                                    \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-In my job I have the opportunity to make decisions_Completetly,)  \\\n",
       "0                                                  0                                                                                   \n",
       "1                                                  0                                                                                   \n",
       "2                                                  1                                                                                   \n",
       "3                                                  1                                                                                   \n",
       "4                                                  0                                                                                   \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-In my job I have the opportunity to make decisions_Not at all,)  \\\n",
       "0                                                  0                                                                                  \n",
       "1                                                  0                                                                                  \n",
       "2                                                  0                                                                                  \n",
       "3                                                  0                                                                                  \n",
       "4                                                  0                                                                                  \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-In my job I have the opportunity to make decisions_Rather,)  \\\n",
       "0                                                  1                                                                              \n",
       "1                                                  1                                                                              \n",
       "2                                                  0                                                                              \n",
       "3                                                  0                                                                              \n",
       "4                                                  1                                                                              \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-In my job I have the opportunity to make decisions_Rather not,)  \\\n",
       "0                                                  0                                                                                  \n",
       "1                                                  0                                                                                  \n",
       "2                                                  0                                                                                  \n",
       "3                                                  0                                                                                  \n",
       "4                                                  0                                                                                  \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-In my job I have the opportunity to make decisions_nan,)  \\\n",
       "0                                                  0                                                                           \n",
       "1                                                  0                                                                           \n",
       "2                                                  0                                                                           \n",
       "3                                                  0                                                                           \n",
       "4                                                  0                                                                           \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-At times, I have difficulty managing priorities_Completetly,)  \\\n",
       "0                                                  0                                                                                \n",
       "1                                                  0                                                                                \n",
       "2                                                  0                                                                                \n",
       "3                                                  0                                                                                \n",
       "4                                                  0                                                                                \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-At times, I have difficulty managing priorities_Not at all,)  \\\n",
       "0                                                  0                                                                               \n",
       "1                                                  0                                                                               \n",
       "2                                                  0                                                                               \n",
       "3                                                  1                                                                               \n",
       "4                                                  1                                                                               \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-At times, I have difficulty managing priorities_Rather,)  \\\n",
       "0                                                  0                                                                           \n",
       "1                                                  0                                                                           \n",
       "2                                                  0                                                                           \n",
       "3                                                  0                                                                           \n",
       "4                                                  0                                                                           \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-At times, I have difficulty managing priorities_Rather not,)  \\\n",
       "0                                                  1                                                                               \n",
       "1                                                  1                                                                               \n",
       "2                                                  1                                                                               \n",
       "3                                                  0                                                                               \n",
       "4                                                  0                                                                               \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-At times, I have difficulty managing priorities_nan,)  \\\n",
       "0                                                  0                                                                        \n",
       "1                                                  0                                                                        \n",
       "2                                                  0                                                                        \n",
       "3                                                  0                                                                        \n",
       "4                                                  0                                                                        \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I feel recognized by my hierarchy_Completetly,)  \\\n",
       "0                                                  0                                                                  \n",
       "1                                                  0                                                                  \n",
       "2                                                  0                                                                  \n",
       "3                                                  0                                                                  \n",
       "4                                                  0                                                                  \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I feel recognized by my hierarchy_Not at all,)  \\\n",
       "0                                                  0                                                                 \n",
       "1                                                  0                                                                 \n",
       "2                                                  0                                                                 \n",
       "3                                                  1                                                                 \n",
       "4                                                  0                                                                 \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I feel recognized by my hierarchy_Rather,)  \\\n",
       "0                                                  1                                                             \n",
       "1                                                  1                                                             \n",
       "2                                                  0                                                             \n",
       "3                                                  0                                                             \n",
       "4                                                  0                                                             \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I feel recognized by my hierarchy_Rather not,)  \\\n",
       "0                                                  0                                                                 \n",
       "1                                                  0                                                                 \n",
       "2                                                  1                                                                 \n",
       "3                                                  0                                                                 \n",
       "4                                                  1                                                                 \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I feel recognized by my hierarchy_nan,)  \\\n",
       "0                                                  0                                                          \n",
       "1                                                  0                                                          \n",
       "2                                                  0                                                          \n",
       "3                                                  0                                                          \n",
       "4                                                  0                                                          \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I have the opportunity to develop my professional skills_Completetly,)  \\\n",
       "0                                                  0                                                                                         \n",
       "1                                                  0                                                                                         \n",
       "2                                                  0                                                                                         \n",
       "3                                                  0                                                                                         \n",
       "4                                                  0                                                                                         \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I have the opportunity to develop my professional skills_Not at all,)  \\\n",
       "0                                                  0                                                                                        \n",
       "1                                                  0                                                                                        \n",
       "2                                                  0                                                                                        \n",
       "3                                                  0                                                                                        \n",
       "4                                                  0                                                                                        \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I have the opportunity to develop my professional skills_Rather,)  \\\n",
       "0                                                  1                                                                                    \n",
       "1                                                  0                                                                                    \n",
       "2                                                  1                                                                                    \n",
       "3                                                  1                                                                                    \n",
       "4                                                  0                                                                                    \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I have the opportunity to develop my professional skills_Rather not,)  \\\n",
       "0                                                  0                                                                                        \n",
       "1                                                  1                                                                                        \n",
       "2                                                  0                                                                                        \n",
       "3                                                  0                                                                                        \n",
       "4                                                  1                                                                                        \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I have the opportunity to develop my professional skills_nan,)  \\\n",
       "0                                                  0                                                                                 \n",
       "1                                                  0                                                                                 \n",
       "2                                                  0                                                                                 \n",
       "3                                                  0                                                                                 \n",
       "4                                                  0                                                                                 \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-There is good understanding where I work_Completetly,)  \\\n",
       "0                                                  0                                                                         \n",
       "1                                                  1                                                                         \n",
       "2                                                  1                                                                         \n",
       "3                                                  0                                                                         \n",
       "4                                                  0                                                                         \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-There is good understanding where I work_Not at all,)  \\\n",
       "0                                                  0                                                                        \n",
       "1                                                  0                                                                        \n",
       "2                                                  0                                                                        \n",
       "3                                                  0                                                                        \n",
       "4                                                  0                                                                        \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-There is good understanding where I work_Rather,)  \\\n",
       "0                                                  1                                                                    \n",
       "1                                                  0                                                                    \n",
       "2                                                  0                                                                    \n",
       "3                                                  1                                                                    \n",
       "4                                                  1                                                                    \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-There is good understanding where I work_Rather not,)  \\\n",
       "0                                                  0                                                                        \n",
       "1                                                  0                                                                        \n",
       "2                                                  0                                                                        \n",
       "3                                                  0                                                                        \n",
       "4                                                  0                                                                        \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-There is good understanding where I work_nan,)  \\\n",
       "0                                                  0                                                                 \n",
       "1                                                  0                                                                 \n",
       "2                                                  0                                                                 \n",
       "3                                                  0                                                                 \n",
       "4                                                  0                                                                 \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I have a well-suited workstation_Completetly,)  \\\n",
       "0                                                  0                                                                 \n",
       "1                                                  0                                                                 \n",
       "2                                                  0                                                                 \n",
       "3                                                  0                                                                 \n",
       "4                                                  0                                                                 \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I have a well-suited workstation_Not at all,)  \\\n",
       "0                                                  0                                                                \n",
       "1                                                  0                                                                \n",
       "2                                                  0                                                                \n",
       "3                                                  0                                                                \n",
       "4                                                  0                                                                \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I have a well-suited workstation_Rather,)  \\\n",
       "0                                                  1                                                            \n",
       "1                                                  1                                                            \n",
       "2                                                  1                                                            \n",
       "3                                                  1                                                            \n",
       "4                                                  1                                                            \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I have a well-suited workstation_Rather not,)  \\\n",
       "0                                                  0                                                                \n",
       "1                                                  0                                                                \n",
       "2                                                  0                                                                \n",
       "3                                                  0                                                                \n",
       "4                                                  0                                                                \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I have a well-suited workstation_nan,)  \\\n",
       "0                                                  0                                                         \n",
       "1                                                  0                                                         \n",
       "2                                                  0                                                         \n",
       "3                                                  0                                                         \n",
       "4                                                  0                                                         \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I systematically seek to improve the way I work_Completetly,)  \\\n",
       "0                                                  0                                                                                \n",
       "1                                                  0                                                                                \n",
       "2                                                  1                                                                                \n",
       "3                                                  0                                                                                \n",
       "4                                                  0                                                                                \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I systematically seek to improve the way I work_Not at all,)  \\\n",
       "0                                                  0                                                                               \n",
       "1                                                  0                                                                               \n",
       "2                                                  0                                                                               \n",
       "3                                                  0                                                                               \n",
       "4                                                  0                                                                               \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I systematically seek to improve the way I work_Rather,)  \\\n",
       "0                                                  1                                                                           \n",
       "1                                                  1                                                                           \n",
       "2                                                  0                                                                           \n",
       "3                                                  1                                                                           \n",
       "4                                                  1                                                                           \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I systematically seek to improve the way I work_Rather not,)  \\\n",
       "0                                                  0                                                                               \n",
       "1                                                  0                                                                               \n",
       "2                                                  0                                                                               \n",
       "3                                                  0                                                                               \n",
       "4                                                  0                                                                               \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-I systematically seek to improve the way I work_nan,)  \\\n",
       "0                                                  0                                                                        \n",
       "1                                                  0                                                                        \n",
       "2                                                  0                                                                        \n",
       "3                                                  0                                                                        \n",
       "4                                                  0                                                                        \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My company takes care of the well-being of its employees_Completetly,)  \\\n",
       "0                                                  0                                                                                         \n",
       "1                                                  1                                                                                         \n",
       "2                                                  0                                                                                         \n",
       "3                                                  0                                                                                         \n",
       "4                                                  0                                                                                         \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My company takes care of the well-being of its employees_Not at all,)  \\\n",
       "0                                                  0                                                                                        \n",
       "1                                                  0                                                                                        \n",
       "2                                                  0                                                                                        \n",
       "3                                                  1                                                                                        \n",
       "4                                                  0                                                                                        \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My company takes care of the well-being of its employees_Rather,)  \\\n",
       "0                                                  1                                                                                    \n",
       "1                                                  0                                                                                    \n",
       "2                                                  1                                                                                    \n",
       "3                                                  0                                                                                    \n",
       "4                                                  1                                                                                    \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My company takes care of the well-being of its employees_Rather not,)  \\\n",
       "0                                                  0                                                                                        \n",
       "1                                                  0                                                                                        \n",
       "2                                                  0                                                                                        \n",
       "3                                                  0                                                                                        \n",
       "4                                                  0                                                                                        \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-My company takes care of the well-being of its employees_nan,)  \\\n",
       "0                                                  0                                                                                 \n",
       "1                                                  0                                                                                 \n",
       "2                                                  0                                                                                 \n",
       "3                                                  0                                                                                 \n",
       "4                                                  0                                                                                 \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-Security is a priority for my business_Completetly,)  \\\n",
       "0                                                  0                                                                       \n",
       "1                                                  1                                                                       \n",
       "2                                                  1                                                                       \n",
       "3                                                  0                                                                       \n",
       "4                                                  0                                                                       \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-Security is a priority for my business_Not at all,)  \\\n",
       "0                                                  0                                                                      \n",
       "1                                                  0                                                                      \n",
       "2                                                  0                                                                      \n",
       "3                                                  0                                                                      \n",
       "4                                                  0                                                                      \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-Security is a priority for my business_Rather,)  \\\n",
       "0                                                  1                                                                  \n",
       "1                                                  0                                                                  \n",
       "2                                                  0                                                                  \n",
       "3                                                  1                                                                  \n",
       "4                                                  1                                                                  \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-Security is a priority for my business_Rather not,)  \\\n",
       "0                                                  0                                                                      \n",
       "1                                                  0                                                                      \n",
       "2                                                  0                                                                      \n",
       "3                                                  0                                                                      \n",
       "4                                                  0                                                                      \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-Security is a priority for my business_nan,)  \\\n",
       "0                                                  0                                                               \n",
       "1                                                  0                                                               \n",
       "2                                                  0                                                               \n",
       "3                                                  0                                                               \n",
       "4                                                  0                                                               \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-In the event of a problem, I can count on my supervisor_Completetly,)  \\\n",
       "0                                                  0                                                                                        \n",
       "1                                                  0                                                                                        \n",
       "2                                                  0                                                                                        \n",
       "3                                                  0                                                                                        \n",
       "4                                                  0                                                                                        \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-In the event of a problem, I can count on my supervisor_Not at all,)  \\\n",
       "0                                                  0                                                                                       \n",
       "1                                                  0                                                                                       \n",
       "2                                                  0                                                                                       \n",
       "3                                                  1                                                                                       \n",
       "4                                                  0                                                                                       \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-In the event of a problem, I can count on my supervisor_Rather,)  \\\n",
       "0                                                  1                                                                                   \n",
       "1                                                  1                                                                                   \n",
       "2                                                  0                                                                                   \n",
       "3                                                  0                                                                                   \n",
       "4                                                  0                                                                                   \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-In the event of a problem, I can count on my supervisor_Rather not,)  \\\n",
       "0                                                  0                                                                                       \n",
       "1                                                  0                                                                                       \n",
       "2                                                  1                                                                                       \n",
       "3                                                  0                                                                                       \n",
       "4                                                  1                                                                                       \n",
       "\n",
       "   (Q15- Indicate whether each of the following sentences suits you-In the event of a problem, I can count on my supervisor_nan,)  \\\n",
       "0                                                  0                                                                                \n",
       "1                                                  0                                                                                \n",
       "2                                                  0                                                                                \n",
       "3                                                  0                                                                                \n",
       "4                                                  0                                                                                \n",
       "\n",
       "   (Would you say that over the last 12 months, your pace of work has:_Accelerated,)  \\\n",
       "0                                                  0                                   \n",
       "1                                                  0                                   \n",
       "2                                                  0                                   \n",
       "3                                                  0                                   \n",
       "4                                                  0                                   \n",
       "\n",
       "   (Would you say that over the last 12 months, your pace of work has:_Do not know,)  \\\n",
       "0                                                  0                                   \n",
       "1                                                  0                                   \n",
       "2                                                  0                                   \n",
       "3                                                  0                                   \n",
       "4                                                  0                                   \n",
       "\n",
       "   (Would you say that over the last 12 months, your pace of work has:_Slow motion,)  \\\n",
       "0                                                  0                                   \n",
       "1                                                  0                                   \n",
       "2                                                  0                                   \n",
       "3                                                  0                                   \n",
       "4                                                  0                                   \n",
       "\n",
       "   (Would you say that over the last 12 months, your pace of work has:_Stabilized,)  \\\n",
       "0                                                  0                                  \n",
       "1                                                  0                                  \n",
       "2                                                  0                                  \n",
       "3                                                  0                                  \n",
       "4                                                  0                                  \n",
       "\n",
       "   (Would you say that over the last 12 months, your pace of work has:_nan,)  \\\n",
       "0                                                  1                           \n",
       "1                                                  1                           \n",
       "2                                                  1                           \n",
       "3                                                  1                           \n",
       "4                                                  1                           \n",
       "\n",
       "   (Q16- And for each of these sentences?-I would recommend my company to a friend_Completetly,)  \\\n",
       "0                                                  0                                               \n",
       "1                                                  0                                               \n",
       "2                                                  0                                               \n",
       "3                                                  0                                               \n",
       "4                                                  0                                               \n",
       "\n",
       "   (Q16- And for each of these sentences?-I would recommend my company to a friend_Not at all,)  \\\n",
       "0                                                  0                                              \n",
       "1                                                  0                                              \n",
       "2                                                  0                                              \n",
       "3                                                  0                                              \n",
       "4                                                  0                                              \n",
       "\n",
       "   (Q16- And for each of these sentences?-I would recommend my company to a friend_Rather,)  \\\n",
       "0                                                  0                                          \n",
       "1                                                  0                                          \n",
       "2                                                  0                                          \n",
       "3                                                  0                                          \n",
       "4                                                  0                                          \n",
       "\n",
       "   (Q16- And for each of these sentences?-I would recommend my company to a friend_Rather not,)  \\\n",
       "0                                                  0                                              \n",
       "1                                                  0                                              \n",
       "2                                                  0                                              \n",
       "3                                                  0                                              \n",
       "4                                                  0                                              \n",
       "\n",
       "   (Q16- And for each of these sentences?-I would recommend my company to a friend_nan,)  \\\n",
       "0                                                  1                                       \n",
       "1                                                  1                                       \n",
       "2                                                  1                                       \n",
       "3                                                  1                                       \n",
       "4                                                  1                                       \n",
       "\n",
       "   (Q16- And for each of these sentences?-I am proud to work in my company_Completetly,)  \\\n",
       "0                                                  0                                       \n",
       "1                                                  0                                       \n",
       "2                                                  0                                       \n",
       "3                                                  0                                       \n",
       "4                                                  0                                       \n",
       "\n",
       "   (Q16- And for each of these sentences?-I am proud to work in my company_Not at all,)  \\\n",
       "0                                                  0                                      \n",
       "1                                                  0                                      \n",
       "2                                                  0                                      \n",
       "3                                                  0                                      \n",
       "4                                                  0                                      \n",
       "\n",
       "   (Q16- And for each of these sentences?-I am proud to work in my company_Rather,)  \\\n",
       "0                                                  0                                  \n",
       "1                                                  0                                  \n",
       "2                                                  0                                  \n",
       "3                                                  0                                  \n",
       "4                                                  0                                  \n",
       "\n",
       "   (Q16- And for each of these sentences?-I am proud to work in my company_Rather not,)  \\\n",
       "0                                                  0                                      \n",
       "1                                                  0                                      \n",
       "2                                                  0                                      \n",
       "3                                                  0                                      \n",
       "4                                                  0                                      \n",
       "\n",
       "   (Q16- And for each of these sentences?-I am proud to work in my company_nan,)  \\\n",
       "0                                                  1                               \n",
       "1                                                  1                               \n",
       "2                                                  1                               \n",
       "3                                                  1                               \n",
       "4                                                  1                               \n",
       "\n",
       "   (Q17- At work, does it happen to you: (D-have decreased alertness, lack of attention_Never,)  \\\n",
       "0                                                  0                                              \n",
       "1                                                  0                                              \n",
       "2                                                  0                                              \n",
       "3                                                  0                                              \n",
       "4                                                  0                                              \n",
       "\n",
       "   (Q17- At work, does it happen to you: (D-have decreased alertness, lack of attention_Often,)  \\\n",
       "0                                                  0                                              \n",
       "1                                                  0                                              \n",
       "2                                                  0                                              \n",
       "3                                                  0                                              \n",
       "4                                                  0                                              \n",
       "\n",
       "   (Q17- At work, does it happen to you: (D-have decreased alertness, lack of attention_Sometimes,)  \\\n",
       "0                                                  1                                                  \n",
       "1                                                  1                                                  \n",
       "2                                                  1                                                  \n",
       "3                                                  0                                                  \n",
       "4                                                  1                                                  \n",
       "\n",
       "   (Q17- At work, does it happen to you: (D-have decreased alertness, lack of attention_Very Often,)  \\\n",
       "0                                                  0                                                   \n",
       "1                                                  0                                                   \n",
       "2                                                  0                                                   \n",
       "3                                                  1                                                   \n",
       "4                                                  0                                                   \n",
       "\n",
       "   (Q17- At work, does it happen to you: (D-have decreased alertness, lack of attention_nan,)  \\\n",
       "0                                                  0                                            \n",
       "1                                                  0                                            \n",
       "2                                                  0                                            \n",
       "3                                                  0                                            \n",
       "4                                                  0                                            \n",
       "\n",
       "   (Q17- At work, does it happen to you: (D-e receiving hurtful or aggressive remarks within the company_Never,)  \\\n",
       "0                                                  1                                                               \n",
       "1                                                  1                                                               \n",
       "2                                                  1                                                               \n",
       "3                                                  0                                                               \n",
       "4                                                  0                                                               \n",
       "\n",
       "   (Q17- At work, does it happen to you: (D-e receiving hurtful or aggressive remarks within the company_Often,)  \\\n",
       "0                                                  0                                                               \n",
       "1                                                  0                                                               \n",
       "2                                                  0                                                               \n",
       "3                                                  0                                                               \n",
       "4                                                  0                                                               \n",
       "\n",
       "   (Q17- At work, does it happen to you: (D-e receiving hurtful or aggressive remarks within the company_Sometimes,)  \\\n",
       "0                                                  0                                                                   \n",
       "1                                                  0                                                                   \n",
       "2                                                  0                                                                   \n",
       "3                                                  0                                                                   \n",
       "4                                                  0                                                                   \n",
       "\n",
       "   (Q17- At work, does it happen to you: (D-e receiving hurtful or aggressive remarks within the company_Very Often,)  \\\n",
       "0                                                  0                                                                    \n",
       "1                                                  0                                                                    \n",
       "2                                                  0                                                                    \n",
       "3                                                  1                                                                    \n",
       "4                                                  1                                                                    \n",
       "\n",
       "   (Q17- At work, does it happen to you: (D-e receiving hurtful or aggressive remarks within the company_nan,)  \\\n",
       "0                                                  0                                                             \n",
       "1                                                  0                                                             \n",
       "2                                                  0                                                             \n",
       "3                                                  0                                                             \n",
       "4                                                  0                                                             \n",
       "\n",
       "   (Q17- At work, does it happen to you: (D-being insulted or attacked by the public or customers_Never,)  \\\n",
       "0                                                  1                                                        \n",
       "1                                                  0                                                        \n",
       "2                                                  1                                                        \n",
       "3                                                  0                                                        \n",
       "4                                                  1                                                        \n",
       "\n",
       "   (Q17- At work, does it happen to you: (D-being insulted or attacked by the public or customers_Often,)  \\\n",
       "0                                                  0                                                        \n",
       "1                                                  0                                                        \n",
       "2                                                  0                                                        \n",
       "3                                                  0                                                        \n",
       "4                                                  0                                                        \n",
       "\n",
       "   (Q17- At work, does it happen to you: (D-being insulted or attacked by the public or customers_Sometimes,)  \\\n",
       "0                                                  0                                                            \n",
       "1                                                  0                                                            \n",
       "2                                                  0                                                            \n",
       "3                                                  0                                                            \n",
       "4                                                  0                                                            \n",
       "\n",
       "   (Q17- At work, does it happen to you: (D-being insulted or attacked by the public or customers_Very Often,)  \\\n",
       "0                                                  0                                                             \n",
       "1                                                  1                                                             \n",
       "2                                                  0                                                             \n",
       "3                                                  1                                                             \n",
       "4                                                  0                                                             \n",
       "\n",
       "   (Q17- At work, does it happen to you: (D-being insulted or attacked by the public or customers_nan,)  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-'work organization_Satisfying,)  \\\n",
       "0                                                  0                                                                                                       \n",
       "1                                                  0                                                                                                       \n",
       "2                                                  0                                                                                                       \n",
       "3                                                  0                                                                                                       \n",
       "4                                                  0                                                                                                       \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-'work organization_Unsatisfactory,)  \\\n",
       "0                                                  0                                                                                                           \n",
       "1                                                  0                                                                                                           \n",
       "2                                                  0                                                                                                           \n",
       "3                                                  0                                                                                                           \n",
       "4                                                  0                                                                                                           \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-'work organization_nan,)  \\\n",
       "0                                                  1                                                                                                \n",
       "1                                                  1                                                                                                \n",
       "2                                                  1                                                                                                \n",
       "3                                                  1                                                                                                \n",
       "4                                                  1                                                                                                \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-clarity of your role in the companyÔøΩs activity_Satisfying,)  \\\n",
       "0                                                  0                                                                                                                                     \n",
       "1                                                  0                                                                                                                                     \n",
       "2                                                  0                                                                                                                                     \n",
       "3                                                  0                                                                                                                                     \n",
       "4                                                  0                                                                                                                                     \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-clarity of your role in the companyÔøΩs activity_Unsatisfactory,)  \\\n",
       "0                                                  0                                                                                                                                         \n",
       "1                                                  0                                                                                                                                         \n",
       "2                                                  0                                                                                                                                         \n",
       "3                                                  0                                                                                                                                         \n",
       "4                                                  0                                                                                                                                         \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-clarity of your role in the companyÔøΩs activity_nan,)  \\\n",
       "0                                                  1                                                                                                                              \n",
       "1                                                  1                                                                                                                              \n",
       "2                                                  1                                                                                                                              \n",
       "3                                                  1                                                                                                                              \n",
       "4                                                  1                                                                                                                              \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-access to professional training_Satisfying,)  \\\n",
       "0                                                  0                                                                                                                    \n",
       "1                                                  0                                                                                                                    \n",
       "2                                                  0                                                                                                                    \n",
       "3                                                  0                                                                                                                    \n",
       "4                                                  0                                                                                                                    \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-access to professional training_Unsatisfactory,)  \\\n",
       "0                                                  0                                                                                                                        \n",
       "1                                                  0                                                                                                                        \n",
       "2                                                  0                                                                                                                        \n",
       "3                                                  0                                                                                                                        \n",
       "4                                                  0                                                                                                                        \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-access to professional training_nan,)  \\\n",
       "0                                                  1                                                                                                             \n",
       "1                                                  1                                                                                                             \n",
       "2                                                  1                                                                                                             \n",
       "3                                                  1                                                                                                             \n",
       "4                                                  1                                                                                                             \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a relationship with your direct superior_Satisfying,)  \\\n",
       "0                                                  0                                                                                                                             \n",
       "1                                                  0                                                                                                                             \n",
       "2                                                  0                                                                                                                             \n",
       "3                                                  0                                                                                                                             \n",
       "4                                                  0                                                                                                                             \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a relationship with your direct superior_Unsatisfactory,)  \\\n",
       "0                                                  0                                                                                                                                 \n",
       "1                                                  0                                                                                                                                 \n",
       "2                                                  0                                                                                                                                 \n",
       "3                                                  0                                                                                                                                 \n",
       "4                                                  0                                                                                                                                 \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a relationship with your direct superior_nan,)  \\\n",
       "0                                                  1                                                                                                                      \n",
       "1                                                  1                                                                                                                      \n",
       "2                                                  1                                                                                                                      \n",
       "3                                                  1                                                                                                                      \n",
       "4                                                  1                                                                                                                      \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-atmosphere in your team_Satisfying,)  \\\n",
       "0                                                  0                                                                                                            \n",
       "1                                                  0                                                                                                            \n",
       "2                                                  0                                                                                                            \n",
       "3                                                  0                                                                                                            \n",
       "4                                                  0                                                                                                            \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-atmosphere in your team_Unsatisfactory,)  \\\n",
       "0                                                  0                                                                                                                \n",
       "1                                                  0                                                                                                                \n",
       "2                                                  0                                                                                                                \n",
       "3                                                  0                                                                                                                \n",
       "4                                                  0                                                                                                                \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-atmosphere in your team_nan,)  \\\n",
       "0                                                  1                                                                                                     \n",
       "1                                                  1                                                                                                     \n",
       "2                                                  1                                                                                                     \n",
       "3                                                  1                                                                                                     \n",
       "4                                                  1                                                                                                     \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-tools or your workstation_Satisfying,)  \\\n",
       "0                                                  0                                                                                                              \n",
       "1                                                  0                                                                                                              \n",
       "2                                                  0                                                                                                              \n",
       "3                                                  0                                                                                                              \n",
       "4                                                  0                                                                                                              \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-tools or your workstation_Unsatisfactory,)  \\\n",
       "0                                                  0                                                                                                                  \n",
       "1                                                  0                                                                                                                  \n",
       "2                                                  0                                                                                                                  \n",
       "3                                                  0                                                                                                                  \n",
       "4                                                  0                                                                                                                  \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-tools or your workstation_nan,)  \\\n",
       "0                                                  1                                                                                                       \n",
       "1                                                  1                                                                                                       \n",
       "2                                                  1                                                                                                       \n",
       "3                                                  1                                                                                                       \n",
       "4                                                  1                                                                                                       \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-the prospects for development_Satisfying,)  \\\n",
       "0                                                  0                                                                                                                  \n",
       "1                                                  0                                                                                                                  \n",
       "2                                                  0                                                                                                                  \n",
       "3                                                  0                                                                                                                  \n",
       "4                                                  0                                                                                                                  \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-the prospects for development_Unsatisfactory,)  \\\n",
       "0                                                  0                                                                                                                      \n",
       "1                                                  0                                                                                                                      \n",
       "2                                                  0                                                                                                                      \n",
       "3                                                  0                                                                                                                      \n",
       "4                                                  0                                                                                                                      \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-the prospects for development_nan,)  \\\n",
       "0                                                  1                                                                                                           \n",
       "1                                                  1                                                                                                           \n",
       "2                                                  1                                                                                                           \n",
       "3                                                  1                                                                                                           \n",
       "4                                                  1                                                                                                           \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-relationships between services_Satisfying,)  \\\n",
       "0                                                  0                                                                                                                   \n",
       "1                                                  0                                                                                                                   \n",
       "2                                                  0                                                                                                                   \n",
       "3                                                  0                                                                                                                   \n",
       "4                                                  0                                                                                                                   \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-relationships between services_Unsatisfactory,)  \\\n",
       "0                                                  0                                                                                                                       \n",
       "1                                                  0                                                                                                                       \n",
       "2                                                  0                                                                                                                       \n",
       "3                                                  0                                                                                                                       \n",
       "4                                                  0                                                                                                                       \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-relationships between services_nan,)  \\\n",
       "0                                                  1                                                                                                            \n",
       "1                                                  1                                                                                                            \n",
       "2                                                  1                                                                                                            \n",
       "3                                                  1                                                                                                            \n",
       "4                                                  1                                                                                                            \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-e management_Satisfying,)  \\\n",
       "0                                                  0                                                                                                 \n",
       "1                                                  0                                                                                                 \n",
       "2                                                  0                                                                                                 \n",
       "3                                                  0                                                                                                 \n",
       "4                                                  0                                                                                                 \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-e management_Unsatisfactory,)  \\\n",
       "0                                                  0                                                                                                     \n",
       "1                                                  0                                                                                                     \n",
       "2                                                  0                                                                                                     \n",
       "3                                                  0                                                                                                     \n",
       "4                                                  0                                                                                                     \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-e management_nan,)  \\\n",
       "0                                                  1                                                                                          \n",
       "1                                                  1                                                                                          \n",
       "2                                                  1                                                                                          \n",
       "3                                                  1                                                                                          \n",
       "4                                                  1                                                                                          \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a communication and understanding of business strategy_Satisfying,)  \\\n",
       "0                                                  0                                                                                                                                           \n",
       "1                                                  0                                                                                                                                           \n",
       "2                                                  0                                                                                                                                           \n",
       "3                                                  0                                                                                                                                           \n",
       "4                                                  0                                                                                                                                           \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a communication and understanding of business strategy_Unsatisfactory,)  \\\n",
       "0                                                  0                                                                                                                                               \n",
       "1                                                  0                                                                                                                                               \n",
       "2                                                  0                                                                                                                                               \n",
       "3                                                  0                                                                                                                                               \n",
       "4                                                  0                                                                                                                                               \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a communication and understanding of business strategy_nan,)  \\\n",
       "0                                                  1                                                                                                                                    \n",
       "1                                                  1                                                                                                                                    \n",
       "2                                                  1                                                                                                                                    \n",
       "3                                                  1                                                                                                                                    \n",
       "4                                                  1                                                                                                                                    \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-recognition at work_Satisfying,)  \\\n",
       "0                                                  0                                                                                                        \n",
       "1                                                  0                                                                                                        \n",
       "2                                                  0                                                                                                        \n",
       "3                                                  0                                                                                                        \n",
       "4                                                  0                                                                                                        \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-recognition at work_Unsatisfactory,)  \\\n",
       "0                                                  0                                                                                                            \n",
       "1                                                  0                                                                                                            \n",
       "2                                                  0                                                                                                            \n",
       "3                                                  0                                                                                                            \n",
       "4                                                  0                                                                                                            \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-recognition at work_nan,)  \\\n",
       "0                                                  1                                                                                                 \n",
       "1                                                  1                                                                                                 \n",
       "2                                                  1                                                                                                 \n",
       "3                                                  1                                                                                                 \n",
       "4                                                  1                                                                                                 \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-has mastery of your position (responsibility, means, skills_Satisfying,)  \\\n",
       "0                                                  0                                                                                                                                                \n",
       "1                                                  0                                                                                                                                                \n",
       "2                                                  0                                                                                                                                                \n",
       "3                                                  0                                                                                                                                                \n",
       "4                                                  0                                                                                                                                                \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-has mastery of your position (responsibility, means, skills_Unsatisfactory,)  \\\n",
       "0                                                  0                                                                                                                                                    \n",
       "1                                                  0                                                                                                                                                    \n",
       "2                                                  0                                                                                                                                                    \n",
       "3                                                  0                                                                                                                                                    \n",
       "4                                                  0                                                                                                                                                    \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-has mastery of your position (responsibility, means, skills_nan,)  \\\n",
       "0                                                  1                                                                                                                                         \n",
       "1                                                  1                                                                                                                                         \n",
       "2                                                  1                                                                                                                                         \n",
       "3                                                  1                                                                                                                                         \n",
       "4                                                  1                                                                                                                                         \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-moments of conviviality_Satisfying,)  \\\n",
       "0                                                  0                                                                                                            \n",
       "1                                                  0                                                                                                            \n",
       "2                                                  0                                                                                                            \n",
       "3                                                  0                                                                                                            \n",
       "4                                                  0                                                                                                            \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-moments of conviviality_Unsatisfactory,)  \\\n",
       "0                                                  0                                                                                                                \n",
       "1                                                  0                                                                                                                \n",
       "2                                                  0                                                                                                                \n",
       "3                                                  0                                                                                                                \n",
       "4                                                  0                                                                                                                \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-moments of conviviality_nan,)  \\\n",
       "0                                                  1                                                                                                     \n",
       "1                                                  1                                                                                                     \n",
       "2                                                  1                                                                                                     \n",
       "3                                                  1                                                                                                     \n",
       "4                                                  1                                                                                                     \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a balance between private life and professional life_Satisfying,)  \\\n",
       "0                                                  0                                                                                                                                         \n",
       "1                                                  0                                                                                                                                         \n",
       "2                                                  0                                                                                                                                         \n",
       "3                                                  0                                                                                                                                         \n",
       "4                                                  0                                                                                                                                         \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a balance between private life and professional life_Unsatisfactory,)  \\\n",
       "0                                                  0                                                                                                                                             \n",
       "1                                                  0                                                                                                                                             \n",
       "2                                                  0                                                                                                                                             \n",
       "3                                                  0                                                                                                                                             \n",
       "4                                                  0                                                                                                                                             \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a balance between private life and professional life_nan,)  \\\n",
       "0                                                  1                                                                                                                                  \n",
       "1                                                  1                                                                                                                                  \n",
       "2                                                  1                                                                                                                                  \n",
       "3                                                  1                                                                                                                                  \n",
       "4                                                  1                                                                                                                                  \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-The services provided by the company (crÔøΩche, concierge, gym, etc.)_Satisfying,)  \\\n",
       "0                                                  0                                                                                                                                                          \n",
       "1                                                  0                                                                                                                                                          \n",
       "2                                                  0                                                                                                                                                          \n",
       "3                                                  0                                                                                                                                                          \n",
       "4                                                  0                                                                                                                                                          \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-The services provided by the company (crÔøΩche, concierge, gym, etc.)_Unsatisfactory,)  \\\n",
       "0                                                  0                                                                                                                                                              \n",
       "1                                                  0                                                                                                                                                              \n",
       "2                                                  0                                                                                                                                                              \n",
       "3                                                  0                                                                                                                                                              \n",
       "4                                                  0                                                                                                                                                              \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-The services provided by the company (crÔøΩche, concierge, gym, etc.)_nan,)  \\\n",
       "0                                                  1                                                                                                                                                   \n",
       "1                                                  1                                                                                                                                                   \n",
       "2                                                  1                                                                                                                                                   \n",
       "3                                                  1                                                                                                                                                   \n",
       "4                                                  1                                                                                                                                                   \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a social protection (mutual health, insurance) offered by your company_Satisfying,)  \\\n",
       "0                                                  0                                                                                                                                                           \n",
       "1                                                  0                                                                                                                                                           \n",
       "2                                                  0                                                                                                                                                           \n",
       "3                                                  0                                                                                                                                                           \n",
       "4                                                  0                                                                                                                                                           \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a social protection (mutual health, insurance) offered by your company_Unsatisfactory,)  \\\n",
       "0                                                  0                                                                                                                                                               \n",
       "1                                                  0                                                                                                                                                               \n",
       "2                                                  0                                                                                                                                                               \n",
       "3                                                  0                                                                                                                                                               \n",
       "4                                                  0                                                                                                                                                               \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a social protection (mutual health, insurance) offered by your company_nan,)  \\\n",
       "0                                                  1                                                                                                                                                    \n",
       "1                                                  1                                                                                                                                                    \n",
       "2                                                  1                                                                                                                                                    \n",
       "3                                                  1                                                                                                                                                    \n",
       "4                                                  1                                                                                                                                                    \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-working hours_Satisfying,)  \\\n",
       "0                                                  0                                                                                                  \n",
       "1                                                  0                                                                                                  \n",
       "2                                                  0                                                                                                  \n",
       "3                                                  0                                                                                                  \n",
       "4                                                  0                                                                                                  \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-working hours_Unsatisfactory,)  \\\n",
       "0                                                  0                                                                                                      \n",
       "1                                                  0                                                                                                      \n",
       "2                                                  0                                                                                                      \n",
       "3                                                  0                                                                                                      \n",
       "4                                                  0                                                                                                      \n",
       "\n",
       "   (Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-working hours_nan,)  \\\n",
       "0                                                  1                                                                                           \n",
       "1                                                  1                                                                                           \n",
       "2                                                  1                                                                                           \n",
       "3                                                  1                                                                                           \n",
       "4                                                  1                                                                                           \n",
       "\n",
       "   (Q22- Over the last 12 months have you personally experienced one or more of the following events:-Loss of job (yourself or your spouse)_I adhere to the directions chosen by my company,)  \\\n",
       "0                                                  0                                                                                                                                            \n",
       "1                                                  0                                                                                                                                            \n",
       "2                                                  0                                                                                                                                            \n",
       "3                                                  0                                                                                                                                            \n",
       "4                                                  0                                                                                                                                            \n",
       "\n",
       "   (Q22- Over the last 12 months have you personally experienced one or more of the following events:-Loss of job (yourself or your spouse)_I am involved upstream, we integrate my point of view,)  \\\n",
       "0                                                  0                                                                                                                                                  \n",
       "1                                                  0                                                                                                                                                  \n",
       "2                                                  0                                                                                                                                                  \n",
       "3                                                  0                                                                                                                                                  \n",
       "4                                                  0                                                                                                                                                  \n",
       "\n",
       "   (Q22- Over the last 12 months have you personally experienced one or more of the following events:-Loss of job (yourself or your spouse)_I benefit from support in implementation (training, communication, etc.),)  \\\n",
       "0                                                  0                                                                                                                                                                     \n",
       "1                                                  0                                                                                                                                                                     \n",
       "2                                                  0                                                                                                                                                                     \n",
       "3                                                  0                                                                                                                                                                     \n",
       "4                                                  0                                                                                                                                                                     \n",
       "\n",
       "   (Q22- Over the last 12 months have you personally experienced one or more of the following events:-Loss of job (yourself or your spouse)_I make sure to adapt,)  \\\n",
       "0                                                  0                                                                                                                 \n",
       "1                                                  1                                                                                                                 \n",
       "2                                                  0                                                                                                                 \n",
       "3                                                  0                                                                                                                 \n",
       "4                                                  0                                                                                                                 \n",
       "\n",
       "   (Q22- Over the last 12 months have you personally experienced one or more of the following events:-Loss of job (yourself or your spouse)_I understand they are necessary,)  \\\n",
       "0                                                  0                                                                                                                            \n",
       "1                                                  0                                                                                                                            \n",
       "2                                                  0                                                                                                                            \n",
       "3                                                  0                                                                                                                            \n",
       "4                                                  0                                                                                                                            \n",
       "\n",
       "   (Q22- Over the last 12 months have you personally experienced one or more of the following events:-Loss of job (yourself or your spouse)_They come back too often,)  \\\n",
       "0                                                  0                                                                                                                     \n",
       "1                                                  0                                                                                                                     \n",
       "2                                                  0                                                                                                                     \n",
       "3                                                  0                                                                                                                     \n",
       "4                                                  0                                                                                                                     \n",
       "\n",
       "   (Q22- Over the last 12 months have you personally experienced one or more of the following events:-Loss of job (yourself or your spouse)_nan,)  \\\n",
       "0                                                  1                                                                                                \n",
       "1                                                  0                                                                                                \n",
       "2                                                  1                                                                                                \n",
       "3                                                  1                                                                                                \n",
       "4                                                  1                                                                                                \n",
       "\n",
       "   (Q22- Over the last 12 months have you personally experienced one or more of the following events:-An imposed change of position or profession_I adhere to the directions chosen by my company,)  \\\n",
       "0                                                  0                                                                                                                                                  \n",
       "1                                                  0                                                                                                                                                  \n",
       "2                                                  0                                                                                                                                                  \n",
       "3                                                  0                                                                                                                                                  \n",
       "4                                                  0                                                                                                                                                  \n",
       "\n",
       "   (Q22- Over the last 12 months have you personally experienced one or more of the following events:-An imposed change of position or profession_I am involved upstream, we integrate my point of view,)  \\\n",
       "0                                                  0                                                                                                                                                        \n",
       "1                                                  1                                                                                                                                                        \n",
       "2                                                  0                                                                                                                                                        \n",
       "3                                                  0                                                                                                                                                        \n",
       "4                                                  0                                                                                                                                                        \n",
       "\n",
       "   (Q22- Over the last 12 months have you personally experienced one or more of the following events:-An imposed change of position or profession_I benefit from support in implementation (training, communication, etc.),)  \\\n",
       "0                                                  0                                                                                                                                                                           \n",
       "1                                                  0                                                                                                                                                                           \n",
       "2                                                  0                                                                                                                                                                           \n",
       "3                                                  0                                                                                                                                                                           \n",
       "4                                                  0                                                                                                                                                                           \n",
       "\n",
       "   (Q22- Over the last 12 months have you personally experienced one or more of the following events:-An imposed change of position or profession_They come back too often,)  \\\n",
       "0                                                  0                                                                                                                           \n",
       "1                                                  0                                                                                                                           \n",
       "2                                                  0                                                                                                                           \n",
       "3                                                  0                                                                                                                           \n",
       "4                                                  0                                                                                                                           \n",
       "\n",
       "   (Q22- Over the last 12 months have you personally experienced one or more of the following events:-An imposed change of position or profession_nan,)  \\\n",
       "0                                                  1                                                                                                      \n",
       "1                                                  0                                                                                                      \n",
       "2                                                  1                                                                                                      \n",
       "3                                                  1                                                                                                      \n",
       "4                                                  1                                                                                                      \n",
       "\n",
       "   (Q22- Over the last 12 months have you personally experienced one or more of the following events:-A restructuring or reorganization of your service or business_I am involved upstream, we integrate my point of view,)  \\\n",
       "0                                                  0                                                                                                                                                                          \n",
       "1                                                  0                                                                                                                                                                          \n",
       "2                                                  0                                                                                                                                                                          \n",
       "3                                                  0                                                                                                                                                                          \n",
       "4                                                  0                                                                                                                                                                          \n",
       "\n",
       "   (Q22- Over the last 12 months have you personally experienced one or more of the following events:-A restructuring or reorganization of your service or business_I benefit from support in implementation (training, communication, etc.),)  \\\n",
       "0                                                  0                                                                                                                                                                                             \n",
       "1                                                  1                                                                                                                                                                                             \n",
       "2                                                  0                                                                                                                                                                                             \n",
       "3                                                  0                                                                                                                                                                                             \n",
       "4                                                  0                                                                                                                                                                                             \n",
       "\n",
       "   (Q22- Over the last 12 months have you personally experienced one or more of the following events:-A restructuring or reorganization of your service or business_They come back too often,)  \\\n",
       "0                                                  0                                                                                                                                             \n",
       "1                                                  0                                                                                                                                             \n",
       "2                                                  0                                                                                                                                             \n",
       "3                                                  0                                                                                                                                             \n",
       "4                                                  0                                                                                                                                             \n",
       "\n",
       "   (Q22- Over the last 12 months have you personally experienced one or more of the following events:-A restructuring or reorganization of your service or business_nan,)  \\\n",
       "0                                                  1                                                                                                                        \n",
       "1                                                  0                                                                                                                        \n",
       "2                                                  1                                                                                                                        \n",
       "3                                                  1                                                                                                                        \n",
       "4                                                  1                                                                                                                        \n",
       "\n",
       "   (Q22- Over the last 12 months have you personally experienced one or more of the following events:-A social plan, layoffs in your company_I benefit from support in implementation (training, communication, etc.),)  \\\n",
       "0                                                  0                                                                                                                                                                      \n",
       "1                                                  0                                                                                                                                                                      \n",
       "2                                                  0                                                                                                                                                                      \n",
       "3                                                  0                                                                                                                                                                      \n",
       "4                                                  0                                                                                                                                                                      \n",
       "\n",
       "   (Q22- Over the last 12 months have you personally experienced one or more of the following events:-A social plan, layoffs in your company_They come back too often,)  \\\n",
       "0                                                  0                                                                                                                      \n",
       "1                                                  0                                                                                                                      \n",
       "2                                                  0                                                                                                                      \n",
       "3                                                  0                                                                                                                      \n",
       "4                                                  0                                                                                                                      \n",
       "\n",
       "   (Q22- Over the last 12 months have you personally experienced one or more of the following events:-A social plan, layoffs in your company_nan,)  \\\n",
       "0                                                  1                                                                                                 \n",
       "1                                                  1                                                                                                 \n",
       "2                                                  1                                                                                                 \n",
       "3                                                  1                                                                                                 \n",
       "4                                                  1                                                                                                 \n",
       "\n",
       "   (Q22- Over the last 12 months have you personally experienced one or more of the following events:-One or more periods of technical unemployment_nan,)  \\\n",
       "0                                                  1                                                                                                        \n",
       "1                                                  1                                                                                                        \n",
       "2                                                  1                                                                                                        \n",
       "3                                                  1                                                                                                        \n",
       "4                                                  1                                                                                                        \n",
       "\n",
       "   (Q23- Do you have difficulty reconciling your work with your other personal or family commitments?-Yes quite_No not at all,)  \\\n",
       "0                                                  0                                                                              \n",
       "1                                                  0                                                                              \n",
       "2                                                  1                                                                              \n",
       "3                                                  0                                                                              \n",
       "4                                                  0                                                                              \n",
       "\n",
       "   (Q23- Do you have difficulty reconciling your work with your other personal or family commitments?-Yes quite_No, rather not,)  \\\n",
       "0                                                  0                                                                               \n",
       "1                                                  1                                                                               \n",
       "2                                                  0                                                                               \n",
       "3                                                  0                                                                               \n",
       "4                                                  0                                                                               \n",
       "\n",
       "   (Q23- Do you have difficulty reconciling your work with your other personal or family commitments?-Yes quite_Yes quite,)  \\\n",
       "0                                                  0                                                                          \n",
       "1                                                  0                                                                          \n",
       "2                                                  0                                                                          \n",
       "3                                                  0                                                                          \n",
       "4                                                  0                                                                          \n",
       "\n",
       "   (Q23- Do you have difficulty reconciling your work with your other personal or family commitments?-Yes quite_Yes, rather,)  \\\n",
       "0                                                  1                                                                            \n",
       "1                                                  0                                                                            \n",
       "2                                                  0                                                                            \n",
       "3                                                  1                                                                            \n",
       "4                                                  1                                                                            \n",
       "\n",
       "   (Q23- Do you have difficulty reconciling your work with your other personal or family commitments?-Yes quite_nan,)  \\\n",
       "0                                                  0                                                                    \n",
       "1                                                  0                                                                    \n",
       "2                                                  0                                                                    \n",
       "3                                                  0                                                                    \n",
       "4                                                  0                                                                    \n",
       "\n",
       "   (Q25-Your workplace-home transportation time (round trip) is:_Between 1 hour and 2 hours per day,)  \\\n",
       "0                                                  0                                                    \n",
       "1                                                  0                                                    \n",
       "2                                                  0                                                    \n",
       "3                                                  1                                                    \n",
       "4                                                  0                                                    \n",
       "\n",
       "   (Q25-Your workplace-home transportation time (round trip) is:_From 2 hours to 3 hours per day,)  \\\n",
       "0                                                  0                                                 \n",
       "1                                                  0                                                 \n",
       "2                                                  0                                                 \n",
       "3                                                  0                                                 \n",
       "4                                                  0                                                 \n",
       "\n",
       "   (Q25-Your workplace-home transportation time (round trip) is:_Less than 1 hour per day,)  \\\n",
       "0                                                  1                                          \n",
       "1                                                  1                                          \n",
       "2                                                  1                                          \n",
       "3                                                  0                                          \n",
       "4                                                  1                                          \n",
       "\n",
       "   (Q25-Your workplace-home transportation time (round trip) is:_More than 3 hours per day,)  \\\n",
       "0                                                  0                                           \n",
       "1                                                  0                                           \n",
       "2                                                  0                                           \n",
       "3                                                  0                                           \n",
       "4                                                  0                                           \n",
       "\n",
       "   (Q25-Your workplace-home transportation time (round trip) is:_nan,)  \\\n",
       "0                                                  0                     \n",
       "1                                                  0                     \n",
       "2                                                  0                     \n",
       "3                                                  0                     \n",
       "4                                                  0                     \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-Your professional situation_Confident,)  \\\n",
       "0                                                  0                                                                                \n",
       "1                                                  0                                                                                \n",
       "2                                                  0                                                                                \n",
       "3                                                  0                                                                                \n",
       "4                                                  0                                                                                \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-Your professional situation_Not confident at all,)  \\\n",
       "0                                                  0                                                                                           \n",
       "1                                                  0                                                                                           \n",
       "2                                                  0                                                                                           \n",
       "3                                                  0                                                                                           \n",
       "4                                                  0                                                                                           \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-Your professional situation_Not very confident,)  \\\n",
       "0                                                  0                                                                                         \n",
       "1                                                  0                                                                                         \n",
       "2                                                  0                                                                                         \n",
       "3                                                  0                                                                                         \n",
       "4                                                  0                                                                                         \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-Your professional situation_Very confident,)  \\\n",
       "0                                                  0                                                                                     \n",
       "1                                                  0                                                                                     \n",
       "2                                                  0                                                                                     \n",
       "3                                                  0                                                                                     \n",
       "4                                                  0                                                                                     \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-Your professional situation_nan,)  \\\n",
       "0                                                  1                                                                          \n",
       "1                                                  1                                                                          \n",
       "2                                                  1                                                                          \n",
       "3                                                  1                                                                          \n",
       "4                                                  1                                                                          \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-The financial situation of your household_Confident,)  \\\n",
       "0                                                  0                                                                                              \n",
       "1                                                  0                                                                                              \n",
       "2                                                  0                                                                                              \n",
       "3                                                  0                                                                                              \n",
       "4                                                  0                                                                                              \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-The financial situation of your household_Not confident at all,)  \\\n",
       "0                                                  0                                                                                                         \n",
       "1                                                  0                                                                                                         \n",
       "2                                                  0                                                                                                         \n",
       "3                                                  0                                                                                                         \n",
       "4                                                  0                                                                                                         \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-The financial situation of your household_Not very confident,)  \\\n",
       "0                                                  0                                                                                                       \n",
       "1                                                  0                                                                                                       \n",
       "2                                                  0                                                                                                       \n",
       "3                                                  0                                                                                                       \n",
       "4                                                  0                                                                                                       \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-The financial situation of your household_Very confident,)  \\\n",
       "0                                                  0                                                                                                   \n",
       "1                                                  0                                                                                                   \n",
       "2                                                  0                                                                                                   \n",
       "3                                                  0                                                                                                   \n",
       "4                                                  0                                                                                                   \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-The financial situation of your household_nan,)  \\\n",
       "0                                                  1                                                                                        \n",
       "1                                                  1                                                                                        \n",
       "2                                                  1                                                                                        \n",
       "3                                                  1                                                                                        \n",
       "4                                                  1                                                                                        \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-Your housing conditions_Confident,)  \\\n",
       "0                                                  0                                                                            \n",
       "1                                                  0                                                                            \n",
       "2                                                  0                                                                            \n",
       "3                                                  0                                                                            \n",
       "4                                                  0                                                                            \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-Your housing conditions_Not confident at all,)  \\\n",
       "0                                                  0                                                                                       \n",
       "1                                                  0                                                                                       \n",
       "2                                                  0                                                                                       \n",
       "3                                                  0                                                                                       \n",
       "4                                                  0                                                                                       \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-Your housing conditions_Not very confident,)  \\\n",
       "0                                                  0                                                                                     \n",
       "1                                                  0                                                                                     \n",
       "2                                                  0                                                                                     \n",
       "3                                                  0                                                                                     \n",
       "4                                                  0                                                                                     \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-Your housing conditions_Very confident,)  \\\n",
       "0                                                  0                                                                                 \n",
       "1                                                  0                                                                                 \n",
       "2                                                  0                                                                                 \n",
       "3                                                  0                                                                                 \n",
       "4                                                  0                                                                                 \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-Your housing conditions_nan,)  \\\n",
       "0                                                  1                                                                      \n",
       "1                                                  1                                                                      \n",
       "2                                                  1                                                                      \n",
       "3                                                  1                                                                      \n",
       "4                                                  1                                                                      \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-Your emotional life_Confident,)  \\\n",
       "0                                                  0                                                                        \n",
       "1                                                  0                                                                        \n",
       "2                                                  0                                                                        \n",
       "3                                                  0                                                                        \n",
       "4                                                  0                                                                        \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-Your emotional life_Not confident at all,)  \\\n",
       "0                                                  0                                                                                   \n",
       "1                                                  0                                                                                   \n",
       "2                                                  0                                                                                   \n",
       "3                                                  0                                                                                   \n",
       "4                                                  0                                                                                   \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-Your emotional life_Not very confident,)  \\\n",
       "0                                                  0                                                                                 \n",
       "1                                                  0                                                                                 \n",
       "2                                                  0                                                                                 \n",
       "3                                                  0                                                                                 \n",
       "4                                                  0                                                                                 \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-Your emotional life_Very confident,)  \\\n",
       "0                                                  0                                                                             \n",
       "1                                                  0                                                                             \n",
       "2                                                  0                                                                             \n",
       "3                                                  0                                                                             \n",
       "4                                                  0                                                                             \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-Your emotional life_nan,)  \\\n",
       "0                                                  1                                                                  \n",
       "1                                                  1                                                                  \n",
       "2                                                  1                                                                  \n",
       "3                                                  1                                                                  \n",
       "4                                                  1                                                                  \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-Your health_Confident,)  \\\n",
       "0                                                  0                                                                \n",
       "1                                                  0                                                                \n",
       "2                                                  0                                                                \n",
       "3                                                  0                                                                \n",
       "4                                                  0                                                                \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-Your health_Not confident at all,)  \\\n",
       "0                                                  0                                                                           \n",
       "1                                                  0                                                                           \n",
       "2                                                  0                                                                           \n",
       "3                                                  0                                                                           \n",
       "4                                                  0                                                                           \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-Your health_Not very confident,)  \\\n",
       "0                                                  0                                                                         \n",
       "1                                                  0                                                                         \n",
       "2                                                  0                                                                         \n",
       "3                                                  0                                                                         \n",
       "4                                                  0                                                                         \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-Your health_Very confident,)  \\\n",
       "0                                                  0                                                                     \n",
       "1                                                  0                                                                     \n",
       "2                                                  0                                                                     \n",
       "3                                                  0                                                                     \n",
       "4                                                  0                                                                     \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-Your health_nan,)  \\\n",
       "0                                                  1                                                          \n",
       "1                                                  1                                                          \n",
       "2                                                  1                                                          \n",
       "3                                                  1                                                          \n",
       "4                                                  1                                                          \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-The future of your child(ren)_Confident,)  \\\n",
       "0                                                  0                                                                                  \n",
       "1                                                  0                                                                                  \n",
       "2                                                  0                                                                                  \n",
       "3                                                  0                                                                                  \n",
       "4                                                  0                                                                                  \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-The future of your child(ren)_Not confident at all,)  \\\n",
       "0                                                  0                                                                                             \n",
       "1                                                  0                                                                                             \n",
       "2                                                  0                                                                                             \n",
       "3                                                  0                                                                                             \n",
       "4                                                  0                                                                                             \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-The future of your child(ren)_Not very confident,)  \\\n",
       "0                                                  0                                                                                           \n",
       "1                                                  0                                                                                           \n",
       "2                                                  0                                                                                           \n",
       "3                                                  0                                                                                           \n",
       "4                                                  0                                                                                           \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-The future of your child(ren)_Very confident,)  \\\n",
       "0                                                  0                                                                                       \n",
       "1                                                  0                                                                                       \n",
       "2                                                  0                                                                                       \n",
       "3                                                  0                                                                                       \n",
       "4                                                  0                                                                                       \n",
       "\n",
       "   (Q31- When you think about the next 3 years, for each of the following points are you:-The future of your child(ren)_nan,)  \\\n",
       "0                                                  1                                                                            \n",
       "1                                                  1                                                                            \n",
       "2                                                  1                                                                            \n",
       "3                                                  1                                                                            \n",
       "4                                                  1                                                                            \n",
       "\n",
       "   (Q34- In your personal life, would you say:-I feel well surrounded_Completetly,)  \\\n",
       "0                                                  0                                  \n",
       "1                                                  1                                  \n",
       "2                                                  0                                  \n",
       "3                                                  0                                  \n",
       "4                                                  0                                  \n",
       "\n",
       "   (Q34- In your personal life, would you say:-I feel well surrounded_Not at all,)  \\\n",
       "0                                                  0                                 \n",
       "1                                                  0                                 \n",
       "2                                                  0                                 \n",
       "3                                                  0                                 \n",
       "4                                                  1                                 \n",
       "\n",
       "   (Q34- In your personal life, would you say:-I feel well surrounded_Rather,)  \\\n",
       "0                                                  1                             \n",
       "1                                                  0                             \n",
       "2                                                  0                             \n",
       "3                                                  1                             \n",
       "4                                                  0                             \n",
       "\n",
       "   (Q34- In your personal life, would you say:-I feel well surrounded_Rather not,)  \\\n",
       "0                                                  0                                 \n",
       "1                                                  0                                 \n",
       "2                                                  1                                 \n",
       "3                                                  0                                 \n",
       "4                                                  0                                 \n",
       "\n",
       "   (Q34- In your personal life, would you say:-I feel well surrounded_nan,)  \\\n",
       "0                                                  0                          \n",
       "1                                                  0                          \n",
       "2                                                  0                          \n",
       "3                                                  0                          \n",
       "4                                                  0                          \n",
       "\n",
       "   (Q34- In your personal life, would you say:-One of my loved ones (child/parent/spouse) is causing me a lot of worry_Completetly,)  \\\n",
       "0                                                  0                                                                                   \n",
       "1                                                  0                                                                                   \n",
       "2                                                  0                                                                                   \n",
       "3                                                  0                                                                                   \n",
       "4                                                  1                                                                                   \n",
       "\n",
       "   (Q34- In your personal life, would you say:-One of my loved ones (child/parent/spouse) is causing me a lot of worry_Not at all,)  \\\n",
       "0                                                  1                                                                                  \n",
       "1                                                  1                                                                                  \n",
       "2                                                  0                                                                                  \n",
       "3                                                  0                                                                                  \n",
       "4                                                  0                                                                                  \n",
       "\n",
       "   (Q34- In your personal life, would you say:-One of my loved ones (child/parent/spouse) is causing me a lot of worry_Rather,)  \\\n",
       "0                                                  0                                                                              \n",
       "1                                                  0                                                                              \n",
       "2                                                  0                                                                              \n",
       "3                                                  0                                                                              \n",
       "4                                                  0                                                                              \n",
       "\n",
       "   (Q34- In your personal life, would you say:-One of my loved ones (child/parent/spouse) is causing me a lot of worry_Rather not,)  \\\n",
       "0                                                  0                                                                                  \n",
       "1                                                  0                                                                                  \n",
       "2                                                  1                                                                                  \n",
       "3                                                  1                                                                                  \n",
       "4                                                  0                                                                                  \n",
       "\n",
       "   (Q34- In your personal life, would you say:-One of my loved ones (child/parent/spouse) is causing me a lot of worry_nan,)  \\\n",
       "0                                                  0                                                                           \n",
       "1                                                  0                                                                           \n",
       "2                                                  0                                                                           \n",
       "3                                                  0                                                                           \n",
       "4                                                  0                                                                           \n",
       "\n",
       "   (Q34- In your personal life, would you say:-I have personal concerns (emotional life, money, health_Completetly,)  \\\n",
       "0                                                  0                                                                   \n",
       "1                                                  0                                                                   \n",
       "2                                                  0                                                                   \n",
       "3                                                  0                                                                   \n",
       "4                                                  0                                                                   \n",
       "\n",
       "   (Q34- In your personal life, would you say:-I have personal concerns (emotional life, money, health_Not at all,)  \\\n",
       "0                                                  0                                                                  \n",
       "1                                                  1                                                                  \n",
       "2                                                  1                                                                  \n",
       "3                                                  0                                                                  \n",
       "4                                                  0                                                                  \n",
       "\n",
       "   (Q34- In your personal life, would you say:-I have personal concerns (emotional life, money, health_Rather,)  \\\n",
       "0                                                  0                                                              \n",
       "1                                                  0                                                              \n",
       "2                                                  0                                                              \n",
       "3                                                  0                                                              \n",
       "4                                                  1                                                              \n",
       "\n",
       "   (Q34- In your personal life, would you say:-I have personal concerns (emotional life, money, health_Rather not,)  \\\n",
       "0                                                  1                                                                  \n",
       "1                                                  0                                                                  \n",
       "2                                                  0                                                                  \n",
       "3                                                  1                                                                  \n",
       "4                                                  0                                                                  \n",
       "\n",
       "   (Q34- In your personal life, would you say:-I have personal concerns (emotional life, money, health_nan,)  \\\n",
       "0                                                  0                                                           \n",
       "1                                                  0                                                           \n",
       "2                                                  0                                                           \n",
       "3                                                  0                                                           \n",
       "4                                                  0                                                           \n",
       "\n",
       "   (Q34- In your personal life, would you say:-If there is a problem I can talk to a loved one_Completetly,)  \\\n",
       "0                                                  0                                                           \n",
       "1                                                  0                                                           \n",
       "2                                                  0                                                           \n",
       "3                                                  0                                                           \n",
       "4                                                  0                                                           \n",
       "\n",
       "   (Q34- In your personal life, would you say:-If there is a problem I can talk to a loved one_Not at all,)  \\\n",
       "0                                                  0                                                          \n",
       "1                                                  0                                                          \n",
       "2                                                  0                                                          \n",
       "3                                                  0                                                          \n",
       "4                                                  0                                                          \n",
       "\n",
       "   (Q34- In your personal life, would you say:-If there is a problem I can talk to a loved one_Rather,)  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   (Q34- In your personal life, would you say:-If there is a problem I can talk to a loved one_Rather not,)  \\\n",
       "0                                                  0                                                          \n",
       "1                                                  0                                                          \n",
       "2                                                  0                                                          \n",
       "3                                                  0                                                          \n",
       "4                                                  0                                                          \n",
       "\n",
       "   (Q34- In your personal life, would you say:-If there is a problem I can talk to a loved one_nan,)  \\\n",
       "0                                                  1                                                   \n",
       "1                                                  1                                                   \n",
       "2                                                  1                                                   \n",
       "3                                                  1                                                   \n",
       "4                                                  1                                                   \n",
       "\n",
       "   (Q37- How do you rate your state of health in general?_AVERAGE,)  \\\n",
       "0                                                  0                  \n",
       "1                                                  0                  \n",
       "2                                                  0                  \n",
       "3                                                  0                  \n",
       "4                                                  0                  \n",
       "\n",
       "   (Q37- How do you rate your state of health in general?_Bad,)  \\\n",
       "0                                                  0              \n",
       "1                                                  0              \n",
       "2                                                  0              \n",
       "3                                                  0              \n",
       "4                                                  0              \n",
       "\n",
       "   (Q37- How do you rate your state of health in general?_Good,)  \\\n",
       "0                                                  1               \n",
       "1                                                  1               \n",
       "2                                                  1               \n",
       "3                                                  1               \n",
       "4                                                  1               \n",
       "\n",
       "   (Q37- How do you rate your state of health in general?_Very bad,)  \\\n",
       "0                                                  0                   \n",
       "1                                                  0                   \n",
       "2                                                  0                   \n",
       "3                                                  0                   \n",
       "4                                                  0                   \n",
       "\n",
       "   (Q37- How do you rate your state of health in general?_Very good,)  \\\n",
       "0                                                  0                    \n",
       "1                                                  0                    \n",
       "2                                                  0                    \n",
       "3                                                  0                    \n",
       "4                                                  0                    \n",
       "\n",
       "   (Q37- How do you rate your state of health in general?_nan,)  \\\n",
       "0                                                  0              \n",
       "1                                                  0              \n",
       "2                                                  0              \n",
       "3                                                  0              \n",
       "4                                                  0              \n",
       "\n",
       "   (Q38- Did you:-A chronic illness (a long-term illness or one that recurs frequently_No,)  \\\n",
       "0                                                  1                                          \n",
       "1                                                  1                                          \n",
       "2                                                  0                                          \n",
       "3                                                  0                                          \n",
       "4                                                  1                                          \n",
       "\n",
       "   (Q38- Did you:-A chronic illness (a long-term illness or one that recurs frequently_Yes,)  \\\n",
       "0                                                  0                                           \n",
       "1                                                  0                                           \n",
       "2                                                  1                                           \n",
       "3                                                  1                                           \n",
       "4                                                  0                                           \n",
       "\n",
       "   (Q38- Did you:-A chronic illness (a long-term illness or one that recurs frequently_nan,)  \\\n",
       "0                                                  0                                           \n",
       "1                                                  0                                           \n",
       "2                                                  0                                           \n",
       "3                                                  0                                           \n",
       "4                                                  0                                           \n",
       "\n",
       "   (Q38- Did you:-Disabilities_No,)  (Q38- Did you:-Disabilities_Yes,)  \\\n",
       "0                                 1                                  0   \n",
       "1                                 1                                  0   \n",
       "2                                 1                                  0   \n",
       "3                                 1                                  0   \n",
       "4                                 1                                  0   \n",
       "\n",
       "   (Q38- Did you:-Disabilities_nan,)  \\\n",
       "0                                  0   \n",
       "1                                  0   \n",
       "2                                  0   \n",
       "3                                  0   \n",
       "4                                  0   \n",
       "\n",
       "   (Q42-During the last 12 months have you had a work accident?_No,)  \\\n",
       "0                                                  1                   \n",
       "1                                                  1                   \n",
       "2                                                  1                   \n",
       "3                                                  1                   \n",
       "4                                                  1                   \n",
       "\n",
       "   (Q42-During the last 12 months have you had a work accident?_Yes,)  \\\n",
       "0                                                  0                    \n",
       "1                                                  0                    \n",
       "2                                                  0                    \n",
       "3                                                  0                    \n",
       "4                                                  0                    \n",
       "\n",
       "   (Q42-During the last 12 months have you had a work accident?_nan,)  \\\n",
       "0                                                  0                    \n",
       "1                                                  0                    \n",
       "2                                                  0                    \n",
       "3                                                  0                    \n",
       "4                                                  0                    \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the head_Never,)  \\\n",
       "0                                                  1                                                                                          \n",
       "1                                                  0                                                                                          \n",
       "2                                                  0                                                                                          \n",
       "3                                                  0                                                                                          \n",
       "4                                                  1                                                                                          \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the head_Often,)  \\\n",
       "0                                                  0                                                                                          \n",
       "1                                                  0                                                                                          \n",
       "2                                                  0                                                                                          \n",
       "3                                                  1                                                                                          \n",
       "4                                                  0                                                                                          \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the head_Permanently,)  \\\n",
       "0                                                  0                                                                                                \n",
       "1                                                  0                                                                                                \n",
       "2                                                  0                                                                                                \n",
       "3                                                  0                                                                                                \n",
       "4                                                  0                                                                                                \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the head_Sometimes,)  \\\n",
       "0                                                  0                                                                                              \n",
       "1                                                  1                                                                                              \n",
       "2                                                  1                                                                                              \n",
       "3                                                  0                                                                                              \n",
       "4                                                  0                                                                                              \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the head_nan,)  \\\n",
       "0                                                  0                                                                                        \n",
       "1                                                  0                                                                                        \n",
       "2                                                  0                                                                                        \n",
       "3                                                  0                                                                                        \n",
       "4                                                  0                                                                                        \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the neck, shoulder, arm_Never,)  \\\n",
       "0                                                  1                                                                                                         \n",
       "1                                                  0                                                                                                         \n",
       "2                                                  0                                                                                                         \n",
       "3                                                  0                                                                                                         \n",
       "4                                                  0                                                                                                         \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the neck, shoulder, arm_Often,)  \\\n",
       "0                                                  0                                                                                                         \n",
       "1                                                  0                                                                                                         \n",
       "2                                                  0                                                                                                         \n",
       "3                                                  1                                                                                                         \n",
       "4                                                  1                                                                                                         \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the neck, shoulder, arm_Permanently,)  \\\n",
       "0                                                  0                                                                                                               \n",
       "1                                                  0                                                                                                               \n",
       "2                                                  0                                                                                                               \n",
       "3                                                  0                                                                                                               \n",
       "4                                                  0                                                                                                               \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the neck, shoulder, arm_Sometimes,)  \\\n",
       "0                                                  0                                                                                                             \n",
       "1                                                  1                                                                                                             \n",
       "2                                                  1                                                                                                             \n",
       "3                                                  0                                                                                                             \n",
       "4                                                  0                                                                                                             \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the neck, shoulder, arm_nan,)  \\\n",
       "0                                                  0                                                                                                       \n",
       "1                                                  0                                                                                                       \n",
       "2                                                  0                                                                                                       \n",
       "3                                                  0                                                                                                       \n",
       "4                                                  0                                                                                                       \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the back_Never,)  \\\n",
       "0                                                  1                                                                                          \n",
       "1                                                  0                                                                                          \n",
       "2                                                  0                                                                                          \n",
       "3                                                  0                                                                                          \n",
       "4                                                  0                                                                                          \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the back_Often,)  \\\n",
       "0                                                  0                                                                                          \n",
       "1                                                  0                                                                                          \n",
       "2                                                  0                                                                                          \n",
       "3                                                  1                                                                                          \n",
       "4                                                  1                                                                                          \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the back_Permanently,)  \\\n",
       "0                                                  0                                                                                                \n",
       "1                                                  0                                                                                                \n",
       "2                                                  0                                                                                                \n",
       "3                                                  0                                                                                                \n",
       "4                                                  0                                                                                                \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the back_Sometimes,)  \\\n",
       "0                                                  0                                                                                              \n",
       "1                                                  1                                                                                              \n",
       "2                                                  1                                                                                              \n",
       "3                                                  0                                                                                              \n",
       "4                                                  0                                                                                              \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the back_nan,)  \\\n",
       "0                                                  0                                                                                        \n",
       "1                                                  0                                                                                        \n",
       "2                                                  0                                                                                        \n",
       "3                                                  0                                                                                        \n",
       "4                                                  0                                                                                        \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the leg, foot, knee_Never,)  \\\n",
       "0                                                  0                                                                                                     \n",
       "1                                                  0                                                                                                     \n",
       "2                                                  1                                                                                                     \n",
       "3                                                  0                                                                                                     \n",
       "4                                                  0                                                                                                     \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the leg, foot, knee_Often,)  \\\n",
       "0                                                  1                                                                                                     \n",
       "1                                                  0                                                                                                     \n",
       "2                                                  0                                                                                                     \n",
       "3                                                  1                                                                                                     \n",
       "4                                                  0                                                                                                     \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the leg, foot, knee_Permanently,)  \\\n",
       "0                                                  0                                                                                                           \n",
       "1                                                  1                                                                                                           \n",
       "2                                                  0                                                                                                           \n",
       "3                                                  0                                                                                                           \n",
       "4                                                  1                                                                                                           \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the leg, foot, knee_Sometimes,)  \\\n",
       "0                                                  0                                                                                                         \n",
       "1                                                  0                                                                                                         \n",
       "2                                                  0                                                                                                         \n",
       "3                                                  0                                                                                                         \n",
       "4                                                  0                                                                                                         \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the leg, foot, knee_nan,)  \\\n",
       "0                                                  0                                                                                                   \n",
       "1                                                  0                                                                                                   \n",
       "2                                                  0                                                                                                   \n",
       "3                                                  0                                                                                                   \n",
       "4                                                  0                                                                                                   \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in other parts of the body_Never,)  \\\n",
       "0                                                  1                                                                                                         \n",
       "1                                                  0                                                                                                         \n",
       "2                                                  0                                                                                                         \n",
       "3                                                  0                                                                                                         \n",
       "4                                                  0                                                                                                         \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in other parts of the body_Often,)  \\\n",
       "0                                                  0                                                                                                         \n",
       "1                                                  0                                                                                                         \n",
       "2                                                  0                                                                                                         \n",
       "3                                                  1                                                                                                         \n",
       "4                                                  0                                                                                                         \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in other parts of the body_Permanently,)  \\\n",
       "0                                                  0                                                                                                               \n",
       "1                                                  1                                                                                                               \n",
       "2                                                  0                                                                                                               \n",
       "3                                                  0                                                                                                               \n",
       "4                                                  0                                                                                                               \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in other parts of the body_Sometimes,)  \\\n",
       "0                                                  0                                                                                                             \n",
       "1                                                  0                                                                                                             \n",
       "2                                                  1                                                                                                             \n",
       "3                                                  0                                                                                                             \n",
       "4                                                  1                                                                                                             \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in other parts of the body_nan,)  \\\n",
       "0                                                  0                                                                                                       \n",
       "1                                                  0                                                                                                       \n",
       "2                                                  0                                                                                                       \n",
       "3                                                  0                                                                                                       \n",
       "4                                                  0                                                                                                       \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-to the eyes_Never,)  \\\n",
       "0                                                  0                                                                                          \n",
       "1                                                  0                                                                                          \n",
       "2                                                  0                                                                                          \n",
       "3                                                  0                                                                                          \n",
       "4                                                  0                                                                                          \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-to the eyes_Often,)  \\\n",
       "0                                                  0                                                                                          \n",
       "1                                                  0                                                                                          \n",
       "2                                                  0                                                                                          \n",
       "3                                                  0                                                                                          \n",
       "4                                                  0                                                                                          \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-to the eyes_Permanently,)  \\\n",
       "0                                                  0                                                                                                \n",
       "1                                                  0                                                                                                \n",
       "2                                                  0                                                                                                \n",
       "3                                                  0                                                                                                \n",
       "4                                                  0                                                                                                \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-to the eyes_Sometimes,)  \\\n",
       "0                                                  0                                                                                              \n",
       "1                                                  0                                                                                              \n",
       "2                                                  0                                                                                              \n",
       "3                                                  0                                                                                              \n",
       "4                                                  0                                                                                              \n",
       "\n",
       "   (Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-to the eyes_nan,)  \\\n",
       "0                                                  1                                                                                        \n",
       "1                                                  1                                                                                        \n",
       "2                                                  1                                                                                        \n",
       "3                                                  1                                                                                        \n",
       "4                                                  1                                                                                        \n",
       "\n",
       "   (Q57- How do you most frequently eat your midday meal?_By bringing your meal from home,)  \\\n",
       "0                                                  0                                          \n",
       "1                                                  1                                          \n",
       "2                                                  0                                          \n",
       "3                                                  0                                          \n",
       "4                                                  0                                          \n",
       "\n",
       "   (Q57- How do you most frequently eat your midday meal?_In the canteen or company restaurant,)  \\\n",
       "0                                                  0                                               \n",
       "1                                                  0                                               \n",
       "2                                                  0                                               \n",
       "3                                                  0                                               \n",
       "4                                                  0                                               \n",
       "\n",
       "   (Q57- How do you most frequently eat your midday meal?_When going to a restaurant, brasserie, snack bar,)  \\\n",
       "0                                                  0                                                           \n",
       "1                                                  0                                                           \n",
       "2                                                  0                                                           \n",
       "3                                                  0                                                           \n",
       "4                                                  0                                                           \n",
       "\n",
       "   (Q57- How do you most frequently eat your midday meal?_When returning home,)  \\\n",
       "0                                                  1                              \n",
       "1                                                  0                              \n",
       "2                                                  1                              \n",
       "3                                                  0                              \n",
       "4                                                  1                              \n",
       "\n",
       "   (Q57- How do you most frequently eat your midday meal?_While eating a sandwich,)  \\\n",
       "0                                                  0                                  \n",
       "1                                                  0                                  \n",
       "2                                                  0                                  \n",
       "3                                                  1                                  \n",
       "4                                                  0                                  \n",
       "\n",
       "   (Q57- How do you most frequently eat your midday meal?_nan,)  \\\n",
       "0                                                  0              \n",
       "1                                                  0              \n",
       "2                                                  0              \n",
       "3                                                  0              \n",
       "4                                                  0              \n",
       "\n",
       "   (Q58- For each of these drinks, indicate whether you consume them:-Every day_Alcoholic beverages,)  \\\n",
       "0                                                  1                                                    \n",
       "1                                                  0                                                    \n",
       "2                                                  0                                                    \n",
       "3                                                  0                                                    \n",
       "4                                                  0                                                    \n",
       "\n",
       "   (Q58- For each of these drinks, indicate whether you consume them:-Every day_Energy drinks (like Red Bull or Monster),)  \\\n",
       "0                                                  0                                                                         \n",
       "1                                                  1                                                                         \n",
       "2                                                  0                                                                         \n",
       "3                                                  0                                                                         \n",
       "4                                                  0                                                                         \n",
       "\n",
       "   (Q58- For each of these drinks, indicate whether you consume them:-Every day_Sodas,)  \\\n",
       "0                                                  0                                      \n",
       "1                                                  0                                      \n",
       "2                                                  0                                      \n",
       "3                                                  0                                      \n",
       "4                                                  0                                      \n",
       "\n",
       "   (Q58- For each of these drinks, indicate whether you consume them:-Every day_None,)  \\\n",
       "0                                                  0                                     \n",
       "1                                                  0                                     \n",
       "2                                                  0                                     \n",
       "3                                                  0                                     \n",
       "4                                                  0                                     \n",
       "\n",
       "   (Q58- For each of these drinks, indicate whether you consume them:-Every day_nan,)  \\\n",
       "0                                                  0                                    \n",
       "1                                                  0                                    \n",
       "2                                                  1                                    \n",
       "3                                                  1                                    \n",
       "4                                                  1                                    \n",
       "\n",
       "   (Q58- For each of these drinks, indicate whether you consume them:-At least once a week_Alcoholic beverages,)  \\\n",
       "0                                                  1                                                               \n",
       "1                                                  1                                                               \n",
       "2                                                  0                                                               \n",
       "3                                                  0                                                               \n",
       "4                                                  0                                                               \n",
       "\n",
       "   (Q58- For each of these drinks, indicate whether you consume them:-At least once a week_Energy drinks (like Red Bull or Monster),)  \\\n",
       "0                                                  0                                                                                    \n",
       "1                                                  0                                                                                    \n",
       "2                                                  0                                                                                    \n",
       "3                                                  0                                                                                    \n",
       "4                                                  1                                                                                    \n",
       "\n",
       "   (Q58- For each of these drinks, indicate whether you consume them:-At least once a week_Sodas,)  \\\n",
       "0                                                  0                                                 \n",
       "1                                                  0                                                 \n",
       "2                                                  0                                                 \n",
       "3                                                  0                                                 \n",
       "4                                                  0                                                 \n",
       "\n",
       "   (Q58- For each of these drinks, indicate whether you consume them:-At least once a week_None,)  \\\n",
       "0                                                  0                                                \n",
       "1                                                  0                                                \n",
       "2                                                  0                                                \n",
       "3                                                  0                                                \n",
       "4                                                  0                                                \n",
       "\n",
       "   (Q58- For each of these drinks, indicate whether you consume them:-At least once a week_nan,)  \\\n",
       "0                                                  0                                               \n",
       "1                                                  0                                               \n",
       "2                                                  1                                               \n",
       "3                                                  1                                               \n",
       "4                                                  0                                               \n",
       "\n",
       "   (Q60- Are you a smoker?_No,)  (Q60- Are you a smoker?_Yes,)  \\\n",
       "0                             0                              1   \n",
       "1                             1                              0   \n",
       "2                             1                              0   \n",
       "3                             1                              0   \n",
       "4                             0                              1   \n",
       "\n",
       "   (Q60- Are you a smoker?_nan,)  \\\n",
       "0                              0   \n",
       "1                              0   \n",
       "2                              0   \n",
       "3                              0   \n",
       "4                              0   \n",
       "\n",
       "   (Q61- Do you smoke cannabis, hashish, marijuana?_Every day or almost,)  \\\n",
       "0                                                  0                        \n",
       "1                                                  0                        \n",
       "2                                                  0                        \n",
       "3                                                  0                        \n",
       "4                                                  0                        \n",
       "\n",
       "   (Q61- Do you smoke cannabis, hashish, marijuana?_Less than once a month,)  \\\n",
       "0                                                  0                           \n",
       "1                                                  0                           \n",
       "2                                                  0                           \n",
       "3                                                  0                           \n",
       "4                                                  0                           \n",
       "\n",
       "   (Q61- Do you smoke cannabis, hashish, marijuana?_Never,)  \\\n",
       "0                                                  1          \n",
       "1                                                  1          \n",
       "2                                                  1          \n",
       "3                                                  1          \n",
       "4                                                  1          \n",
       "\n",
       "   (Q61- Do you smoke cannabis, hashish, marijuana?_Once a month,)  \\\n",
       "0                                                  0                 \n",
       "1                                                  0                 \n",
       "2                                                  0                 \n",
       "3                                                  0                 \n",
       "4                                                  0                 \n",
       "\n",
       "   (Q61- Do you smoke cannabis, hashish, marijuana?_Once a week,)  \\\n",
       "0                                                  0                \n",
       "1                                                  0                \n",
       "2                                                  0                \n",
       "3                                                  0                \n",
       "4                                                  0                \n",
       "\n",
       "   (Q61- Do you smoke cannabis, hashish, marijuana?_nan,)  \\\n",
       "0                                                  0        \n",
       "1                                                  0        \n",
       "2                                                  0        \n",
       "3                                                  0        \n",
       "4                                                  0        \n",
       "\n",
       "   (Q62- Do you take sleeping pills, anxiolytics or anti-depressants:_At least once a week,)  \\\n",
       "0                                                  0                                           \n",
       "1                                                  0                                           \n",
       "2                                                  0                                           \n",
       "3                                                  0                                           \n",
       "4                                                  0                                           \n",
       "\n",
       "   (Q62- Do you take sleeping pills, anxiolytics or anti-depressants:_Less than once a month,)  \\\n",
       "0                                                  0                                             \n",
       "1                                                  0                                             \n",
       "2                                                  0                                             \n",
       "3                                                  0                                             \n",
       "4                                                  0                                             \n",
       "\n",
       "   (Q62- Do you take sleeping pills, anxiolytics or anti-depressants:_Never,)  \\\n",
       "0                                                  1                            \n",
       "1                                                  1                            \n",
       "2                                                  1                            \n",
       "3                                                  1                            \n",
       "4                                                  1                            \n",
       "\n",
       "   (Q62- Do you take sleeping pills, anxiolytics or anti-depressants:_Once a month,)  \\\n",
       "0                                                  0                                   \n",
       "1                                                  0                                   \n",
       "2                                                  0                                   \n",
       "3                                                  0                                   \n",
       "4                                                  0                                   \n",
       "\n",
       "   (Q62- Do you take sleeping pills, anxiolytics or anti-depressants:_Several times a month,)  \\\n",
       "0                                                  0                                            \n",
       "1                                                  0                                            \n",
       "2                                                  0                                            \n",
       "3                                                  0                                            \n",
       "4                                                  0                                            \n",
       "\n",
       "   (Q62- Do you take sleeping pills, anxiolytics or anti-depressants:_nan,)  \\\n",
       "0                                                  0                          \n",
       "1                                                  0                          \n",
       "2                                                  0                          \n",
       "3                                                  0                          \n",
       "4                                                  0                          \n",
       "\n",
       "   (Q63- Over the past 12 months have you experienced the following difficulties?-Sleep disorders (difficulty falling asleep, waking up at night, waking up early without being able to go back to sleep, etc.)_Never,)  \\\n",
       "0                                                  0                                                                                                                                                                      \n",
       "1                                                  1                                                                                                                                                                      \n",
       "2                                                  0                                                                                                                                                                      \n",
       "3                                                  0                                                                                                                                                                      \n",
       "4                                                  0                                                                                                                                                                      \n",
       "\n",
       "   (Q63- Over the past 12 months have you experienced the following difficulties?-Sleep disorders (difficulty falling asleep, waking up at night, waking up early without being able to go back to sleep, etc.)_often,)  \\\n",
       "0                                                  0                                                                                                                                                                      \n",
       "1                                                  0                                                                                                                                                                      \n",
       "2                                                  1                                                                                                                                                                      \n",
       "3                                                  0                                                                                                                                                                      \n",
       "4                                                  0                                                                                                                                                                      \n",
       "\n",
       "   (Q63- Over the past 12 months have you experienced the following difficulties?-Sleep disorders (difficulty falling asleep, waking up at night, waking up early without being able to go back to sleep, etc.)_permanently,)  \\\n",
       "0                                                  0                                                                                                                                                                            \n",
       "1                                                  0                                                                                                                                                                            \n",
       "2                                                  0                                                                                                                                                                            \n",
       "3                                                  0                                                                                                                                                                            \n",
       "4                                                  0                                                                                                                                                                            \n",
       "\n",
       "   (Q63- Over the past 12 months have you experienced the following difficulties?-Sleep disorders (difficulty falling asleep, waking up at night, waking up early without being able to go back to sleep, etc.)_sometimes,)  \\\n",
       "0                                                  1                                                                                                                                                                          \n",
       "1                                                  0                                                                                                                                                                          \n",
       "2                                                  0                                                                                                                                                                          \n",
       "3                                                  1                                                                                                                                                                          \n",
       "4                                                  1                                                                                                                                                                          \n",
       "\n",
       "   (Q63- Over the past 12 months have you experienced the following difficulties?-Sleep disorders (difficulty falling asleep, waking up at night, waking up early without being able to go back to sleep, etc.)_nan,)  \\\n",
       "0                                                  0                                                                                                                                                                    \n",
       "1                                                  0                                                                                                                                                                    \n",
       "2                                                  0                                                                                                                                                                    \n",
       "3                                                  0                                                                                                                                                                    \n",
       "4                                                  0                                                                                                                                                                    \n",
       "\n",
       "   (Q63- Over the past 12 months have you experienced the following difficulties?-A lack of tone_Never,)  \\\n",
       "0                                                  0                                                       \n",
       "1                                                  1                                                       \n",
       "2                                                  0                                                       \n",
       "3                                                  0                                                       \n",
       "4                                                  0                                                       \n",
       "\n",
       "   (Q63- Over the past 12 months have you experienced the following difficulties?-A lack of tone_often,)  \\\n",
       "0                                                  0                                                       \n",
       "1                                                  0                                                       \n",
       "2                                                  0                                                       \n",
       "3                                                  1                                                       \n",
       "4                                                  1                                                       \n",
       "\n",
       "   (Q63- Over the past 12 months have you experienced the following difficulties?-A lack of tone_permanently,)  \\\n",
       "0                                                  0                                                             \n",
       "1                                                  0                                                             \n",
       "2                                                  0                                                             \n",
       "3                                                  0                                                             \n",
       "4                                                  0                                                             \n",
       "\n",
       "   (Q63- Over the past 12 months have you experienced the following difficulties?-A lack of tone_sometimes,)  \\\n",
       "0                                                  1                                                           \n",
       "1                                                  0                                                           \n",
       "2                                                  1                                                           \n",
       "3                                                  0                                                           \n",
       "4                                                  0                                                           \n",
       "\n",
       "   (Q63- Over the past 12 months have you experienced the following difficulties?-A lack of tone_nan,)  \n",
       "0                                                  0                                                    \n",
       "1                                                  0                                                    \n",
       "2                                                  0                                                    \n",
       "3                                                  0                                                    \n",
       "4                                                  0                                                    "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/BST_V2toV9.csv\", header=0, sep=\";\")\n",
    "df = pd.DataFrame(main(one_hot=True, dataV=data, retained=True))\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df\n",
    "\n",
    "# Split the data for training and evaluation\n",
    "# X: features with the outcome column removed, where outcome is 0 or 1\n",
    "# y: outcome column\n",
    "\n",
    "# get the rows withs outcome 0 or 1\n",
    "X = data[(data['outcome'] == 0) | (data['outcome'] == 1)].drop('outcome', axis=1, inplace=False)\n",
    "X.columns = [str(i) for i in X.columns]\n",
    "y = data[(data['outcome'] == 0) | (data['outcome'] == 1)]['outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test,score_func, k):\n",
    " fs = SelectKBest(score_func, k=k)\n",
    " fs.fit(X_train, y_train)\n",
    " X_train_fs = fs.transform(X_train)\n",
    " X_test_fs = fs.transform(X_test)\n",
    " return X_train_fs, X_test_fs, fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi Sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 37.304216\n",
      "Feature 1: 9.609575\n",
      "Feature 2: 56.390146\n",
      "Feature 3: 100.338786\n",
      "Feature 4: 20.202416\n",
      "Feature 5: 25.538608\n",
      "Feature 6: 1.949307\n",
      "Feature 7: 111.308462\n",
      "Feature 8: 66.267365\n",
      "Feature 9: 5.615003\n",
      "Feature 10: 73.648381\n",
      "Feature 11: 58.230402\n",
      "Feature 12: 67.409854\n",
      "Feature 13: 0.044400\n",
      "Feature 14: 1.139935\n",
      "Feature 15: 0.133944\n",
      "Feature 16: 22.087948\n",
      "Feature 17: 38.451512\n",
      "Feature 18: nan\n",
      "Feature 19: 0.406987\n",
      "Feature 20: 21.959481\n",
      "Feature 21: 3.682892\n",
      "Feature 22: 0.071547\n",
      "Feature 23: 5.033678\n",
      "Feature 24: 9.165950\n",
      "Feature 25: 2.458128\n",
      "Feature 26: 0.464581\n",
      "Feature 27: 18.127028\n",
      "Feature 28: nan\n",
      "Feature 29: 0.256690\n",
      "Feature 30: 24.232202\n",
      "Feature 31: 5.842533\n",
      "Feature 32: 61.204258\n",
      "Feature 33: 0.268348\n",
      "Feature 34: 0.486014\n",
      "Feature 35: 1.131551\n",
      "Feature 36: 9.014910\n",
      "Feature 37: 2.593681\n",
      "Feature 38: 2.455229\n",
      "Feature 39: 4.522018\n",
      "Feature 40: 3.803984\n",
      "Feature 41: 17.605139\n",
      "Feature 42: 8.441646\n",
      "Feature 43: 2.460109\n",
      "Feature 44: 15.436807\n",
      "Feature 45: 2.879989\n",
      "Feature 46: 1.857699\n",
      "Feature 47: 7.181245\n",
      "Feature 48: 0.035299\n",
      "Feature 49: 4.626352\n",
      "Feature 50: 37.735206\n",
      "Feature 51: 7.748746\n",
      "Feature 52: 19.184095\n",
      "Feature 53: 0.088249\n",
      "Feature 54: 32.876274\n",
      "Feature 55: 12.662834\n",
      "Feature 56: 0.007039\n",
      "Feature 57: 100.305388\n",
      "Feature 58: 5.820386\n",
      "Feature 59: 13.548399\n",
      "Feature 60: 24.286526\n",
      "Feature 61: 46.672134\n",
      "Feature 62: 7.233090\n",
      "Feature 63: 0.610680\n",
      "Feature 64: 1.533671\n",
      "Feature 65: 7.132523\n",
      "Feature 66: 31.521907\n",
      "Feature 67: 17.646175\n",
      "Feature 68: 1.365318\n",
      "Feature 69: 0.815529\n",
      "Feature 70: 0.389017\n",
      "Feature 71: 0.309465\n",
      "Feature 72: 0.002276\n",
      "Feature 73: 0.225670\n",
      "Feature 74: 2.641667\n",
      "Feature 75: 68.038948\n",
      "Feature 76: 51.687014\n",
      "Feature 77: 23.576238\n",
      "Feature 78: 21.405996\n",
      "Feature 79: 6.207116\n",
      "Feature 80: 11.112825\n",
      "Feature 81: 15.431493\n",
      "Feature 82: 14.528739\n",
      "Feature 83: 1.695974\n",
      "Feature 84: 0.315026\n",
      "Feature 85: 4.206003\n",
      "Feature 86: 4.944377\n",
      "Feature 87: 0.080889\n",
      "Feature 88: 0.290163\n",
      "Feature 89: 0.423307\n",
      "Feature 90: 2.026613\n",
      "Feature 91: 4.233844\n",
      "Feature 92: 5.174276\n",
      "Feature 93: 1.489264\n",
      "Feature 94: 4.912260\n",
      "Feature 95: 5.105929\n",
      "Feature 96: 4.400244\n",
      "Feature 97: 16.553873\n",
      "Feature 98: 6.789618\n",
      "Feature 99: 1.873635\n",
      "Feature 100: 5.331550\n",
      "Feature 101: 3.633729\n",
      "Feature 102: 0.333995\n",
      "Feature 103: 1.882982\n",
      "Feature 104: 1.254465\n",
      "Feature 105: 1.682161\n",
      "Feature 106: 2.170881\n",
      "Feature 107: 7.634368\n",
      "Feature 108: 14.341741\n",
      "Feature 109: 1.866093\n",
      "Feature 110: 5.379573\n",
      "Feature 111: 4.209378\n",
      "Feature 112: 15.453148\n",
      "Feature 113: 26.152974\n",
      "Feature 114: 0.649309\n",
      "Feature 115: 10.643393\n",
      "Feature 116: 0.878039\n",
      "Feature 117: 10.502755\n",
      "Feature 118: 11.987558\n",
      "Feature 119: 12.667518\n",
      "Feature 120: 8.759566\n",
      "Feature 121: 5.092302\n",
      "Feature 122: 8.177955\n",
      "Feature 123: 21.595293\n",
      "Feature 124: 2.863611\n",
      "Feature 125: 6.168749\n",
      "Feature 126: 1.384354\n",
      "Feature 127: 14.067315\n",
      "Feature 128: 0.001245\n",
      "Feature 129: 0.901996\n",
      "Feature 130: 8.544113\n",
      "Feature 131: 2.724713\n",
      "Feature 132: 12.158992\n",
      "Feature 133: 0.290051\n",
      "Feature 134: 0.967137\n",
      "Feature 135: 11.306495\n",
      "Feature 136: 4.673203\n",
      "Feature 137: 1.658132\n",
      "Feature 138: 23.043611\n",
      "Feature 139: 22.582411\n",
      "Feature 140: 1.274519\n",
      "Feature 141: 3.244116\n",
      "Feature 142: 12.292121\n",
      "Feature 143: 0.212612\n",
      "Feature 144: 0.130098\n",
      "Feature 145: 7.895503\n",
      "Feature 146: 4.308750\n",
      "Feature 147: 0.915076\n",
      "Feature 148: 5.046918\n",
      "Feature 149: 0.059669\n",
      "Feature 150: 4.352634\n",
      "Feature 151: 4.893852\n",
      "Feature 152: 0.000356\n",
      "Feature 153: 2.269291\n",
      "Feature 154: 0.082272\n",
      "Feature 155: 0.284184\n",
      "Feature 156: 1.299542\n",
      "Feature 157: 6.359828\n",
      "Feature 158: 4.725873\n",
      "Feature 159: 3.808187\n",
      "Feature 160: 0.022441\n",
      "Feature 161: 1.539155\n",
      "Feature 162: 0.400633\n",
      "Feature 163: 13.277732\n",
      "Feature 164: 1.711475\n",
      "Feature 165: 0.000328\n",
      "Feature 166: 4.417207\n",
      "Feature 167: 6.174499\n",
      "Feature 168: 1.129953\n",
      "Feature 169: 0.588978\n",
      "Feature 170: 10.513626\n",
      "Feature 171: 4.999339\n",
      "Feature 172: 19.470766\n",
      "Feature 173: 0.503749\n",
      "Feature 174: 0.191769\n",
      "Feature 175: 21.149828\n",
      "Feature 176: 3.600671\n",
      "Feature 177: 1.136659\n",
      "Feature 178: 9.542341\n",
      "Feature 179: 1.055058\n",
      "Feature 180: 3.628407\n",
      "Feature 181: 6.476110\n",
      "Feature 182: 2.184498\n",
      "Feature 183: 4.515810\n",
      "Feature 184: 2.723029\n",
      "Feature 185: 27.647421\n",
      "Feature 186: 8.241708\n",
      "Feature 187: 15.676357\n",
      "Feature 188: 6.995826\n",
      "Feature 189: 22.523395\n",
      "Feature 190: 1.291181\n",
      "Feature 191: 124.148226\n",
      "Feature 192: 15.255011\n",
      "Feature 193: 3.755862\n",
      "Feature 194: 24.087329\n",
      "Feature 195: 1.301652\n",
      "Feature 196: 123.767007\n",
      "Feature 197: 92.204816\n",
      "Feature 198: 11.702082\n",
      "Feature 199: 9.597363\n",
      "Feature 200: 3.981686\n",
      "Feature 201: 5.274950\n",
      "Feature 202: 13.750722\n",
      "Feature 203: 0.081805\n",
      "Feature 204: 3.483615\n",
      "Feature 205: 51.000640\n",
      "Feature 206: 4.705753\n",
      "Feature 207: 0.020476\n",
      "Feature 208: 0.136227\n",
      "Feature 209: 13.937922\n",
      "Feature 210: 64.326697\n",
      "Feature 211: 5.473792\n",
      "Feature 212: 45.673049\n",
      "Feature 213: 0.279593\n",
      "Feature 214: 199.238232\n",
      "Feature 215: 36.545522\n",
      "Feature 216: 0.002975\n",
      "Feature 217: 200.042355\n",
      "Feature 218: 22.706857\n",
      "Feature 219: 6.112110\n",
      "Feature 220: 196.001369\n",
      "Feature 221: 30.148357\n",
      "Feature 222: 0.749664\n",
      "Feature 223: 193.952395\n",
      "Feature 224: 21.357970\n",
      "Feature 225: 4.845237\n",
      "Feature 226: 190.845967\n",
      "Feature 227: 22.293941\n",
      "Feature 228: 4.326943\n",
      "Feature 229: 192.267617\n",
      "Feature 230: 41.514631\n",
      "Feature 231: 1.740031\n",
      "Feature 232: 197.265903\n",
      "Feature 233: 45.713879\n",
      "Feature 234: 0.104658\n",
      "Feature 235: 185.718675\n",
      "Feature 236: 60.235829\n",
      "Feature 237: 1.064890\n",
      "Feature 238: 125.793217\n",
      "Feature 239: 47.537814\n",
      "Feature 240: 4.224059\n",
      "Feature 241: 127.572512\n",
      "Feature 242: 49.475818\n",
      "Feature 243: 3.477510\n",
      "Feature 244: 127.727870\n",
      "Feature 245: 36.377081\n",
      "Feature 246: 4.900330\n",
      "Feature 247: 125.875702\n",
      "Feature 248: 24.437876\n",
      "Feature 249: 18.305225\n",
      "Feature 250: 129.241275\n",
      "Feature 251: 41.374607\n",
      "Feature 252: 3.160746\n",
      "Feature 253: 126.334103\n",
      "Feature 254: 38.877457\n",
      "Feature 255: 13.087081\n",
      "Feature 256: 124.835174\n",
      "Feature 257: 16.494562\n",
      "Feature 258: 31.803519\n",
      "Feature 259: 127.306132\n",
      "Feature 260: 29.800182\n",
      "Feature 261: 11.835474\n",
      "Feature 262: 127.225043\n",
      "Feature 263: 22.047328\n",
      "Feature 264: 4.900680\n",
      "Feature 265: 25.009009\n",
      "Feature 266: 0.456573\n",
      "Feature 267: 17.313522\n",
      "Feature 268: 4.277289\n",
      "Feature 269: 4.732891\n",
      "Feature 270: 1.443735\n",
      "Feature 271: 19.973035\n",
      "Feature 272: 9.805712\n",
      "Feature 273: 1.020085\n",
      "Feature 274: 2.848017\n",
      "Feature 275: 0.765872\n",
      "Feature 276: 7.831536\n",
      "Feature 277: 0.073012\n",
      "Feature 278: 0.134001\n",
      "Feature 279: 0.162121\n",
      "Feature 280: 0.001796\n",
      "Feature 281: 0.000148\n",
      "Feature 282: 0.000000\n",
      "Feature 283: 62.797681\n",
      "Feature 284: 7.636382\n",
      "Feature 285: 1.817632\n",
      "Feature 286: 11.021638\n",
      "Feature 287: 1.205940\n",
      "Feature 288: 32.064256\n",
      "Feature 289: 4.038070\n",
      "Feature 290: 14.286824\n",
      "Feature 291: 0.267366\n",
      "Feature 292: 4.383324\n",
      "Feature 293: 12.715228\n",
      "Feature 294: 10.539070\n",
      "Feature 295: 7.936884\n",
      "Feature 296: 17.321882\n",
      "Feature 297: 125.880554\n",
      "Feature 298: 14.146014\n",
      "Feature 299: 4.562884\n",
      "Feature 300: 17.093261\n",
      "Feature 301: 7.162332\n",
      "Feature 302: 125.800815\n",
      "Feature 303: 22.683752\n",
      "Feature 304: 1.406732\n",
      "Feature 305: 2.237164\n",
      "Feature 306: 16.271301\n",
      "Feature 307: 125.913178\n",
      "Feature 308: 29.591909\n",
      "Feature 309: 9.765292\n",
      "Feature 310: 2.029639\n",
      "Feature 311: 5.638511\n",
      "Feature 312: 128.350546\n",
      "Feature 313: 22.604950\n",
      "Feature 314: 1.949644\n",
      "Feature 315: 3.049856\n",
      "Feature 316: 18.742652\n",
      "Feature 317: 123.880675\n",
      "Feature 318: 10.716341\n",
      "Feature 319: 12.042257\n",
      "Feature 320: 13.899348\n",
      "Feature 321: 8.292829\n",
      "Feature 322: 106.056824\n",
      "Feature 323: 0.264128\n",
      "Feature 324: 2.024910\n",
      "Feature 325: 1.228199\n",
      "Feature 326: 3.812600\n",
      "Feature 327: 3.389582\n",
      "Feature 328: 0.070511\n",
      "Feature 329: 7.925897\n",
      "Feature 330: 1.631710\n",
      "Feature 331: 6.680407\n",
      "Feature 332: 3.571286\n",
      "Feature 333: 3.758058\n",
      "Feature 334: 21.188428\n",
      "Feature 335: 8.692958\n",
      "Feature 336: 1.140424\n",
      "Feature 337: 6.125904\n",
      "Feature 338: 0.220734\n",
      "Feature 339: 14.797955\n",
      "Feature 340: 11.402449\n",
      "Feature 341: 16.615763\n",
      "Feature 342: 186.088003\n",
      "Feature 343: 20.548037\n",
      "Feature 344: 7.964259\n",
      "Feature 345: 0.973182\n",
      "Feature 346: 1.125491\n",
      "Feature 347: 19.399262\n",
      "Feature 348: 4.652643\n",
      "Feature 349: 4.780480\n",
      "Feature 350: 29.942019\n",
      "Feature 351: 6.119975\n",
      "Feature 352: 0.002396\n",
      "Feature 353: 0.039633\n",
      "Feature 354: 0.845950\n",
      "Feature 355: 2.209885\n",
      "Feature 356: 100.206298\n",
      "Feature 357: 4.102697\n",
      "Feature 358: 78.985332\n",
      "Feature 359: 87.822126\n",
      "Feature 360: 6.768260\n",
      "Feature 361: 0.100233\n",
      "Feature 362: 7.682751\n",
      "Feature 363: 39.228939\n",
      "Feature 364: 36.175854\n",
      "Feature 365: 5.244497\n",
      "Feature 366: 0.566199\n",
      "Feature 367: 10.364018\n",
      "Feature 368: 45.218284\n",
      "Feature 369: 26.686874\n",
      "Feature 370: 13.289846\n",
      "Feature 371: 0.256775\n",
      "Feature 372: 8.255282\n",
      "Feature 373: 13.763529\n",
      "Feature 374: 7.252126\n",
      "Feature 375: 0.263168\n",
      "Feature 376: 6.785504\n",
      "Feature 377: 2.344832\n",
      "Feature 378: 16.689580\n",
      "Feature 379: 3.714009\n",
      "Feature 380: 0.077065\n",
      "Feature 381: 21.003660\n",
      "Feature 382: 2.483704\n",
      "Feature 383: 101.341032\n",
      "Feature 384: 35.156655\n",
      "Feature 385: 6.190894\n",
      "Feature 386: 1.261529\n",
      "Feature 387: 188.440190\n",
      "Feature 388: 18.514767\n",
      "Feature 389: 20.048725\n",
      "Feature 390: 14.203012\n",
      "Feature 391: 100.268985\n",
      "Feature 392: 1.204385\n",
      "Feature 393: 8.492349\n",
      "Feature 394: 19.824088\n",
      "Feature 395: 5.851343\n",
      "Feature 396: 12.276508\n",
      "Feature 397: 9.572941\n",
      "Feature 398: 1.624321\n",
      "Feature 399: 1.924298\n",
      "Feature 400: 0.929511\n",
      "Feature 401: 8.695281\n",
      "Feature 402: 1.058248\n",
      "Feature 403: 7.447503\n",
      "Feature 404: 0.219265\n",
      "Feature 405: 1.206228\n",
      "Feature 406: 4.355490\n",
      "Feature 407: 19.385008\n",
      "Feature 408: 20.211973\n",
      "Feature 409: 2.660282\n",
      "Feature 410: 7.368138\n",
      "Feature 411: 9.942525\n",
      "Feature 412: 6.353267\n",
      "Feature 413: 3.410233\n",
      "Feature 414: 41.335739\n",
      "Feature 415: 4.951551\n",
      "Feature 416: 4.958454\n",
      "Feature 417: 8.154247\n",
      "Feature 418: 2.624499\n",
      "Feature 419: 52.047037\n",
      "Feature 420: 15.232011\n",
      "Feature 421: 3.175435\n",
      "Feature 422: 5.298595\n",
      "Feature 423: 6.899035\n",
      "Feature 424: 125.072565\n",
      "Feature 425: 87.789096\n",
      "Feature 426: 4.250025\n",
      "Feature 427: 1.160417\n",
      "Feature 428: 10.062136\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test, chi2, 'all')\n",
    "# what are scores for the features\n",
    "for i in range(len(fs.scores_)):\n",
    " print('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "# plot the scores\n",
    "plt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "plt.savefig('outputs/00_feature_select_29/feat_imp_chi2.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 0.0\n",
      "max: 200.04235488377833\n"
     ]
    }
   ],
   "source": [
    "# get the scores for the features and remove the nan values\n",
    "scores = []\n",
    "for i in range(len(fs.scores_)):\n",
    "    if np.isnan(fs.scores_[i]):\n",
    "        continue\n",
    "    else:\n",
    "        scores.append(fs.scores_[i])\n",
    "\n",
    "# get the min and max scores\n",
    "min_chi2_imp = min(scores)\n",
    "max_chi2_imp = max(scores)\n",
    "print(f\"min: {min_chi2_imp}\")\n",
    "print(f\"max: {max_chi2_imp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features with scores above the threshold_chi2: 426\n"
     ]
    }
   ],
   "source": [
    "# sort the scores in descending order\n",
    "scores.sort(reverse=True)\n",
    "\n",
    "# get the threshold_chi2\n",
    "\n",
    "threshold_chi2 = 0\n",
    "# plot the scores\n",
    "# draw a vertical line at the threshold_chi2\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.bar([i for i in range(len(scores))], scores)\n",
    "plt.axhline(y=threshold_chi2, color='r', linestyle='-')\n",
    "plt.savefig('outputs/00_feature_select_29/feat_imp_chi2_sorted.png')\n",
    "plt.show()\n",
    "\n",
    "# get the number of features with scores above the threshold\n",
    "\n",
    "num_features = len([i for i in scores if i > threshold_chi2])\n",
    "print(f\"number of features with scores above the threshold_chi2: {num_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test, chi2, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest 1/1 trained with \n",
      "F1 score: 0.4682439037330047 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6864088195895977 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.92      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.88      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/1: 0 minutes and 4 seconds\n",
      "average test accuracy: 0.8376216968011126\n"
     ]
    }
   ],
   "source": [
    "models, test_accuracies = train_random_forests(X_train_fs, y_train, X_test_fs, y_test)\n",
    "print(f\"average test accuracy: {np.mean(test_accuracies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range: 200.04235488377833\n"
     ]
    }
   ],
   "source": [
    "# difference between the max and threshold scores\n",
    "range_chi2 =  max_chi2_imp - threshold_chi2\n",
    "print(f\"Range: {range_chi2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\n",
      "\n",
      "Threshold: 0.0\n",
      "number of features with scores above the threshold: 426\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4682439037330047 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6864088195895977 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.92      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.88      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 4 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47038758219524535 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6855950812472552 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.93      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.89      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 4 seconds\n",
      "1:\n",
      "\n",
      "Threshold: 0.2\n",
      "number of features with scores above the threshold: 395\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4724538500360015 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6789595860534076 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.89      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.86      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 4 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4691196603547202 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6808850188712889 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.76      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 4 seconds\n",
      "2:\n",
      "\n",
      "Threshold: 0.4001\n",
      "number of features with scores above the threshold: 377\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47032079024673057 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6933246599150489 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.88      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.86      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 4 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4713205607772173 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6852256904888484 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.83      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 4 seconds\n",
      "3:\n",
      "\n",
      "Threshold: 0.6001\n",
      "number of features with scores above the threshold: 368\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47032079024673057 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6832555697544256 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.88      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.86      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 4 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47145622263634096 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6857178079146042 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.94      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.89      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 4 seconds\n",
      "4:\n",
      "\n",
      "Threshold: 0.8002\n",
      "number of features with scores above the threshold: 364\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47138837975491366 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6832392795779523 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.88      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.86      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 4 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47125276559559703 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6890536618225406 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.79      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 4 seconds\n",
      "5:\n",
      "\n",
      "Threshold: 1.0002\n",
      "number of features with scores above the threshold: 356\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47012054453691526 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6859242969082786 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 4 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4724538500360015 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6817509298058497 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.89      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.86      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 4 seconds\n",
      "6:\n",
      "\n",
      "Threshold: 1.2003\n",
      "number of features with scores above the threshold: 345\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4702540200548168 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6864015550514405 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.82      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.83      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 4 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47118499410283154 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6812668473995704 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.75      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 4 seconds\n",
      "7:\n",
      "\n",
      "Threshold: 1.4003\n",
      "number of features with scores above the threshold: 333\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47012054453691526 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6791655247032823 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 4 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4734473042884878 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6820146545547003 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.85      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 4 seconds\n",
      "8:\n",
      "\n",
      "Threshold: 1.6003\n",
      "number of features with scores above the threshold: 328\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4701872715184332 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.691116130246565 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.78      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 4 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4734473042884878 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.689211390355555 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.85      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "9:\n",
      "\n",
      "Threshold: 1.8004\n",
      "number of features with scores above the threshold: 321\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4723161491956597 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6829308669125601 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.80      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4723849866542789 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6931879545151856 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.84      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "10:\n",
      "\n",
      "Threshold: 2.0004\n",
      "number of features with scores above the threshold: 313\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47118499410283154 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.689766136905725 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.75      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47032079024673057 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6863280291197911 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.88      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.86      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "11:\n",
      "\n",
      "Threshold: 2.2005\n",
      "number of features with scores above the threshold: 308\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47012054453691526 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6893920131906401 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47330758142946133 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6865851497430445 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.77      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "12:\n",
      "\n",
      "Threshold: 2.4005\n",
      "number of features with scores above the threshold: 304\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47125276559559703 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6860763018657755 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.79      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47012054453691526 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6815473025999341 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "13:\n",
      "\n",
      "Threshold: 2.6006\n",
      "number of features with scores above the threshold: 299\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4733774289007111 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6856217178871641 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.81      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47012054453691526 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.685127949430009 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "14:\n",
      "\n",
      "Threshold: 2.8006\n",
      "number of features with scores above the threshold: 294\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47125276559559703 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6859021730875278 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.79      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47012054453691526 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6920728479080881 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "15:\n",
      "\n",
      "Threshold: 3.0006\n",
      "number of features with scores above the threshold: 291\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47125276559559703 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6841206001389066 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.79      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47012054453691526 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6887125587354421 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "16:\n",
      "\n",
      "Threshold: 3.2007\n",
      "number of features with scores above the threshold: 288\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47118499410283154 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6861802067751724 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.75      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47217855159329725 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6921041074359153 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.73      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.78      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "17:\n",
      "\n",
      "Threshold: 3.4007\n",
      "number of features with scores above the threshold: 286\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4723161491956597 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6884898896340543 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.80      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4733774289007111 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6791514359020079 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.81      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "18:\n",
      "\n",
      "Threshold: 3.6008\n",
      "number of features with scores above the threshold: 281\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4744366112656254 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6931455780426032 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.82      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.83      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4691196603547202 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6824857488473048 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.76      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "19:\n",
      "\n",
      "Threshold: 3.8008\n",
      "number of features with scores above the threshold: 275\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.46898832347823344 \n",
      "test accuracy: 0.8369 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6877285440214501 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.68      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.76      0.51      0.47      5752\n",
      "weighted avg       0.81      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4723849866542789 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6759047376896347 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.84      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "20:\n",
      "\n",
      "Threshold: 4.0008\n",
      "number of features with scores above the threshold: 271\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4722473375464208 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6787993259389141 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.76      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4724538500360015 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6856601318843881 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.89      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.86      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "21:\n",
      "\n",
      "Threshold: 4.2009\n",
      "number of features with scores above the threshold: 269\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47457845938131593 \n",
      "test accuracy: 0.8385 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.685568884882386 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.90      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.87      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47450752025500137 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6870466680535329 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.86      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.85      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "22:\n",
      "\n",
      "Threshold: 4.4009\n",
      "number of features with scores above the threshold: 257\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4713205607772173 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6838649104095328 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.83      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47118499410283154 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6863174625188355 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.75      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "23:\n",
      "\n",
      "Threshold: 4.601\n",
      "number of features with scores above the threshold: 253\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.46905398225964917 \n",
      "test accuracy: 0.8371 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6819780016576354 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.72      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.78      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4735172077129607 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6884358458729167 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.89      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.87      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "24:\n",
      "\n",
      "Threshold: 4.801\n",
      "number of features with scores above the threshold: 246\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4713205607772173 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6852319644081657 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.83      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4723161491956597 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6844087601524672 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.80      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "25:\n",
      "\n",
      "Threshold: 5.0011\n",
      "number of features with scores above the threshold: 237\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47125276559559703 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6927316094364149 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.79      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4744366112656254 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6830364228533565 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.82      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.83      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "26:\n",
      "\n",
      "Threshold: 5.2011\n",
      "number of features with scores above the threshold: 232\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4723161491956597 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6904971035405817 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.80      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4724538500360015 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6835094983836403 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.89      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.86      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "27:\n",
      "\n",
      "Threshold: 5.4011\n",
      "number of features with scores above the threshold: 227\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.46898832347823344 \n",
      "test accuracy: 0.8369 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6770146710650142 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.68      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.76      0.51      0.47      5752\n",
      "weighted avg       0.81      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4713205607772173 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.682290486867146 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.83      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "28:\n",
      "\n",
      "Threshold: 5.6012\n",
      "number of features with scores above the threshold: 226\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4722473375464208 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6771608423782337 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.76      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4713205607772173 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6870316987021792 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.83      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "29:\n",
      "\n",
      "Threshold: 5.8012\n",
      "number of features with scores above the threshold: 224\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4731679697582828 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6929104711713407 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.71      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.77      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4723161491956597 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6837782862954488 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.80      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "30:\n",
      "\n",
      "Threshold: 6.0013\n",
      "number of features with scores above the threshold: 221\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4722473375464208 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6886919758773306 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.76      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47118499410283154 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6765076943566646 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.75      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "31:\n",
      "\n",
      "Threshold: 6.2013\n",
      "number of features with scores above the threshold: 215\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4722473375464208 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6822459090193644 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.76      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4733774289007111 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6883723361984231 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.81      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "32:\n",
      "\n",
      "Threshold: 6.4014\n",
      "number of features with scores above the threshold: 212\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4713205607772173 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6903400354201269 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.83      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4723161491956597 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.689667295159286 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.80      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "33:\n",
      "\n",
      "Threshold: 6.6014\n",
      "number of features with scores above the threshold: 211\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4713205607772173 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6783949333148418 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.83      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4734473042884878 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6925584712770068 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.85      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "34:\n",
      "\n",
      "Threshold: 6.8014\n",
      "number of features with scores above the threshold: 207\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4701872715184332 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6812388899345421 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.78      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4701872715184332 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6840832868292823 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.78      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "35:\n",
      "\n",
      "Threshold: 7.0015\n",
      "number of features with scores above the threshold: 205\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4691853578571201 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6880644738768309 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.81      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.83      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4734473042884878 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6875781900953525 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.85      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "36:\n",
      "\n",
      "Threshold: 7.2015\n",
      "number of features with scores above the threshold: 202\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47118499410283154 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6862233537290745 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.75      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4723161491956597 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6790925491154323 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.80      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "37:\n",
      "\n",
      "Threshold: 7.4016\n",
      "number of features with scores above the threshold: 199\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47118499410283154 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6781217426526351 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.75      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4734473042884878 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6781633486438978 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.85      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "38:\n",
      "\n",
      "Threshold: 7.6016\n",
      "number of features with scores above the threshold: 198\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4731679697582828 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6828367581227994 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.71      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.77      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47323776175505317 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.68698172748516 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "39:\n",
      "\n",
      "Threshold: 7.8017\n",
      "number of features with scores above the threshold: 194\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47012054453691526 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6932887774993037 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47012054453691526 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6836313445009098 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "40:\n",
      "\n",
      "Threshold: 8.0017\n",
      "number of features with scores above the threshold: 189\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4744366112656254 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6819400279354513 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.82      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.83      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4723161491956597 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6863030435112816 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.80      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "41:\n",
      "\n",
      "Threshold: 8.2017\n",
      "number of features with scores above the threshold: 187\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4744366112656254 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6867523441894151 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.82      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.83      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4713205607772173 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6855038342452531 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.83      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "42:\n",
      "\n",
      "Threshold: 8.4018\n",
      "number of features with scores above the threshold: 184\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4711172461921304 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6810933790338825 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.71      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.78      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4723849866542789 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6819939616278289 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.84      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "43:\n",
      "\n",
      "Threshold: 8.6018\n",
      "number of features with scores above the threshold: 181\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4713205607772173 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6859950711209293 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.83      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4701872715184332 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6788687793264453 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.78      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "44:\n",
      "\n",
      "Threshold: 8.8019\n",
      "number of features with scores above the threshold: 178\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4701872715184332 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6893421520423808 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.78      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4733774289007111 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6835837947966094 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.81      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "45:\n",
      "\n",
      "Threshold: 9.0019\n",
      "number of features with scores above the threshold: 178\n",
      "46:\n",
      "\n",
      "Threshold: 9.2019\n",
      "number of features with scores above the threshold: 176\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47450752025500137 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6847922397121482 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.86      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.85      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4711172461921304 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.689216563587273 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.71      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.78      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "47:\n",
      "\n",
      "Threshold: 9.402\n",
      "number of features with scores above the threshold: 176\n",
      "48:\n",
      "\n",
      "Threshold: 9.602\n",
      "number of features with scores above the threshold: 173\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47032079024673057 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6863067858491199 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.88      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.86      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47330758142946133 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6804828276224156 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.77      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "49:\n",
      "\n",
      "Threshold: 9.8021\n",
      "number of features with scores above the threshold: 171\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47032079024673057 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6774782806819419 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.88      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.86      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47457845938131593 \n",
      "test accuracy: 0.8385 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6847676943786785 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.90      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.87      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "50:\n",
      "\n",
      "Threshold: 10.0021\n",
      "number of features with scores above the threshold: 169\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47125276559559703 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6791161038300626 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.79      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4722473375464208 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6898002582213109 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.76      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "51:\n",
      "\n",
      "Threshold: 10.2022\n",
      "number of features with scores above the threshold: 168\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4724538500360015 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6828894810588174 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.89      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.86      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4733774289007111 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6822478902570436 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.81      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "52:\n",
      "\n",
      "Threshold: 10.4022\n",
      "number of features with scores above the threshold: 167\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4702540200548168 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6785119364066733 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.82      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.83      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4735172077129607 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6817227522033015 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.89      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.87      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "53:\n",
      "\n",
      "Threshold: 10.6022\n",
      "number of features with scores above the threshold: 164\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47252273945501033 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.68580035948457 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.94      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.89      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4724538500360015 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6835972231853238 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.89      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.86      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "54:\n",
      "\n",
      "Threshold: 10.8023\n",
      "number of features with scores above the threshold: 162\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47138837975491366 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6842344112366995 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.88      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.86      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4788025369266434 \n",
      "test accuracy: 0.8392 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6772679392816693 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.92      0.02      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.88      0.51      0.48      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "55:\n",
      "\n",
      "Threshold: 11.0023\n",
      "number of features with scores above the threshold: 162\n",
      "56:\n",
      "\n",
      "Threshold: 11.2024\n",
      "number of features with scores above the threshold: 160\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4734473042884878 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6810289888093092 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.85      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4724538500360015 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6887682535279789 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.89      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.86      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "57:\n",
      "\n",
      "Threshold: 11.4024\n",
      "number of features with scores above the threshold: 159\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4711172461921304 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6877495671546014 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.71      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.78      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4734473042884878 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6842635794580876 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.85      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "58:\n",
      "\n",
      "Threshold: 11.6025\n",
      "number of features with scores above the threshold: 158\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4702540200548168 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6828535986430723 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.82      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.83      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4713205607772173 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6899228748198999 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.83      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "59:\n",
      "\n",
      "Threshold: 11.8025\n",
      "number of features with scores above the threshold: 157\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47450752025500137 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6865840490554449 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.86      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.85      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4723849866542789 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6835865465156084 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.84      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "60:\n",
      "\n",
      "Threshold: 12.0025\n",
      "number of features with scores above the threshold: 155\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47138837975491366 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.686960154008209 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.88      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.86      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4713205607772173 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6888872378574895 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.83      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "61:\n",
      "\n",
      "Threshold: 12.2026\n",
      "number of features with scores above the threshold: 153\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4711172461921304 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6883193931248851 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.71      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.78      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4733774289007111 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6812458242664193 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.81      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "62:\n",
      "\n",
      "Threshold: 12.4026\n",
      "number of features with scores above the threshold: 151\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47252273945501033 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.68531803817845 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.94      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.89      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4734473042884878 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6944799416195298 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.85      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "63:\n",
      "\n",
      "Threshold: 12.6027\n",
      "number of features with scores above the threshold: 151\n",
      "64:\n",
      "\n",
      "Threshold: 12.8027\n",
      "number of features with scores above the threshold: 148\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4734473042884878 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6800060097542935 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.85      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47429488319195484 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6781271360218729 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.75      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "65:\n",
      "\n",
      "Threshold: 13.0028\n",
      "number of features with scores above the threshold: 148\n",
      "66:\n",
      "\n",
      "Threshold: 13.2028\n",
      "number of features with scores above the threshold: 147\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4713205607772173 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6851552464824776 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.83      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4711172461921304 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6919228241882703 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.71      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.78      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "67:\n",
      "\n",
      "Threshold: 13.4028\n",
      "number of features with scores above the threshold: 145\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4723849866542789 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6810877655271249 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.84      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47556564110178945 \n",
      "test accuracy: 0.8385 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6905556601208775 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.86      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.85      0.51      0.48      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "68:\n",
      "\n",
      "Threshold: 13.6029\n",
      "number of features with scores above the threshold: 144\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4711172461921304 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6828025267384535 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.71      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.78      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4723161491956597 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6883519734778316 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.80      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "69:\n",
      "\n",
      "Threshold: 13.8029\n",
      "number of features with scores above the threshold: 142\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4752780799846063 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6827560777217527 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.73      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.78      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47330758142946133 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6866277463531468 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.77      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "70:\n",
      "\n",
      "Threshold: 14.003\n",
      "number of features with scores above the threshold: 140\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47457845938131593 \n",
      "test accuracy: 0.8385 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6861147158629997 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.90      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.87      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47542179662562706 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6847213554307375 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.79      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "71:\n",
      "\n",
      "Threshold: 14.203\n",
      "number of features with scores above the threshold: 138\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4754937028182007 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6767181458256973 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.83      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.83      0.51      0.48      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4734473042884878 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6874843014431115 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.85      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "72:\n",
      "\n",
      "Threshold: 14.403\n",
      "number of features with scores above the threshold: 135\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4722473375464208 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.686931205924341 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.76      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47457845938131593 \n",
      "test accuracy: 0.8385 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6890559732664996 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.90      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.87      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "73:\n",
      "\n",
      "Threshold: 14.6031\n",
      "number of features with scores above the threshold: 134\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4735172077129607 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6803866275262156 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.89      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.87      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4756376116092917 \n",
      "test accuracy: 0.8387 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6793506603575253 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.90      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.87      0.51      0.48      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "74:\n",
      "\n",
      "Threshold: 14.8031\n",
      "number of features with scores above the threshold: 133\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4733774289007111 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6828460038986354 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.81      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47662167334977434 \n",
      "test accuracy: 0.8387 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6790616197938852 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.87      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.85      0.51      0.48      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "75:\n",
      "\n",
      "Threshold: 15.0032\n",
      "number of features with scores above the threshold: 133\n",
      "76:\n",
      "\n",
      "Threshold: 15.2032\n",
      "number of features with scores above the threshold: 133\n",
      "77:\n",
      "\n",
      "Threshold: 15.4033\n",
      "number of features with scores above the threshold: 131\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4723161491956597 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6874658098914391 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.80      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4754937028182007 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6941331149569137 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.83      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.83      0.51      0.48      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "78:\n",
      "\n",
      "Threshold: 15.6033\n",
      "number of features with scores above the threshold: 128\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4721097912234794 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6886564236678653 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.70      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.77      0.51      0.47      5752\n",
      "weighted avg       0.81      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47422406385606547 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6844414505741737 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.72      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.78      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "79:\n",
      "\n",
      "Threshold: 15.8033\n",
      "number of features with scores above the threshold: 127\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47633002458507795 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6782554761959796 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47640288581529305 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6866640690439317 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.77      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "80:\n",
      "\n",
      "Threshold: 16.0034\n",
      "number of features with scores above the threshold: 127\n",
      "81:\n",
      "\n",
      "Threshold: 16.2034\n",
      "number of features with scores above the threshold: 127\n",
      "82:\n",
      "\n",
      "Threshold: 16.4035\n",
      "number of features with scores above the threshold: 126\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4764757809273457 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.678348594366901 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.80      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47640288581529305 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6889433729250664 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.77      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "83:\n",
      "\n",
      "Threshold: 16.6035\n",
      "number of features with scores above the threshold: 124\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4733774289007111 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6893573415312546 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.81      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47640288581529305 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6816036578050308 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.77      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "84:\n",
      "\n",
      "Threshold: 16.8036\n",
      "number of features with scores above the threshold: 122\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47534992239170554 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6877385602786059 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.76      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47654871005929905 \n",
      "test accuracy: 0.8385 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6871820526282769 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.83      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.48      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "85:\n",
      "\n",
      "Threshold: 17.0036\n",
      "number of features with scores above the threshold: 122\n",
      "86:\n",
      "\n",
      "Threshold: 17.2036\n",
      "number of features with scores above the threshold: 121\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4764757809273457 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6845466763086899 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.80      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47760163946298584 \n",
      "test accuracy: 0.8387 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6823596100483972 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.84      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.48      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "87:\n",
      "\n",
      "Threshold: 17.4037\n",
      "number of features with scores above the threshold: 119\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4733774289007111 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6900705870957587 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.81      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4774537798971271 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6764728025597588 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.78      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "88:\n",
      "\n",
      "Threshold: 17.6037\n",
      "number of features with scores above the threshold: 119\n",
      "89:\n",
      "\n",
      "Threshold: 17.8038\n",
      "number of features with scores above the threshold: 117\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4744366112656254 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6751159849558019 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.82      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.83      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4754937028182007 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6777984707046493 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.83      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.83      0.51      0.48      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "90:\n",
      "\n",
      "Threshold: 18.0038\n",
      "number of features with scores above the threshold: 117\n",
      "91:\n",
      "\n",
      "Threshold: 18.2039\n",
      "number of features with scores above the threshold: 116\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4782780656734266 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6873559612690048 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.71      0.02      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.77      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4764757809273457 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6809540319837804 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.80      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "92:\n",
      "\n",
      "Threshold: 18.4039\n",
      "number of features with scores above the threshold: 115\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4752780799846063 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6798824025368647 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.73      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.78      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4752780799846063 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.678748694309335 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.73      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.78      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "93:\n",
      "\n",
      "Threshold: 18.6039\n",
      "number of features with scores above the threshold: 114\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47633002458507795 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6805731940743383 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47850261104517633 \n",
      "test accuracy: 0.8385 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6814941393888764 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.79      0.02      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "94:\n",
      "\n",
      "Threshold: 18.804\n",
      "number of features with scores above the threshold: 113\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47640288581529305 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.686947936375854 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.77      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47556564110178945 \n",
      "test accuracy: 0.8385 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6862348008801098 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.86      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.85      0.51      0.48      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "95:\n",
      "\n",
      "Threshold: 19.004\n",
      "number of features with scores above the threshold: 113\n",
      "96:\n",
      "\n",
      "Threshold: 19.2041\n",
      "number of features with scores above the threshold: 112\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47939764063979273 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6835087279023205 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.02      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4783528764267676 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6884075582016085 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.73      0.02      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "97:\n",
      "\n",
      "Threshold: 19.4041\n",
      "number of features with scores above the threshold: 110\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47534992239170554 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.680450577475749 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.76      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4752780799846063 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.675694616426882 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.73      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.78      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "98:\n",
      "\n",
      "Threshold: 19.6042\n",
      "number of features with scores above the threshold: 109\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4773799040721842 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6791117010796645 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.75      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47939764063979273 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6788141852215078 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.02      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "99:\n",
      "\n",
      "Threshold: 19.8042\n",
      "number of features with scores above the threshold: 109\n",
      "100:\n",
      "\n",
      "Threshold: 20.0042\n",
      "number of features with scores above the threshold: 107\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47850261104517633 \n",
      "test accuracy: 0.8385 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.681417641600708 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.79      0.02      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47842772483429563 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6871580576386069 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.76      0.02      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "101:\n",
      "\n",
      "Threshold: 20.2043\n",
      "number of features with scores above the threshold: 105\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47865249747666666 \n",
      "test accuracy: 0.8388 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6747325053961211 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.85      0.02      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.48      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47842772483429563 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6789252446003019 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.76      0.02      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "102:\n",
      "\n",
      "Threshold: 20.4043\n",
      "number of features with scores above the threshold: 104\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4774537798971271 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6664461989404782 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.78      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4793218277045359 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6775453125567542 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.72      0.02      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.78      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "103:\n",
      "\n",
      "Threshold: 20.6044\n",
      "number of features with scores above the threshold: 103\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47939764063979273 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6809991601753616 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.02      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4783528764267676 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6807378569392302 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.73      0.02      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "104:\n",
      "\n",
      "Threshold: 20.8044\n",
      "number of features with scores above the threshold: 103\n",
      "105:\n",
      "\n",
      "Threshold: 21.0044\n",
      "number of features with scores above the threshold: 102\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4815588982621964 \n",
      "test accuracy: 0.8388 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6738348946586934 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.78      0.03      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4814810497484659 \n",
      "test accuracy: 0.8387 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6800074406481729 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.76      0.03      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "106:\n",
      "\n",
      "Threshold: 21.2045\n",
      "number of features with scores above the threshold: 100\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.48021005437522785 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6727135141322784 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.69      0.03      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.76      0.51      0.48      5752\n",
      "weighted avg       0.81      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.48028678252810203 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6806707149956578 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.71      0.03      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.77      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "107:\n",
      "\n",
      "Threshold: 21.4045\n",
      "number of features with scores above the threshold: 99\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4805172156061587 \n",
      "test accuracy: 0.8387 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6739929533979877 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.77      0.03      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4832375034776964 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6787765417056033 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.69      0.03      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.77      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "108:\n",
      "\n",
      "Threshold: 21.6046\n",
      "number of features with scores above the threshold: 97\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.48355634157882077 \n",
      "test accuracy: 0.8390 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6786636111578903 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.77      0.03      0.06       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4832375034776964 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6792863802017121 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.69      0.03      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.77      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "109:\n",
      "\n",
      "Threshold: 21.8046\n",
      "number of features with scores above the threshold: 97\n",
      "110:\n",
      "\n",
      "Threshold: 22.0047\n",
      "number of features with scores above the threshold: 96\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4791703201919647 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6806172215783199 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.68      0.02      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.76      0.51      0.48      5752\n",
      "weighted avg       0.81      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4778299836130369 \n",
      "test accuracy: 0.8369 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6744969582498187 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.59      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.72      0.51      0.48      5752\n",
      "weighted avg       0.80      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "111:\n",
      "\n",
      "Threshold: 22.2047\n",
      "number of features with scores above the threshold: 94\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.48078235662066504 \n",
      "test accuracy: 0.8371 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6736323681403774 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.60      0.03      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.72      0.51      0.48      5752\n",
      "weighted avg       0.80      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.481014869084052 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6755079398099993 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.64      0.03      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.74      0.51      0.48      5752\n",
      "weighted avg       0.81      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "112:\n",
      "\n",
      "Threshold: 22.4047\n",
      "number of features with scores above the threshold: 93\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4840266538130445 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6769341007327276 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.65      0.03      0.06       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.75      0.51      0.48      5752\n",
      "weighted avg       0.81      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4874318888731219 \n",
      "test accuracy: 0.8392 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6796881311755455 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.03      0.06       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.52      0.49      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "113:\n",
      "\n",
      "Threshold: 22.6048\n",
      "number of features with scores above the threshold: 91\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.48276064814014213 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6818456990081704 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.60      0.03      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.72      0.51      0.48      5752\n",
      "weighted avg       0.80      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.48769731675277095 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6774946809271752 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.62      0.03      0.06       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.73      0.51      0.49      5752\n",
      "weighted avg       0.80      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "114:\n",
      "\n",
      "Threshold: 22.8048\n",
      "number of features with scores above the threshold: 88\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.48500978352439106 \n",
      "test accuracy: 0.8361 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6810661920501738 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.52      0.03      0.06       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.68      0.51      0.49      5752\n",
      "weighted avg       0.79      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4824436629290491 \n",
      "test accuracy: 0.8366 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6709409668219737 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.55      0.03      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.70      0.51      0.48      5752\n",
      "weighted avg       0.79      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "115:\n",
      "\n",
      "Threshold: 23.0049\n",
      "number of features with scores above the threshold: 88\n",
      "116:\n",
      "\n",
      "Threshold: 23.2049\n",
      "number of features with scores above the threshold: 87\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.48260206461432714 \n",
      "test accuracy: 0.8369 \n",
      "train accuracy: 0.9997 \n",
      "ROAUC: 0.6782800215294496 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.57      0.03      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.71      0.51      0.48      5752\n",
      "weighted avg       0.80      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4862675171158462 \n",
      "test accuracy: 0.8368 \n",
      "train accuracy: 0.9997 \n",
      "ROAUC: 0.6757126677035145 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.55      0.03      0.06       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.70      0.51      0.49      5752\n",
      "weighted avg       0.79      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "117:\n",
      "\n",
      "Threshold: 23.405\n",
      "number of features with scores above the threshold: 87\n",
      "118:\n",
      "\n",
      "Threshold: 23.605\n",
      "number of features with scores above the threshold: 86\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.485747214016736 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 0.9997 \n",
      "ROAUC: 0.6703748831895285 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.61      0.03      0.06       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.73      0.51      0.49      5752\n",
      "weighted avg       0.80      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.48727796739410156 \n",
      "test accuracy: 0.8369 \n",
      "train accuracy: 0.9997 \n",
      "ROAUC: 0.668054413592171 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.56      0.03      0.06       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.70      0.51      0.49      5752\n",
      "weighted avg       0.79      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "119:\n",
      "\n",
      "Threshold: 23.805\n",
      "number of features with scores above the threshold: 86\n",
      "120:\n",
      "\n",
      "Threshold: 24.0051\n",
      "number of features with scores above the threshold: 86\n",
      "121:\n",
      "\n",
      "Threshold: 24.2051\n",
      "number of features with scores above the threshold: 85\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4894644152943399 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 0.9998 \n",
      "ROAUC: 0.6817163682152241 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.60      0.04      0.07       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.72      0.52      0.49      5752\n",
      "weighted avg       0.80      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.48472721667024515 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 0.9998 \n",
      "ROAUC: 0.672885661672847 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.60      0.03      0.06       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.72      0.51      0.48      5752\n",
      "weighted avg       0.80      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "122:\n",
      "\n",
      "Threshold: 24.4052\n",
      "number of features with scores above the threshold: 83\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4871106051982546 \n",
      "test accuracy: 0.8366 \n",
      "train accuracy: 0.9995 \n",
      "ROAUC: 0.6692646196078691 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.54      0.03      0.06       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.69      0.51      0.49      5752\n",
      "weighted avg       0.79      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.48895119531552456 \n",
      "test accuracy: 0.8366 \n",
      "train accuracy: 0.9995 \n",
      "ROAUC: 0.6743253610530499 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.54      0.04      0.07       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.69      0.51      0.49      5752\n",
      "weighted avg       0.79      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "123:\n",
      "\n",
      "Threshold: 24.6052\n",
      "number of features with scores above the threshold: 82\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4893787355199424 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 0.9995 \n",
      "ROAUC: 0.6792128542700625 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.59      0.04      0.07       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.71      0.52      0.49      5752\n",
      "weighted avg       0.80      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.49095135928687217 \n",
      "test accuracy: 0.8369 \n",
      "train accuracy: 0.9995 \n",
      "ROAUC: 0.667697680741159 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.55      0.04      0.07       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.70      0.52      0.49      5752\n",
      "weighted avg       0.79      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "124:\n",
      "\n",
      "Threshold: 24.8053\n",
      "number of features with scores above the threshold: 82\n",
      "125:\n",
      "\n",
      "Threshold: 25.0053\n",
      "number of features with scores above the threshold: 82\n",
      "126:\n",
      "\n",
      "Threshold: 25.2053\n",
      "number of features with scores above the threshold: 81\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4870270042302063 \n",
      "test accuracy: 0.8364 \n",
      "train accuracy: 0.9995 \n",
      "ROAUC: 0.6714261499158525 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.53      0.03      0.06       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.69      0.51      0.49      5752\n",
      "weighted avg       0.79      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.48886585759134915 \n",
      "test accuracy: 0.8364 \n",
      "train accuracy: 0.9995 \n",
      "ROAUC: 0.665156743417613 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.53      0.04      0.07       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.69      0.51      0.49      5752\n",
      "weighted avg       0.79      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "127:\n",
      "\n",
      "Threshold: 25.4054\n",
      "number of features with scores above the threshold: 81\n",
      "128:\n",
      "\n",
      "Threshold: 25.6054\n",
      "number of features with scores above the threshold: 80\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4846833336502537 \n",
      "test accuracy: 0.8354 \n",
      "train accuracy: 0.9992 \n",
      "ROAUC: 0.6710181250227018 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.48      0.03      0.06       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.66      0.51      0.48      5752\n",
      "weighted avg       0.78      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4929439934661303 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 0.9992 \n",
      "ROAUC: 0.6727657967932567 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.57      0.04      0.08       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.70      0.52      0.49      5752\n",
      "weighted avg       0.80      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "129:\n",
      "\n",
      "Threshold: 25.8055\n",
      "number of features with scores above the threshold: 80\n",
      "130:\n",
      "\n",
      "Threshold: 26.0055\n",
      "number of features with scores above the threshold: 80\n",
      "131:\n",
      "\n",
      "Threshold: 26.2055\n",
      "number of features with scores above the threshold: 79\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.48827005891998054 \n",
      "test accuracy: 0.8352 \n",
      "train accuracy: 0.9992 \n",
      "ROAUC: 0.6666460838085553 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.48      0.04      0.07       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.66      0.51      0.49      5752\n",
      "weighted avg       0.78      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.48861018144447343 \n",
      "test accuracy: 0.8359 \n",
      "train accuracy: 0.9992 \n",
      "ROAUC: 0.6675007677296007 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.51      0.04      0.07       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.67      0.51      0.49      5752\n",
      "weighted avg       0.79      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "132:\n",
      "\n",
      "Threshold: 26.4056\n",
      "number of features with scores above the threshold: 79\n",
      "133:\n",
      "\n",
      "Threshold: 26.6056\n",
      "number of features with scores above the threshold: 79\n",
      "134:\n",
      "\n",
      "Threshold: 26.8057\n",
      "number of features with scores above the threshold: 78\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4899092694922728 \n",
      "test accuracy: 0.8348 \n",
      "train accuracy: 0.9987 \n",
      "ROAUC: 0.6614685594090629 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.47      0.04      0.07       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.65      0.51      0.49      5752\n",
      "weighted avg       0.78      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.49420477038075894 \n",
      "test accuracy: 0.8362 \n",
      "train accuracy: 0.9987 \n",
      "ROAUC: 0.6698959740149673 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.52      0.04      0.08       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.68      0.52      0.49      5752\n",
      "weighted avg       0.79      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "135:\n",
      "\n",
      "Threshold: 27.0057\n",
      "number of features with scores above the threshold: 78\n",
      "136:\n",
      "\n",
      "Threshold: 27.2058\n",
      "number of features with scores above the threshold: 78\n",
      "137:\n",
      "\n",
      "Threshold: 27.4058\n",
      "number of features with scores above the threshold: 78\n",
      "138:\n",
      "\n",
      "Threshold: 27.6058\n",
      "number of features with scores above the threshold: 78\n",
      "139:\n",
      "\n",
      "Threshold: 27.8059\n",
      "number of features with scores above the threshold: 77\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.49491424899548186 \n",
      "test accuracy: 0.8359 \n",
      "train accuracy: 0.9986 \n",
      "ROAUC: 0.6621386580196649 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.51      0.04      0.08       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.67      0.52      0.49      5752\n",
      "weighted avg       0.79      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4969616294012228 \n",
      "test accuracy: 0.8364 \n",
      "train accuracy: 0.9986 \n",
      "ROAUC: 0.6617055374492447 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.52      0.05      0.08       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.68      0.52      0.50      5752\n",
      "weighted avg       0.79      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "140:\n",
      "\n",
      "Threshold: 28.0059\n",
      "number of features with scores above the threshold: 77\n",
      "141:\n",
      "\n",
      "Threshold: 28.206\n",
      "number of features with scores above the threshold: 77\n",
      "142:\n",
      "\n",
      "Threshold: 28.406\n",
      "number of features with scores above the threshold: 77\n",
      "143:\n",
      "\n",
      "Threshold: 28.6061\n",
      "number of features with scores above the threshold: 77\n",
      "144:\n",
      "\n",
      "Threshold: 28.8061\n",
      "number of features with scores above the threshold: 77\n",
      "145:\n",
      "\n",
      "Threshold: 29.0061\n",
      "number of features with scores above the threshold: 77\n",
      "146:\n",
      "\n",
      "Threshold: 29.2062\n",
      "number of features with scores above the threshold: 77\n",
      "147:\n",
      "\n",
      "Threshold: 29.4062\n",
      "number of features with scores above the threshold: 77\n",
      "148:\n",
      "\n",
      "Threshold: 29.6063\n",
      "number of features with scores above the threshold: 76\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.49063386127510467 \n",
      "test accuracy: 0.8345 \n",
      "train accuracy: 0.9985 \n",
      "ROAUC: 0.6709705753184014 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.46      0.04      0.07       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.65      0.52      0.49      5752\n",
      "weighted avg       0.78      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.49277405513529315 \n",
      "test accuracy: 0.8352 \n",
      "train accuracy: 0.9985 \n",
      "ROAUC: 0.6645208761913567 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.48      0.04      0.08       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.66      0.52      0.49      5752\n",
      "weighted avg       0.78      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "149:\n",
      "\n",
      "Threshold: 29.8063\n",
      "number of features with scores above the threshold: 75\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4915277907776604 \n",
      "test accuracy: 0.8345 \n",
      "train accuracy: 0.9985 \n",
      "ROAUC: 0.655896878780174 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.46      0.04      0.07       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.65      0.52      0.49      5752\n",
      "weighted avg       0.78      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.49330514446793516 \n",
      "test accuracy: 0.8345 \n",
      "train accuracy: 0.9985 \n",
      "ROAUC: 0.6607776578028294 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.46      0.04      0.08       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.65      0.52      0.49      5752\n",
      "weighted avg       0.78      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "150:\n",
      "\n",
      "Threshold: 30.0064\n",
      "number of features with scores above the threshold: 74\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.49391756007008847 \n",
      "test accuracy: 0.8340 \n",
      "train accuracy: 0.9979 \n",
      "ROAUC: 0.6595356419155045 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.45      0.04      0.08       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.64      0.52      0.49      5752\n",
      "weighted avg       0.78      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.49436962945854873 \n",
      "test accuracy: 0.8348 \n",
      "train accuracy: 0.9980 \n",
      "ROAUC: 0.6494789895247562 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.47      0.04      0.08       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.66      0.52      0.49      5752\n",
      "weighted avg       0.78      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "151:\n",
      "\n",
      "Threshold: 30.2064\n",
      "number of features with scores above the threshold: 73\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.49672561920083785 \n",
      "test accuracy: 0.8343 \n",
      "train accuracy: 0.9978 \n",
      "ROAUC: 0.6578908844355068 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.46      0.05      0.08       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.65      0.52      0.50      5752\n",
      "weighted avg       0.78      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.49108841891535954 \n",
      "test accuracy: 0.8336 \n",
      "train accuracy: 0.9978 \n",
      "ROAUC: 0.6563592776407422 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.43      0.04      0.07       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.64      0.51      0.49      5752\n",
      "weighted avg       0.77      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "152:\n",
      "\n",
      "Threshold: 30.4064\n",
      "number of features with scores above the threshold: 73\n",
      "153:\n",
      "\n",
      "Threshold: 30.6065\n",
      "number of features with scores above the threshold: 73\n",
      "154:\n",
      "\n",
      "Threshold: 30.8065\n",
      "number of features with scores above the threshold: 73\n",
      "155:\n",
      "\n",
      "Threshold: 31.0066\n",
      "number of features with scores above the threshold: 73\n",
      "156:\n",
      "\n",
      "Threshold: 31.2066\n",
      "number of features with scores above the threshold: 73\n",
      "157:\n",
      "\n",
      "Threshold: 31.4066\n",
      "number of features with scores above the threshold: 73\n",
      "158:\n",
      "\n",
      "Threshold: 31.6067\n",
      "number of features with scores above the threshold: 72\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.49262833591755056 \n",
      "test accuracy: 0.8298 \n",
      "train accuracy: 0.9965 \n",
      "ROAUC: 0.6524376377923289 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91      4807\n",
      "           1       0.36      0.04      0.08       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.60      0.51      0.49      5752\n",
      "weighted avg       0.76      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4979048468249512 \n",
      "test accuracy: 0.8317 \n",
      "train accuracy: 0.9964 \n",
      "ROAUC: 0.6595844023761644 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.40      0.05      0.09       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.62      0.52      0.50      5752\n",
      "weighted avg       0.77      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "159:\n",
      "\n",
      "Threshold: 31.8067\n",
      "number of features with scores above the threshold: 71\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.49724854695399334 \n",
      "test accuracy: 0.8305 \n",
      "train accuracy: 0.9960 \n",
      "ROAUC: 0.6481834802200934 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91      4807\n",
      "           1       0.38      0.05      0.09       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.61      0.52      0.50      5752\n",
      "weighted avg       0.76      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4950670606545098 \n",
      "test accuracy: 0.8312 \n",
      "train accuracy: 0.9959 \n",
      "ROAUC: 0.6471633629528366 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.39      0.05      0.08       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.61      0.52      0.50      5752\n",
      "weighted avg       0.77      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "160:\n",
      "\n",
      "Threshold: 32.0068\n",
      "number of features with scores above the threshold: 71\n",
      "161:\n",
      "\n",
      "Threshold: 32.2068\n",
      "number of features with scores above the threshold: 70\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5020995721764131 \n",
      "test accuracy: 0.8288 \n",
      "train accuracy: 0.9937 \n",
      "ROAUC: 0.6486496214185002 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91      4807\n",
      "           1       0.36      0.06      0.10       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.60      0.52      0.50      5752\n",
      "weighted avg       0.76      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.49944837454984525 \n",
      "test accuracy: 0.8284 \n",
      "train accuracy: 0.9938 \n",
      "ROAUC: 0.6507448903329911 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91      4807\n",
      "           1       0.35      0.05      0.09       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.60      0.52      0.50      5752\n",
      "weighted avg       0.76      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "162:\n",
      "\n",
      "Threshold: 32.4069\n",
      "number of features with scores above the threshold: 70\n",
      "163:\n",
      "\n",
      "Threshold: 32.6069\n",
      "number of features with scores above the threshold: 70\n",
      "164:\n",
      "\n",
      "Threshold: 32.8069\n",
      "number of features with scores above the threshold: 70\n",
      "165:\n",
      "\n",
      "Threshold: 33.007\n",
      "number of features with scores above the threshold: 69\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4972456723799778 \n",
      "test accuracy: 0.8289 \n",
      "train accuracy: 0.9935 \n",
      "ROAUC: 0.649944690448123 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91      4807\n",
      "           1       0.36      0.05      0.09       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.60      0.52      0.50      5752\n",
      "weighted avg       0.76      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.49900367209013907 \n",
      "test accuracy: 0.8291 \n",
      "train accuracy: 0.9936 \n",
      "ROAUC: 0.6484937640544048 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91      4807\n",
      "           1       0.36      0.05      0.09       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.60      0.52      0.50      5752\n",
      "weighted avg       0.76      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "166:\n",
      "\n",
      "Threshold: 33.207\n",
      "number of features with scores above the threshold: 69\n",
      "167:\n",
      "\n",
      "Threshold: 33.4071\n",
      "number of features with scores above the threshold: 69\n",
      "168:\n",
      "\n",
      "Threshold: 33.6071\n",
      "number of features with scores above the threshold: 69\n",
      "169:\n",
      "\n",
      "Threshold: 33.8072\n",
      "number of features with scores above the threshold: 69\n",
      "170:\n",
      "\n",
      "Threshold: 34.0072\n",
      "number of features with scores above the threshold: 69\n",
      "171:\n",
      "\n",
      "Threshold: 34.2072\n",
      "number of features with scores above the threshold: 69\n",
      "172:\n",
      "\n",
      "Threshold: 34.4073\n",
      "number of features with scores above the threshold: 69\n",
      "173:\n",
      "\n",
      "Threshold: 34.6073\n",
      "number of features with scores above the threshold: 69\n",
      "174:\n",
      "\n",
      "Threshold: 34.8074\n",
      "number of features with scores above the threshold: 69\n",
      "175:\n",
      "\n",
      "Threshold: 35.0074\n",
      "number of features with scores above the threshold: 69\n",
      "176:\n",
      "\n",
      "Threshold: 35.2075\n",
      "number of features with scores above the threshold: 68\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5054377686903638 \n",
      "test accuracy: 0.8289 \n",
      "train accuracy: 0.9929 \n",
      "ROAUC: 0.6484966258421636 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91      4807\n",
      "           1       0.37      0.06      0.11       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.61      0.52      0.51      5752\n",
      "weighted avg       0.76      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.49695114562533915 \n",
      "test accuracy: 0.8268 \n",
      "train accuracy: 0.9930 \n",
      "ROAUC: 0.6442682243597575 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.90      4807\n",
      "           1       0.33      0.05      0.09       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.58      0.52      0.50      5752\n",
      "weighted avg       0.76      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "177:\n",
      "\n",
      "Threshold: 35.4075\n",
      "number of features with scores above the threshold: 68\n",
      "178:\n",
      "\n",
      "Threshold: 35.6075\n",
      "number of features with scores above the threshold: 68\n",
      "179:\n",
      "\n",
      "Threshold: 35.8076\n",
      "number of features with scores above the threshold: 68\n",
      "180:\n",
      "\n",
      "Threshold: 36.0076\n",
      "number of features with scores above the threshold: 68\n",
      "181:\n",
      "\n",
      "Threshold: 36.2077\n",
      "number of features with scores above the threshold: 67\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.50797660433766 \n",
      "test accuracy: 0.8265 \n",
      "train accuracy: 0.9914 \n",
      "ROAUC: 0.6513631465576546 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.90      4807\n",
      "           1       0.35      0.07      0.11       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.60      0.52      0.51      5752\n",
      "weighted avg       0.76      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5051189055832961 \n",
      "test accuracy: 0.8256 \n",
      "train accuracy: 0.9913 \n",
      "ROAUC: 0.6448539002314746 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.90      4807\n",
      "           1       0.34      0.06      0.11       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.59      0.52      0.51      5752\n",
      "weighted avg       0.76      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "182:\n",
      "\n",
      "Threshold: 36.4077\n",
      "number of features with scores above the threshold: 66\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5083433566898867 \n",
      "test accuracy: 0.8258 \n",
      "train accuracy: 0.9909 \n",
      "ROAUC: 0.655354459931119 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90      4807\n",
      "           1       0.35      0.07      0.11       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.59      0.52      0.51      5752\n",
      "weighted avg       0.76      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5080793109337449 \n",
      "test accuracy: 0.8267 \n",
      "train accuracy: 0.9909 \n",
      "ROAUC: 0.6483047759935632 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.90      4807\n",
      "           1       0.35      0.07      0.11       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.60      0.52      0.51      5752\n",
      "weighted avg       0.76      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "183:\n",
      "\n",
      "Threshold: 36.6078\n",
      "number of features with scores above the threshold: 65\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5159716320358032 \n",
      "test accuracy: 0.8270 \n",
      "train accuracy: 0.9891 \n",
      "ROAUC: 0.6436884922010779 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90      4807\n",
      "           1       0.37      0.08      0.13       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.61      0.53      0.52      5752\n",
      "weighted avg       0.77      0.83      0.78      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5209041599375352 \n",
      "test accuracy: 0.8277 \n",
      "train accuracy: 0.9891 \n",
      "ROAUC: 0.6475154729159306 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90      4807\n",
      "           1       0.39      0.08      0.14       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.62      0.53      0.52      5752\n",
      "weighted avg       0.77      0.83      0.78      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "184:\n",
      "\n",
      "Threshold: 36.8078\n",
      "number of features with scores above the threshold: 65\n",
      "185:\n",
      "\n",
      "Threshold: 37.0078\n",
      "number of features with scores above the threshold: 65\n",
      "186:\n",
      "\n",
      "Threshold: 37.2079\n",
      "number of features with scores above the threshold: 65\n",
      "187:\n",
      "\n",
      "Threshold: 37.4079\n",
      "number of features with scores above the threshold: 64\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5176245780452985 \n",
      "test accuracy: 0.8215 \n",
      "train accuracy: 0.9856 \n",
      "ROAUC: 0.6391725911176712 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90      4807\n",
      "           1       0.33      0.08      0.13       945\n",
      "\n",
      "    accuracy                           0.82      5752\n",
      "   macro avg       0.59      0.53      0.52      5752\n",
      "weighted avg       0.76      0.82      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5181141578340653 \n",
      "test accuracy: 0.8234 \n",
      "train accuracy: 0.9856 \n",
      "ROAUC: 0.6391206386629728 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90      4807\n",
      "           1       0.34      0.08      0.13       945\n",
      "\n",
      "    accuracy                           0.82      5752\n",
      "   macro avg       0.59      0.53      0.52      5752\n",
      "weighted avg       0.76      0.82      0.78      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "188:\n",
      "\n",
      "Threshold: 37.608\n",
      "number of features with scores above the threshold: 64\n",
      "189:\n",
      "\n",
      "Threshold: 37.808\n",
      "number of features with scores above the threshold: 63\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5136755560517208 \n",
      "test accuracy: 0.8209 \n",
      "train accuracy: 0.9855 \n",
      "ROAUC: 0.6423441123669956 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90      4807\n",
      "           1       0.32      0.08      0.13       945\n",
      "\n",
      "    accuracy                           0.82      5752\n",
      "   macro avg       0.58      0.52      0.51      5752\n",
      "weighted avg       0.76      0.82      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5203306164919194 \n",
      "test accuracy: 0.8223 \n",
      "train accuracy: 0.9854 \n",
      "ROAUC: 0.6373608593288227 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90      4807\n",
      "           1       0.34      0.09      0.14       945\n",
      "\n",
      "    accuracy                           0.82      5752\n",
      "   macro avg       0.59      0.53      0.52      5752\n",
      "weighted avg       0.76      0.82      0.78      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "190:\n",
      "\n",
      "Threshold: 38.008\n",
      "number of features with scores above the threshold: 63\n",
      "191:\n",
      "\n",
      "Threshold: 38.2081\n",
      "number of features with scores above the threshold: 63\n",
      "192:\n",
      "\n",
      "Threshold: 38.4081\n",
      "number of features with scores above the threshold: 63\n",
      "193:\n",
      "\n",
      "Threshold: 38.6082\n",
      "number of features with scores above the threshold: 62\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5222591362126245 \n",
      "test accuracy: 0.8209 \n",
      "train accuracy: 0.9835 \n",
      "ROAUC: 0.6335119749307392 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90      4807\n",
      "           1       0.34      0.09      0.14       945\n",
      "\n",
      "    accuracy                           0.82      5752\n",
      "   macro avg       0.59      0.53      0.52      5752\n",
      "weighted avg       0.76      0.82      0.78      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5198106854401559 \n",
      "test accuracy: 0.8204 \n",
      "train accuracy: 0.9836 \n",
      "ROAUC: 0.6231203833034497 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90      4807\n",
      "           1       0.33      0.09      0.14       945\n",
      "\n",
      "    accuracy                           0.82      5752\n",
      "   macro avg       0.59      0.53      0.52      5752\n",
      "weighted avg       0.76      0.82      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "194:\n",
      "\n",
      "Threshold: 38.8082\n",
      "number of features with scores above the threshold: 62\n",
      "195:\n",
      "\n",
      "Threshold: 39.0083\n",
      "number of features with scores above the threshold: 61\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5191176619330825 \n",
      "test accuracy: 0.8161 \n",
      "train accuracy: 0.9814 \n",
      "ROAUC: 0.6286024679617357 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90      4807\n",
      "           1       0.30      0.09      0.14       945\n",
      "\n",
      "    accuracy                           0.82      5752\n",
      "   macro avg       0.57      0.53      0.52      5752\n",
      "weighted avg       0.75      0.82      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5254809442893554 \n",
      "test accuracy: 0.8185 \n",
      "train accuracy: 0.9812 \n",
      "ROAUC: 0.6245407105819003 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90      4807\n",
      "           1       0.33      0.10      0.15       945\n",
      "\n",
      "    accuracy                           0.82      5752\n",
      "   macro avg       0.59      0.53      0.53      5752\n",
      "weighted avg       0.76      0.82      0.78      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "196:\n",
      "\n",
      "Threshold: 39.2083\n",
      "number of features with scores above the threshold: 61\n",
      "197:\n",
      "\n",
      "Threshold: 39.4083\n",
      "number of features with scores above the threshold: 60\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5288833650503292 \n",
      "test accuracy: 0.8147 \n",
      "train accuracy: 0.9752 \n",
      "ROAUC: 0.6284273485646483 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.90      4807\n",
      "           1       0.31      0.11      0.16       945\n",
      "\n",
      "    accuracy                           0.81      5752\n",
      "   macro avg       0.58      0.53      0.53      5752\n",
      "weighted avg       0.76      0.81      0.78      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5267176841529402 \n",
      "test accuracy: 0.8124 \n",
      "train accuracy: 0.9750 \n",
      "ROAUC: 0.6242770959018099 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      4807\n",
      "           1       0.30      0.11      0.16       945\n",
      "\n",
      "    accuracy                           0.81      5752\n",
      "   macro avg       0.57      0.53      0.53      5752\n",
      "weighted avg       0.76      0.81      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "198:\n",
      "\n",
      "Threshold: 39.6084\n",
      "number of features with scores above the threshold: 60\n",
      "199:\n",
      "\n",
      "Threshold: 39.8084\n",
      "number of features with scores above the threshold: 60\n",
      "200:\n",
      "\n",
      "Threshold: 40.0085\n",
      "number of features with scores above the threshold: 60\n",
      "201:\n",
      "\n",
      "Threshold: 40.2085\n",
      "number of features with scores above the threshold: 60\n",
      "202:\n",
      "\n",
      "Threshold: 40.4086\n",
      "number of features with scores above the threshold: 60\n",
      "203:\n",
      "\n",
      "Threshold: 40.6086\n",
      "number of features with scores above the threshold: 60\n",
      "204:\n",
      "\n",
      "Threshold: 40.8086\n",
      "number of features with scores above the threshold: 60\n",
      "205:\n",
      "\n",
      "Threshold: 41.0087\n",
      "number of features with scores above the threshold: 60\n",
      "206:\n",
      "\n",
      "Threshold: 41.2087\n",
      "number of features with scores above the threshold: 60\n",
      "207:\n",
      "\n",
      "Threshold: 41.4088\n",
      "number of features with scores above the threshold: 58\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5360510437978329 \n",
      "test accuracy: 0.8105 \n",
      "train accuracy: 0.9675 \n",
      "ROAUC: 0.6227930388113454 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.89      4807\n",
      "           1       0.31      0.13      0.18       945\n",
      "\n",
      "    accuracy                           0.81      5752\n",
      "   macro avg       0.58      0.54      0.54      5752\n",
      "weighted avg       0.76      0.81      0.78      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5305881429334127 \n",
      "test accuracy: 0.8079 \n",
      "train accuracy: 0.9669 \n",
      "ROAUC: 0.6169492682078493 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      4807\n",
      "           1       0.29      0.12      0.17       945\n",
      "\n",
      "    accuracy                           0.81      5752\n",
      "   macro avg       0.57      0.53      0.53      5752\n",
      "weighted avg       0.75      0.81      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "208:\n",
      "\n",
      "Threshold: 41.6088\n",
      "number of features with scores above the threshold: 57\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5329907938233495 \n",
      "test accuracy: 0.8018 \n",
      "train accuracy: 0.9599 \n",
      "ROAUC: 0.6127948329321328 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89      4807\n",
      "           1       0.28      0.13      0.18       945\n",
      "\n",
      "    accuracy                           0.80      5752\n",
      "   macro avg       0.56      0.53      0.53      5752\n",
      "weighted avg       0.75      0.80      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5280680504522827 \n",
      "test accuracy: 0.8006 \n",
      "train accuracy: 0.9597 \n",
      "ROAUC: 0.613512701384555 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.89      4807\n",
      "           1       0.27      0.12      0.17       945\n",
      "\n",
      "    accuracy                           0.80      5752\n",
      "   macro avg       0.56      0.53      0.53      5752\n",
      "weighted avg       0.75      0.80      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "209:\n",
      "\n",
      "Threshold: 41.8089\n",
      "number of features with scores above the threshold: 57\n",
      "210:\n",
      "\n",
      "Threshold: 42.0089\n",
      "number of features with scores above the threshold: 57\n",
      "211:\n",
      "\n",
      "Threshold: 42.2089\n",
      "number of features with scores above the threshold: 57\n",
      "212:\n",
      "\n",
      "Threshold: 42.409\n",
      "number of features with scores above the threshold: 57\n",
      "213:\n",
      "\n",
      "Threshold: 42.609\n",
      "number of features with scores above the threshold: 57\n",
      "214:\n",
      "\n",
      "Threshold: 42.8091\n",
      "number of features with scores above the threshold: 57\n",
      "215:\n",
      "\n",
      "Threshold: 43.0091\n",
      "number of features with scores above the threshold: 57\n",
      "216:\n",
      "\n",
      "Threshold: 43.2091\n",
      "number of features with scores above the threshold: 57\n",
      "217:\n",
      "\n",
      "Threshold: 43.4092\n",
      "number of features with scores above the threshold: 57\n",
      "218:\n",
      "\n",
      "Threshold: 43.6092\n",
      "number of features with scores above the threshold: 57\n",
      "219:\n",
      "\n",
      "Threshold: 43.8093\n",
      "number of features with scores above the threshold: 57\n",
      "220:\n",
      "\n",
      "Threshold: 44.0093\n",
      "number of features with scores above the threshold: 57\n",
      "221:\n",
      "\n",
      "Threshold: 44.2094\n",
      "number of features with scores above the threshold: 57\n",
      "222:\n",
      "\n",
      "Threshold: 44.4094\n",
      "number of features with scores above the threshold: 57\n",
      "223:\n",
      "\n",
      "Threshold: 44.6094\n",
      "number of features with scores above the threshold: 57\n",
      "224:\n",
      "\n",
      "Threshold: 44.8095\n",
      "number of features with scores above the threshold: 57\n",
      "225:\n",
      "\n",
      "Threshold: 45.0095\n",
      "number of features with scores above the threshold: 57\n",
      "226:\n",
      "\n",
      "Threshold: 45.2096\n",
      "number of features with scores above the threshold: 57\n",
      "227:\n",
      "\n",
      "Threshold: 45.4096\n",
      "number of features with scores above the threshold: 56\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5340344020491079 \n",
      "test accuracy: 0.7959 \n",
      "train accuracy: 0.9525 \n",
      "ROAUC: 0.6067394001032445 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88      4807\n",
      "           1       0.27      0.14      0.18       945\n",
      "\n",
      "    accuracy                           0.80      5752\n",
      "   macro avg       0.56      0.53      0.53      5752\n",
      "weighted avg       0.75      0.80      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5325271103945663 \n",
      "test accuracy: 0.7945 \n",
      "train accuracy: 0.9523 \n",
      "ROAUC: 0.6115551284887669 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88      4807\n",
      "           1       0.26      0.14      0.18       945\n",
      "\n",
      "    accuracy                           0.79      5752\n",
      "   macro avg       0.55      0.53      0.53      5752\n",
      "weighted avg       0.75      0.79      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "228:\n",
      "\n",
      "Threshold: 45.6097\n",
      "number of features with scores above the threshold: 56\n",
      "229:\n",
      "\n",
      "Threshold: 45.8097\n",
      "number of features with scores above the threshold: 54\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5478002756804068 \n",
      "test accuracy: 0.7783 \n",
      "train accuracy: 0.9251 \n",
      "ROAUC: 0.6184373978424322 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      4807\n",
      "           1       0.26      0.20      0.22       945\n",
      "\n",
      "    accuracy                           0.78      5752\n",
      "   macro avg       0.56      0.54      0.55      5752\n",
      "weighted avg       0.75      0.78      0.76      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5456722769777264 \n",
      "test accuracy: 0.7773 \n",
      "train accuracy: 0.9266 \n",
      "ROAUC: 0.6171621411896011 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      4807\n",
      "           1       0.26      0.19      0.22       945\n",
      "\n",
      "    accuracy                           0.78      5752\n",
      "   macro avg       0.55      0.54      0.55      5752\n",
      "weighted avg       0.75      0.78      0.76      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "230:\n",
      "\n",
      "Threshold: 46.0097\n",
      "number of features with scores above the threshold: 54\n",
      "231:\n",
      "\n",
      "Threshold: 46.2098\n",
      "number of features with scores above the threshold: 54\n",
      "232:\n",
      "\n",
      "Threshold: 46.4098\n",
      "number of features with scores above the threshold: 54\n",
      "233:\n",
      "\n",
      "Threshold: 46.6099\n",
      "number of features with scores above the threshold: 54\n",
      "234:\n",
      "\n",
      "Threshold: 46.8099\n",
      "number of features with scores above the threshold: 53\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5466364237453639 \n",
      "test accuracy: 0.7622 \n",
      "train accuracy: 0.9018 \n",
      "ROAUC: 0.6192319842205426 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86      4807\n",
      "           1       0.25      0.22      0.23       945\n",
      "\n",
      "    accuracy                           0.76      5752\n",
      "   macro avg       0.55      0.54      0.55      5752\n",
      "weighted avg       0.75      0.76      0.76      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.549949981392473 \n",
      "test accuracy: 0.7616 \n",
      "train accuracy: 0.9025 \n",
      "ROAUC: 0.617545950955562 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86      4807\n",
      "           1       0.25      0.23      0.24       945\n",
      "\n",
      "    accuracy                           0.76      5752\n",
      "   macro avg       0.55      0.55      0.55      5752\n",
      "weighted avg       0.75      0.76      0.76      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "235:\n",
      "\n",
      "Threshold: 47.01\n",
      "number of features with scores above the threshold: 53\n",
      "236:\n",
      "\n",
      "Threshold: 47.21\n",
      "number of features with scores above the threshold: 53\n",
      "237:\n",
      "\n",
      "Threshold: 47.41\n",
      "number of features with scores above the threshold: 53\n",
      "238:\n",
      "\n",
      "Threshold: 47.6101\n",
      "number of features with scores above the threshold: 52\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5449964566508542 \n",
      "test accuracy: 0.7470 \n",
      "train accuracy: 0.8859 \n",
      "ROAUC: 0.6108647772263334 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85      4807\n",
      "           1       0.24      0.25      0.24       945\n",
      "\n",
      "    accuracy                           0.75      5752\n",
      "   macro avg       0.54      0.55      0.54      5752\n",
      "weighted avg       0.75      0.75      0.75      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5397075411967223 \n",
      "test accuracy: 0.7450 \n",
      "train accuracy: 0.8869 \n",
      "ROAUC: 0.612080266542509 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85      4807\n",
      "           1       0.23      0.23      0.23       945\n",
      "\n",
      "    accuracy                           0.74      5752\n",
      "   macro avg       0.54      0.54      0.54      5752\n",
      "weighted avg       0.75      0.74      0.75      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "239:\n",
      "\n",
      "Threshold: 47.8101\n",
      "number of features with scores above the threshold: 52\n",
      "240:\n",
      "\n",
      "Threshold: 48.0102\n",
      "number of features with scores above the threshold: 52\n",
      "241:\n",
      "\n",
      "Threshold: 48.2102\n",
      "number of features with scores above the threshold: 52\n",
      "242:\n",
      "\n",
      "Threshold: 48.4102\n",
      "number of features with scores above the threshold: 52\n",
      "243:\n",
      "\n",
      "Threshold: 48.6103\n",
      "number of features with scores above the threshold: 52\n",
      "244:\n",
      "\n",
      "Threshold: 48.8103\n",
      "number of features with scores above the threshold: 52\n",
      "245:\n",
      "\n",
      "Threshold: 49.0104\n",
      "number of features with scores above the threshold: 52\n",
      "246:\n",
      "\n",
      "Threshold: 49.2104\n",
      "number of features with scores above the threshold: 52\n",
      "247:\n",
      "\n",
      "Threshold: 49.4105\n",
      "number of features with scores above the threshold: 52\n",
      "248:\n",
      "\n",
      "Threshold: 49.6105\n",
      "number of features with scores above the threshold: 51\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5525423060326429 \n",
      "test accuracy: 0.7394 \n",
      "train accuracy: 0.8668 \n",
      "ROAUC: 0.6150304395155654 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84      4807\n",
      "           1       0.25      0.28      0.26       945\n",
      "\n",
      "    accuracy                           0.74      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.75      0.74      0.75      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.553357535786878 \n",
      "test accuracy: 0.7396 \n",
      "train accuracy: 0.8674 \n",
      "ROAUC: 0.6133942673988441 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84      4807\n",
      "           1       0.25      0.29      0.26       945\n",
      "\n",
      "    accuracy                           0.74      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.74      0.75      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "249:\n",
      "\n",
      "Threshold: 49.8105\n",
      "number of features with scores above the threshold: 51\n",
      "250:\n",
      "\n",
      "Threshold: 50.0106\n",
      "number of features with scores above the threshold: 51\n",
      "251:\n",
      "\n",
      "Threshold: 50.2106\n",
      "number of features with scores above the threshold: 51\n",
      "252:\n",
      "\n",
      "Threshold: 50.4107\n",
      "number of features with scores above the threshold: 51\n",
      "253:\n",
      "\n",
      "Threshold: 50.6107\n",
      "number of features with scores above the threshold: 51\n",
      "254:\n",
      "\n",
      "Threshold: 50.8108\n",
      "number of features with scores above the threshold: 51\n",
      "255:\n",
      "\n",
      "Threshold: 51.0108\n",
      "number of features with scores above the threshold: 50\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5501117360761819 \n",
      "test accuracy: 0.7337 \n",
      "train accuracy: 0.8585 \n",
      "ROAUC: 0.613874277261005 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.84      4807\n",
      "           1       0.24      0.29      0.26       945\n",
      "\n",
      "    accuracy                           0.73      5752\n",
      "   macro avg       0.55      0.55      0.55      5752\n",
      "weighted avg       0.75      0.73      0.74      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5543659233153065 \n",
      "test accuracy: 0.7340 \n",
      "train accuracy: 0.8587 \n",
      "ROAUC: 0.6120497774960018 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84      4807\n",
      "           1       0.25      0.30      0.27       945\n",
      "\n",
      "    accuracy                           0.73      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.73      0.74      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "256:\n",
      "\n",
      "Threshold: 51.2108\n",
      "number of features with scores above the threshold: 50\n",
      "257:\n",
      "\n",
      "Threshold: 51.4109\n",
      "number of features with scores above the threshold: 50\n",
      "258:\n",
      "\n",
      "Threshold: 51.6109\n",
      "number of features with scores above the threshold: 50\n",
      "259:\n",
      "\n",
      "Threshold: 51.811\n",
      "number of features with scores above the threshold: 49\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5511826284379538 \n",
      "test accuracy: 0.7251 \n",
      "train accuracy: 0.8478 \n",
      "ROAUC: 0.6140060295666703 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.83      4807\n",
      "           1       0.24      0.31      0.27       945\n",
      "\n",
      "    accuracy                           0.73      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.73      0.74      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5484487714672591 \n",
      "test accuracy: 0.7244 \n",
      "train accuracy: 0.8494 \n",
      "ROAUC: 0.6172814557253917 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.83      4807\n",
      "           1       0.24      0.30      0.27       945\n",
      "\n",
      "    accuracy                           0.72      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.75      0.72      0.74      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "260:\n",
      "\n",
      "Threshold: 52.011\n",
      "number of features with scores above the threshold: 49\n",
      "261:\n",
      "\n",
      "Threshold: 52.2111\n",
      "number of features with scores above the threshold: 48\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5490393836060232 \n",
      "test accuracy: 0.7055 \n",
      "train accuracy: 0.8256 \n",
      "ROAUC: 0.6133138071353175 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.77      0.81      4807\n",
      "           1       0.24      0.35      0.28       945\n",
      "\n",
      "    accuracy                           0.71      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.71      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5410871537246422 \n",
      "test accuracy: 0.7011 \n",
      "train accuracy: 0.8273 \n",
      "ROAUC: 0.6068414338437221 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.77      0.81      4807\n",
      "           1       0.23      0.34      0.27       945\n",
      "\n",
      "    accuracy                           0.70      5752\n",
      "   macro avg       0.54      0.55      0.54      5752\n",
      "weighted avg       0.75      0.70      0.72      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "262:\n",
      "\n",
      "Threshold: 52.4111\n",
      "number of features with scores above the threshold: 48\n",
      "263:\n",
      "\n",
      "Threshold: 52.6111\n",
      "number of features with scores above the threshold: 48\n",
      "264:\n",
      "\n",
      "Threshold: 52.8112\n",
      "number of features with scores above the threshold: 48\n",
      "265:\n",
      "\n",
      "Threshold: 53.0112\n",
      "number of features with scores above the threshold: 48\n",
      "266:\n",
      "\n",
      "Threshold: 53.2113\n",
      "number of features with scores above the threshold: 48\n",
      "267:\n",
      "\n",
      "Threshold: 53.4113\n",
      "number of features with scores above the threshold: 48\n",
      "268:\n",
      "\n",
      "Threshold: 53.6114\n",
      "number of features with scores above the threshold: 48\n",
      "269:\n",
      "\n",
      "Threshold: 53.8114\n",
      "number of features with scores above the threshold: 48\n",
      "270:\n",
      "\n",
      "Threshold: 54.0114\n",
      "number of features with scores above the threshold: 48\n",
      "271:\n",
      "\n",
      "Threshold: 54.2115\n",
      "number of features with scores above the threshold: 48\n",
      "272:\n",
      "\n",
      "Threshold: 54.4115\n",
      "number of features with scores above the threshold: 48\n",
      "273:\n",
      "\n",
      "Threshold: 54.6116\n",
      "number of features with scores above the threshold: 48\n",
      "274:\n",
      "\n",
      "Threshold: 54.8116\n",
      "number of features with scores above the threshold: 48\n",
      "275:\n",
      "\n",
      "Threshold: 55.0116\n",
      "number of features with scores above the threshold: 48\n",
      "276:\n",
      "\n",
      "Threshold: 55.2117\n",
      "number of features with scores above the threshold: 48\n",
      "277:\n",
      "\n",
      "Threshold: 55.4117\n",
      "number of features with scores above the threshold: 48\n",
      "278:\n",
      "\n",
      "Threshold: 55.6118\n",
      "number of features with scores above the threshold: 48\n",
      "279:\n",
      "\n",
      "Threshold: 55.8118\n",
      "number of features with scores above the threshold: 48\n",
      "280:\n",
      "\n",
      "Threshold: 56.0119\n",
      "number of features with scores above the threshold: 48\n",
      "281:\n",
      "\n",
      "Threshold: 56.2119\n",
      "number of features with scores above the threshold: 48\n",
      "282:\n",
      "\n",
      "Threshold: 56.4119\n",
      "number of features with scores above the threshold: 47\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5406347175809896 \n",
      "test accuracy: 0.6937 \n",
      "train accuracy: 0.8083 \n",
      "ROAUC: 0.6062821744743941 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.76      0.81      4807\n",
      "           1       0.23      0.35      0.28       945\n",
      "\n",
      "    accuracy                           0.69      5752\n",
      "   macro avg       0.54      0.56      0.54      5752\n",
      "weighted avg       0.75      0.69      0.72      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.539714051160424 \n",
      "test accuracy: 0.6932 \n",
      "train accuracy: 0.8097 \n",
      "ROAUC: 0.6025419279423856 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.76      0.81      4807\n",
      "           1       0.22      0.35      0.27       945\n",
      "\n",
      "    accuracy                           0.69      5752\n",
      "   macro avg       0.54      0.56      0.54      5752\n",
      "weighted avg       0.75      0.69      0.72      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "283:\n",
      "\n",
      "Threshold: 56.612\n",
      "number of features with scores above the threshold: 47\n",
      "284:\n",
      "\n",
      "Threshold: 56.812\n",
      "number of features with scores above the threshold: 47\n",
      "285:\n",
      "\n",
      "Threshold: 57.0121\n",
      "number of features with scores above the threshold: 47\n",
      "286:\n",
      "\n",
      "Threshold: 57.2121\n",
      "number of features with scores above the threshold: 47\n",
      "287:\n",
      "\n",
      "Threshold: 57.4122\n",
      "number of features with scores above the threshold: 47\n",
      "288:\n",
      "\n",
      "Threshold: 57.6122\n",
      "number of features with scores above the threshold: 47\n",
      "289:\n",
      "\n",
      "Threshold: 57.8122\n",
      "number of features with scores above the threshold: 47\n",
      "290:\n",
      "\n",
      "Threshold: 58.0123\n",
      "number of features with scores above the threshold: 47\n",
      "291:\n",
      "\n",
      "Threshold: 58.2123\n",
      "number of features with scores above the threshold: 47\n",
      "292:\n",
      "\n",
      "Threshold: 58.4124\n",
      "number of features with scores above the threshold: 46\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5412292380109075 \n",
      "test accuracy: 0.6895 \n",
      "train accuracy: 0.7997 \n",
      "ROAUC: 0.605800293443314 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80      4807\n",
      "           1       0.23      0.37      0.28       945\n",
      "\n",
      "    accuracy                           0.69      5752\n",
      "   macro avg       0.54      0.56      0.54      5752\n",
      "weighted avg       0.75      0.69      0.72      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.54344598206596 \n",
      "test accuracy: 0.6904 \n",
      "train accuracy: 0.8015 \n",
      "ROAUC: 0.6045285589908016 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80      4807\n",
      "           1       0.23      0.37      0.28       945\n",
      "\n",
      "    accuracy                           0.69      5752\n",
      "   macro avg       0.54      0.56      0.54      5752\n",
      "weighted avg       0.76      0.69      0.72      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "293:\n",
      "\n",
      "Threshold: 58.6124\n",
      "number of features with scores above the threshold: 46\n",
      "294:\n",
      "\n",
      "Threshold: 58.8125\n",
      "number of features with scores above the threshold: 46\n",
      "295:\n",
      "\n",
      "Threshold: 59.0125\n",
      "number of features with scores above the threshold: 46\n",
      "296:\n",
      "\n",
      "Threshold: 59.2125\n",
      "number of features with scores above the threshold: 46\n",
      "297:\n",
      "\n",
      "Threshold: 59.4126\n",
      "number of features with scores above the threshold: 46\n",
      "298:\n",
      "\n",
      "Threshold: 59.6126\n",
      "number of features with scores above the threshold: 46\n",
      "299:\n",
      "\n",
      "Threshold: 59.8127\n",
      "number of features with scores above the threshold: 46\n",
      "300:\n",
      "\n",
      "Threshold: 60.0127\n",
      "number of features with scores above the threshold: 46\n",
      "301:\n",
      "\n",
      "Threshold: 60.2127\n",
      "number of features with scores above the threshold: 46\n",
      "302:\n",
      "\n",
      "Threshold: 60.4128\n",
      "number of features with scores above the threshold: 45\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5352781096808682 \n",
      "test accuracy: 0.6737 \n",
      "train accuracy: 0.7756 \n",
      "ROAUC: 0.5938062107398492 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.73      0.79      4807\n",
      "           1       0.22      0.39      0.28       945\n",
      "\n",
      "    accuracy                           0.67      5752\n",
      "   macro avg       0.54      0.56      0.54      5752\n",
      "weighted avg       0.75      0.67      0.71      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5364131820062983 \n",
      "test accuracy: 0.6728 \n",
      "train accuracy: 0.7739 \n",
      "ROAUC: 0.5939356516015555 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.73      0.79      4807\n",
      "           1       0.22      0.40      0.28       945\n",
      "\n",
      "    accuracy                           0.67      5752\n",
      "   macro avg       0.54      0.56      0.54      5752\n",
      "weighted avg       0.76      0.67      0.71      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "303:\n",
      "\n",
      "Threshold: 60.6128\n",
      "number of features with scores above the threshold: 45\n",
      "304:\n",
      "\n",
      "Threshold: 60.8129\n",
      "number of features with scores above the threshold: 45\n",
      "305:\n",
      "\n",
      "Threshold: 61.0129\n",
      "number of features with scores above the threshold: 45\n",
      "306:\n",
      "\n",
      "Threshold: 61.213\n",
      "number of features with scores above the threshold: 44\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5300512604486809 \n",
      "test accuracy: 0.6511 \n",
      "train accuracy: 0.7420 \n",
      "ROAUC: 0.5895426973230178 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.69      0.77      4807\n",
      "           1       0.22      0.44      0.29       945\n",
      "\n",
      "    accuracy                           0.65      5752\n",
      "   macro avg       0.54      0.57      0.53      5752\n",
      "weighted avg       0.76      0.65      0.69      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5323387129558113 \n",
      "test accuracy: 0.6537 \n",
      "train accuracy: 0.7447 \n",
      "ROAUC: 0.5914276248372358 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.70      0.77      4807\n",
      "           1       0.22      0.44      0.29       945\n",
      "\n",
      "    accuracy                           0.65      5752\n",
      "   macro avg       0.54      0.57      0.53      5752\n",
      "weighted avg       0.76      0.65      0.69      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "307:\n",
      "\n",
      "Threshold: 61.413\n",
      "number of features with scores above the threshold: 44\n",
      "308:\n",
      "\n",
      "Threshold: 61.613\n",
      "number of features with scores above the threshold: 44\n",
      "309:\n",
      "\n",
      "Threshold: 61.8131\n",
      "number of features with scores above the threshold: 44\n",
      "310:\n",
      "\n",
      "Threshold: 62.0131\n",
      "number of features with scores above the threshold: 44\n",
      "311:\n",
      "\n",
      "Threshold: 62.2132\n",
      "number of features with scores above the threshold: 44\n",
      "312:\n",
      "\n",
      "Threshold: 62.4132\n",
      "number of features with scores above the threshold: 44\n",
      "313:\n",
      "\n",
      "Threshold: 62.6133\n",
      "number of features with scores above the threshold: 44\n",
      "314:\n",
      "\n",
      "Threshold: 62.8133\n",
      "number of features with scores above the threshold: 43\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5311105812329309 \n",
      "test accuracy: 0.6519 \n",
      "train accuracy: 0.7274 \n",
      "ROAUC: 0.5925988665119101 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.69      0.77      4807\n",
      "           1       0.22      0.44      0.29       945\n",
      "\n",
      "    accuracy                           0.65      5752\n",
      "   macro avg       0.54      0.57      0.53      5752\n",
      "weighted avg       0.76      0.65      0.69      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5294211659567926 \n",
      "test accuracy: 0.6483 \n",
      "train accuracy: 0.7245 \n",
      "ROAUC: 0.5930752441049925 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.69      0.77      4807\n",
      "           1       0.22      0.44      0.29       945\n",
      "\n",
      "    accuracy                           0.65      5752\n",
      "   macro avg       0.54      0.57      0.53      5752\n",
      "weighted avg       0.76      0.65      0.69      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "315:\n",
      "\n",
      "Threshold: 63.0133\n",
      "number of features with scores above the threshold: 43\n",
      "316:\n",
      "\n",
      "Threshold: 63.2134\n",
      "number of features with scores above the threshold: 43\n",
      "317:\n",
      "\n",
      "Threshold: 63.4134\n",
      "number of features with scores above the threshold: 43\n",
      "318:\n",
      "\n",
      "Threshold: 63.6135\n",
      "number of features with scores above the threshold: 43\n",
      "319:\n",
      "\n",
      "Threshold: 63.8135\n",
      "number of features with scores above the threshold: 43\n",
      "320:\n",
      "\n",
      "Threshold: 64.0136\n",
      "number of features with scores above the threshold: 43\n",
      "321:\n",
      "\n",
      "Threshold: 64.2136\n",
      "number of features with scores above the threshold: 43\n",
      "322:\n",
      "\n",
      "Threshold: 64.4136\n",
      "number of features with scores above the threshold: 42\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5363638356152134 \n",
      "test accuracy: 0.6490 \n",
      "train accuracy: 0.7126 \n",
      "ROAUC: 0.6057587975208113 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.68      0.76      4807\n",
      "           1       0.23      0.48      0.31       945\n",
      "\n",
      "    accuracy                           0.65      5752\n",
      "   macro avg       0.55      0.58      0.54      5752\n",
      "weighted avg       0.76      0.65      0.69      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5349128752318366 \n",
      "test accuracy: 0.6464 \n",
      "train accuracy: 0.7111 \n",
      "ROAUC: 0.6063025371949857 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.68      0.76      4807\n",
      "           1       0.23      0.48      0.31       945\n",
      "\n",
      "    accuracy                           0.65      5752\n",
      "   macro avg       0.55      0.58      0.53      5752\n",
      "weighted avg       0.76      0.65      0.69      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "323:\n",
      "\n",
      "Threshold: 64.6137\n",
      "number of features with scores above the threshold: 42\n",
      "324:\n",
      "\n",
      "Threshold: 64.8137\n",
      "number of features with scores above the threshold: 42\n",
      "325:\n",
      "\n",
      "Threshold: 65.0138\n",
      "number of features with scores above the threshold: 42\n",
      "326:\n",
      "\n",
      "Threshold: 65.2138\n",
      "number of features with scores above the threshold: 42\n",
      "327:\n",
      "\n",
      "Threshold: 65.4139\n",
      "number of features with scores above the threshold: 42\n",
      "328:\n",
      "\n",
      "Threshold: 65.6139\n",
      "number of features with scores above the threshold: 42\n",
      "329:\n",
      "\n",
      "Threshold: 65.8139\n",
      "number of features with scores above the threshold: 42\n",
      "330:\n",
      "\n",
      "Threshold: 66.014\n",
      "number of features with scores above the threshold: 42\n",
      "331:\n",
      "\n",
      "Threshold: 66.214\n",
      "number of features with scores above the threshold: 42\n",
      "332:\n",
      "\n",
      "Threshold: 66.4141\n",
      "number of features with scores above the threshold: 41\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5380248735787554 \n",
      "test accuracy: 0.6406 \n",
      "train accuracy: 0.6953 \n",
      "ROAUC: 0.6096387213092018 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.67      0.76      4807\n",
      "           1       0.23      0.52      0.32       945\n",
      "\n",
      "    accuracy                           0.64      5752\n",
      "   macro avg       0.55      0.59      0.54      5752\n",
      "weighted avg       0.77      0.64      0.68      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5435937485230224 \n",
      "test accuracy: 0.6483 \n",
      "train accuracy: 0.6996 \n",
      "ROAUC: 0.608869450745881 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.67      0.76      4807\n",
      "           1       0.24      0.52      0.32       945\n",
      "\n",
      "    accuracy                           0.65      5752\n",
      "   macro avg       0.56      0.59      0.54      5752\n",
      "weighted avg       0.77      0.65      0.69      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "333:\n",
      "\n",
      "Threshold: 66.6141\n",
      "number of features with scores above the threshold: 41\n",
      "334:\n",
      "\n",
      "Threshold: 66.8141\n",
      "number of features with scores above the threshold: 41\n",
      "335:\n",
      "\n",
      "Threshold: 67.0142\n",
      "number of features with scores above the threshold: 41\n",
      "336:\n",
      "\n",
      "Threshold: 67.2142\n",
      "number of features with scores above the threshold: 41\n",
      "337:\n",
      "\n",
      "Threshold: 67.4143\n",
      "number of features with scores above the threshold: 40\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5331943309231636 \n",
      "test accuracy: 0.6326 \n",
      "train accuracy: 0.6873 \n",
      "ROAUC: 0.6067425920972832 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.65      0.75      4807\n",
      "           1       0.23      0.52      0.32       945\n",
      "\n",
      "    accuracy                           0.63      5752\n",
      "   macro avg       0.55      0.59      0.53      5752\n",
      "weighted avg       0.77      0.63      0.68      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5380390352927646 \n",
      "test accuracy: 0.6426 \n",
      "train accuracy: 0.6952 \n",
      "ROAUC: 0.605646087110618 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.67      0.76      4807\n",
      "           1       0.23      0.51      0.32       945\n",
      "\n",
      "    accuracy                           0.64      5752\n",
      "   macro avg       0.55      0.59      0.54      5752\n",
      "weighted avg       0.77      0.64      0.69      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "338:\n",
      "\n",
      "Threshold: 67.6143\n",
      "number of features with scores above the threshold: 40\n",
      "339:\n",
      "\n",
      "Threshold: 67.8144\n",
      "number of features with scores above the threshold: 40\n",
      "340:\n",
      "\n",
      "Threshold: 68.0144\n",
      "number of features with scores above the threshold: 40\n",
      "341:\n",
      "\n",
      "Threshold: 68.2144\n",
      "number of features with scores above the threshold: 39\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5333879065980459 \n",
      "test accuracy: 0.6408 \n",
      "train accuracy: 0.6881 \n",
      "ROAUC: 0.6067808960257474 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.67      0.76      4807\n",
      "           1       0.23      0.49      0.31       945\n",
      "\n",
      "    accuracy                           0.64      5752\n",
      "   macro avg       0.55      0.58      0.53      5752\n",
      "weighted avg       0.76      0.64      0.68      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5220650688725581 \n",
      "test accuracy: 0.6182 \n",
      "train accuracy: 0.6668 \n",
      "ROAUC: 0.6062347348388538 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.64      0.74      4807\n",
      "           1       0.22      0.52      0.31       945\n",
      "\n",
      "    accuracy                           0.62      5752\n",
      "   macro avg       0.54      0.58      0.52      5752\n",
      "weighted avg       0.76      0.62      0.67      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "342:\n",
      "\n",
      "Threshold: 68.4145\n",
      "number of features with scores above the threshold: 39\n",
      "343:\n",
      "\n",
      "Threshold: 68.6145\n",
      "number of features with scores above the threshold: 39\n",
      "344:\n",
      "\n",
      "Threshold: 68.8146\n",
      "number of features with scores above the threshold: 39\n",
      "345:\n",
      "\n",
      "Threshold: 69.0146\n",
      "number of features with scores above the threshold: 39\n",
      "346:\n",
      "\n",
      "Threshold: 69.2147\n",
      "number of features with scores above the threshold: 39\n",
      "347:\n",
      "\n",
      "Threshold: 69.4147\n",
      "number of features with scores above the threshold: 39\n",
      "348:\n",
      "\n",
      "Threshold: 69.6147\n",
      "number of features with scores above the threshold: 39\n",
      "349:\n",
      "\n",
      "Threshold: 69.8148\n",
      "number of features with scores above the threshold: 39\n",
      "350:\n",
      "\n",
      "Threshold: 70.0148\n",
      "number of features with scores above the threshold: 39\n",
      "351:\n",
      "\n",
      "Threshold: 70.2149\n",
      "number of features with scores above the threshold: 39\n",
      "352:\n",
      "\n",
      "Threshold: 70.4149\n",
      "number of features with scores above the threshold: 39\n",
      "353:\n",
      "\n",
      "Threshold: 70.615\n",
      "number of features with scores above the threshold: 39\n",
      "354:\n",
      "\n",
      "Threshold: 70.815\n",
      "number of features with scores above the threshold: 39\n",
      "355:\n",
      "\n",
      "Threshold: 71.015\n",
      "number of features with scores above the threshold: 39\n",
      "356:\n",
      "\n",
      "Threshold: 71.2151\n",
      "number of features with scores above the threshold: 39\n",
      "357:\n",
      "\n",
      "Threshold: 71.4151\n",
      "number of features with scores above the threshold: 39\n",
      "358:\n",
      "\n",
      "Threshold: 71.6152\n",
      "number of features with scores above the threshold: 39\n",
      "359:\n",
      "\n",
      "Threshold: 71.8152\n",
      "number of features with scores above the threshold: 39\n",
      "360:\n",
      "\n",
      "Threshold: 72.0152\n",
      "number of features with scores above the threshold: 39\n",
      "361:\n",
      "\n",
      "Threshold: 72.2153\n",
      "number of features with scores above the threshold: 39\n",
      "362:\n",
      "\n",
      "Threshold: 72.4153\n",
      "number of features with scores above the threshold: 39\n",
      "363:\n",
      "\n",
      "Threshold: 72.6154\n",
      "number of features with scores above the threshold: 39\n",
      "364:\n",
      "\n",
      "Threshold: 72.8154\n",
      "number of features with scores above the threshold: 39\n",
      "365:\n",
      "\n",
      "Threshold: 73.0155\n",
      "number of features with scores above the threshold: 39\n",
      "366:\n",
      "\n",
      "Threshold: 73.2155\n",
      "number of features with scores above the threshold: 39\n",
      "367:\n",
      "\n",
      "Threshold: 73.4155\n",
      "number of features with scores above the threshold: 39\n",
      "368:\n",
      "\n",
      "Threshold: 73.6156\n",
      "number of features with scores above the threshold: 39\n",
      "369:\n",
      "\n",
      "Threshold: 73.8156\n",
      "number of features with scores above the threshold: 38\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5350696292367146 \n",
      "test accuracy: 0.6420 \n",
      "train accuracy: 0.6795 \n",
      "ROAUC: 0.6138323410634623 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.67      0.76      4807\n",
      "           1       0.23      0.49      0.31       945\n",
      "\n",
      "    accuracy                           0.64      5752\n",
      "   macro avg       0.55      0.58      0.54      5752\n",
      "weighted avg       0.77      0.64      0.68      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5350696292367146 \n",
      "test accuracy: 0.6420 \n",
      "train accuracy: 0.6787 \n",
      "ROAUC: 0.613893319156477 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.67      0.76      4807\n",
      "           1       0.23      0.49      0.31       945\n",
      "\n",
      "    accuracy                           0.64      5752\n",
      "   macro avg       0.55      0.58      0.54      5752\n",
      "weighted avg       0.77      0.64      0.68      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "370:\n",
      "\n",
      "Threshold: 74.0157\n",
      "number of features with scores above the threshold: 38\n",
      "371:\n",
      "\n",
      "Threshold: 74.2157\n",
      "number of features with scores above the threshold: 38\n",
      "372:\n",
      "\n",
      "Threshold: 74.4158\n",
      "number of features with scores above the threshold: 38\n",
      "373:\n",
      "\n",
      "Threshold: 74.6158\n",
      "number of features with scores above the threshold: 38\n",
      "374:\n",
      "\n",
      "Threshold: 74.8158\n",
      "number of features with scores above the threshold: 38\n",
      "375:\n",
      "\n",
      "Threshold: 75.0159\n",
      "number of features with scores above the threshold: 38\n",
      "376:\n",
      "\n",
      "Threshold: 75.2159\n",
      "number of features with scores above the threshold: 38\n",
      "377:\n",
      "\n",
      "Threshold: 75.416\n",
      "number of features with scores above the threshold: 38\n",
      "378:\n",
      "\n",
      "Threshold: 75.616\n",
      "number of features with scores above the threshold: 38\n",
      "379:\n",
      "\n",
      "Threshold: 75.8161\n",
      "number of features with scores above the threshold: 38\n",
      "380:\n",
      "\n",
      "Threshold: 76.0161\n",
      "number of features with scores above the threshold: 38\n",
      "381:\n",
      "\n",
      "Threshold: 76.2161\n",
      "number of features with scores above the threshold: 38\n",
      "382:\n",
      "\n",
      "Threshold: 76.4162\n",
      "number of features with scores above the threshold: 38\n",
      "383:\n",
      "\n",
      "Threshold: 76.6162\n",
      "number of features with scores above the threshold: 38\n",
      "384:\n",
      "\n",
      "Threshold: 76.8163\n",
      "number of features with scores above the threshold: 38\n",
      "385:\n",
      "\n",
      "Threshold: 77.0163\n",
      "number of features with scores above the threshold: 38\n",
      "386:\n",
      "\n",
      "Threshold: 77.2163\n",
      "number of features with scores above the threshold: 38\n",
      "387:\n",
      "\n",
      "Threshold: 77.4164\n",
      "number of features with scores above the threshold: 38\n",
      "388:\n",
      "\n",
      "Threshold: 77.6164\n",
      "number of features with scores above the threshold: 38\n",
      "389:\n",
      "\n",
      "Threshold: 77.8165\n",
      "number of features with scores above the threshold: 38\n",
      "390:\n",
      "\n",
      "Threshold: 78.0165\n",
      "number of features with scores above the threshold: 38\n",
      "391:\n",
      "\n",
      "Threshold: 78.2166\n",
      "number of features with scores above the threshold: 38\n",
      "392:\n",
      "\n",
      "Threshold: 78.4166\n",
      "number of features with scores above the threshold: 38\n",
      "393:\n",
      "\n",
      "Threshold: 78.6166\n",
      "number of features with scores above the threshold: 38\n",
      "394:\n",
      "\n",
      "Threshold: 78.8167\n",
      "number of features with scores above the threshold: 38\n",
      "395:\n",
      "\n",
      "Threshold: 79.0167\n",
      "number of features with scores above the threshold: 37\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5331538011476009 \n",
      "test accuracy: 0.6353 \n",
      "train accuracy: 0.6641 \n",
      "ROAUC: 0.6181894129262551 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.66      0.75      4807\n",
      "           1       0.23      0.51      0.31       945\n",
      "\n",
      "    accuracy                           0.64      5752\n",
      "   macro avg       0.55      0.58      0.53      5752\n",
      "weighted avg       0.77      0.64      0.68      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5347150424786364 \n",
      "test accuracy: 0.6377 \n",
      "train accuracy: 0.6649 \n",
      "ROAUC: 0.6187156516675968 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.66      0.75      4807\n",
      "           1       0.23      0.51      0.32       945\n",
      "\n",
      "    accuracy                           0.64      5752\n",
      "   macro avg       0.55      0.59      0.53      5752\n",
      "weighted avg       0.77      0.64      0.68      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "396:\n",
      "\n",
      "Threshold: 79.2168\n",
      "number of features with scores above the threshold: 37\n",
      "397:\n",
      "\n",
      "Threshold: 79.4168\n",
      "number of features with scores above the threshold: 37\n",
      "398:\n",
      "\n",
      "Threshold: 79.6169\n",
      "number of features with scores above the threshold: 37\n",
      "399:\n",
      "\n",
      "Threshold: 79.8169\n",
      "number of features with scores above the threshold: 37\n",
      "400:\n",
      "\n",
      "Threshold: 80.0169\n",
      "number of features with scores above the threshold: 37\n",
      "401:\n",
      "\n",
      "Threshold: 80.217\n",
      "number of features with scores above the threshold: 37\n",
      "402:\n",
      "\n",
      "Threshold: 80.417\n",
      "number of features with scores above the threshold: 37\n",
      "403:\n",
      "\n",
      "Threshold: 80.6171\n",
      "number of features with scores above the threshold: 37\n",
      "404:\n",
      "\n",
      "Threshold: 80.8171\n",
      "number of features with scores above the threshold: 37\n",
      "405:\n",
      "\n",
      "Threshold: 81.0172\n",
      "number of features with scores above the threshold: 37\n",
      "406:\n",
      "\n",
      "Threshold: 81.2172\n",
      "number of features with scores above the threshold: 37\n",
      "407:\n",
      "\n",
      "Threshold: 81.4172\n",
      "number of features with scores above the threshold: 37\n",
      "408:\n",
      "\n",
      "Threshold: 81.6173\n",
      "number of features with scores above the threshold: 37\n",
      "409:\n",
      "\n",
      "Threshold: 81.8173\n",
      "number of features with scores above the threshold: 37\n",
      "410:\n",
      "\n",
      "Threshold: 82.0174\n",
      "number of features with scores above the threshold: 37\n",
      "411:\n",
      "\n",
      "Threshold: 82.2174\n",
      "number of features with scores above the threshold: 37\n",
      "412:\n",
      "\n",
      "Threshold: 82.4175\n",
      "number of features with scores above the threshold: 37\n",
      "413:\n",
      "\n",
      "Threshold: 82.6175\n",
      "number of features with scores above the threshold: 37\n",
      "414:\n",
      "\n",
      "Threshold: 82.8175\n",
      "number of features with scores above the threshold: 37\n",
      "415:\n",
      "\n",
      "Threshold: 83.0176\n",
      "number of features with scores above the threshold: 37\n",
      "416:\n",
      "\n",
      "Threshold: 83.2176\n",
      "number of features with scores above the threshold: 37\n",
      "417:\n",
      "\n",
      "Threshold: 83.4177\n",
      "number of features with scores above the threshold: 37\n",
      "418:\n",
      "\n",
      "Threshold: 83.6177\n",
      "number of features with scores above the threshold: 37\n",
      "419:\n",
      "\n",
      "Threshold: 83.8177\n",
      "number of features with scores above the threshold: 37\n",
      "420:\n",
      "\n",
      "Threshold: 84.0178\n",
      "number of features with scores above the threshold: 37\n",
      "421:\n",
      "\n",
      "Threshold: 84.2178\n",
      "number of features with scores above the threshold: 37\n",
      "422:\n",
      "\n",
      "Threshold: 84.4179\n",
      "number of features with scores above the threshold: 37\n",
      "423:\n",
      "\n",
      "Threshold: 84.6179\n",
      "number of features with scores above the threshold: 37\n",
      "424:\n",
      "\n",
      "Threshold: 84.818\n",
      "number of features with scores above the threshold: 37\n",
      "425:\n",
      "\n",
      "Threshold: 85.018\n",
      "number of features with scores above the threshold: 37\n",
      "426:\n",
      "\n",
      "Threshold: 85.218\n",
      "number of features with scores above the threshold: 37\n",
      "427:\n",
      "\n",
      "Threshold: 85.4181\n",
      "number of features with scores above the threshold: 37\n",
      "428:\n",
      "\n",
      "Threshold: 85.6181\n",
      "number of features with scores above the threshold: 37\n",
      "429:\n",
      "\n",
      "Threshold: 85.8182\n",
      "number of features with scores above the threshold: 37\n",
      "430:\n",
      "\n",
      "Threshold: 86.0182\n",
      "number of features with scores above the threshold: 37\n",
      "431:\n",
      "\n",
      "Threshold: 86.2183\n",
      "number of features with scores above the threshold: 37\n",
      "432:\n",
      "\n",
      "Threshold: 86.4183\n",
      "number of features with scores above the threshold: 37\n",
      "433:\n",
      "\n",
      "Threshold: 86.6183\n",
      "number of features with scores above the threshold: 37\n",
      "434:\n",
      "\n",
      "Threshold: 86.8184\n",
      "number of features with scores above the threshold: 37\n",
      "435:\n",
      "\n",
      "Threshold: 87.0184\n",
      "number of features with scores above the threshold: 37\n",
      "436:\n",
      "\n",
      "Threshold: 87.2185\n",
      "number of features with scores above the threshold: 37\n",
      "437:\n",
      "\n",
      "Threshold: 87.4185\n",
      "number of features with scores above the threshold: 37\n",
      "438:\n",
      "\n",
      "Threshold: 87.6186\n",
      "number of features with scores above the threshold: 37\n",
      "439:\n",
      "\n",
      "Threshold: 87.8186\n",
      "number of features with scores above the threshold: 36\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5342604178473205 \n",
      "test accuracy: 0.6313 \n",
      "train accuracy: 0.6546 \n",
      "ROAUC: 0.6304958707704703 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.65      0.75      4807\n",
      "           1       0.23      0.53      0.32       945\n",
      "\n",
      "    accuracy                           0.63      5752\n",
      "   macro avg       0.55      0.59      0.53      5752\n",
      "weighted avg       0.77      0.63      0.68      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5337555738676235 \n",
      "test accuracy: 0.6306 \n",
      "train accuracy: 0.6554 \n",
      "ROAUC: 0.6296779498152496 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.65      0.75      4807\n",
      "           1       0.23      0.53      0.32       945\n",
      "\n",
      "    accuracy                           0.63      5752\n",
      "   macro avg       0.55      0.59      0.53      5752\n",
      "weighted avg       0.77      0.63      0.68      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "440:\n",
      "\n",
      "Threshold: 88.0186\n",
      "number of features with scores above the threshold: 35\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5135008199200777 \n",
      "test accuracy: 0.5862 \n",
      "train accuracy: 0.6058 \n",
      "ROAUC: 0.6362163643628174 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.58      0.70      4807\n",
      "           1       0.22      0.61      0.33       945\n",
      "\n",
      "    accuracy                           0.59      5752\n",
      "   macro avg       0.55      0.59      0.51      5752\n",
      "weighted avg       0.77      0.59      0.64      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5132194455145871 \n",
      "test accuracy: 0.5861 \n",
      "train accuracy: 0.6056 \n",
      "ROAUC: 0.635238513499383 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.58      0.70      4807\n",
      "           1       0.22      0.61      0.32       945\n",
      "\n",
      "    accuracy                           0.59      5752\n",
      "   macro avg       0.55      0.59      0.51      5752\n",
      "weighted avg       0.77      0.59      0.64      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "441:\n",
      "\n",
      "Threshold: 88.2187\n",
      "number of features with scores above the threshold: 35\n",
      "442:\n",
      "\n",
      "Threshold: 88.4187\n",
      "number of features with scores above the threshold: 35\n",
      "443:\n",
      "\n",
      "Threshold: 88.6188\n",
      "number of features with scores above the threshold: 35\n",
      "444:\n",
      "\n",
      "Threshold: 88.8188\n",
      "number of features with scores above the threshold: 35\n",
      "445:\n",
      "\n",
      "Threshold: 89.0188\n",
      "number of features with scores above the threshold: 35\n",
      "446:\n",
      "\n",
      "Threshold: 89.2189\n",
      "number of features with scores above the threshold: 35\n",
      "447:\n",
      "\n",
      "Threshold: 89.4189\n",
      "number of features with scores above the threshold: 35\n",
      "448:\n",
      "\n",
      "Threshold: 89.619\n",
      "number of features with scores above the threshold: 35\n",
      "449:\n",
      "\n",
      "Threshold: 89.819\n",
      "number of features with scores above the threshold: 35\n",
      "450:\n",
      "\n",
      "Threshold: 90.0191\n",
      "number of features with scores above the threshold: 35\n",
      "451:\n",
      "\n",
      "Threshold: 90.2191\n",
      "number of features with scores above the threshold: 35\n",
      "452:\n",
      "\n",
      "Threshold: 90.4191\n",
      "number of features with scores above the threshold: 35\n",
      "453:\n",
      "\n",
      "Threshold: 90.6192\n",
      "number of features with scores above the threshold: 35\n",
      "454:\n",
      "\n",
      "Threshold: 90.8192\n",
      "number of features with scores above the threshold: 35\n",
      "455:\n",
      "\n",
      "Threshold: 91.0193\n",
      "number of features with scores above the threshold: 35\n",
      "456:\n",
      "\n",
      "Threshold: 91.2193\n",
      "number of features with scores above the threshold: 35\n",
      "457:\n",
      "\n",
      "Threshold: 91.4194\n",
      "number of features with scores above the threshold: 35\n",
      "458:\n",
      "\n",
      "Threshold: 91.6194\n",
      "number of features with scores above the threshold: 35\n",
      "459:\n",
      "\n",
      "Threshold: 91.8194\n",
      "number of features with scores above the threshold: 35\n",
      "460:\n",
      "\n",
      "Threshold: 92.0195\n",
      "number of features with scores above the threshold: 35\n",
      "461:\n",
      "\n",
      "Threshold: 92.2195\n",
      "number of features with scores above the threshold: 34\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5444327174594418 \n",
      "test accuracy: 0.6511 \n",
      "train accuracy: 0.6587 \n",
      "ROAUC: 0.6301524562394127 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.68      0.76      4807\n",
      "           1       0.24      0.51      0.32       945\n",
      "\n",
      "    accuracy                           0.65      5752\n",
      "   macro avg       0.56      0.59      0.54      5752\n",
      "weighted avg       0.77      0.65      0.69      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5399303214166071 \n",
      "test accuracy: 0.6427 \n",
      "train accuracy: 0.6514 \n",
      "ROAUC: 0.6295981499642826 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.67      0.76      4807\n",
      "           1       0.23      0.52      0.32       945\n",
      "\n",
      "    accuracy                           0.64      5752\n",
      "   macro avg       0.55      0.59      0.54      5752\n",
      "weighted avg       0.77      0.64      0.69      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "462:\n",
      "\n",
      "Threshold: 92.4196\n",
      "number of features with scores above the threshold: 34\n",
      "463:\n",
      "\n",
      "Threshold: 92.6196\n",
      "number of features with scores above the threshold: 34\n",
      "464:\n",
      "\n",
      "Threshold: 92.8197\n",
      "number of features with scores above the threshold: 34\n",
      "465:\n",
      "\n",
      "Threshold: 93.0197\n",
      "number of features with scores above the threshold: 34\n",
      "466:\n",
      "\n",
      "Threshold: 93.2197\n",
      "number of features with scores above the threshold: 34\n",
      "467:\n",
      "\n",
      "Threshold: 93.4198\n",
      "number of features with scores above the threshold: 34\n",
      "468:\n",
      "\n",
      "Threshold: 93.6198\n",
      "number of features with scores above the threshold: 34\n",
      "469:\n",
      "\n",
      "Threshold: 93.8199\n",
      "number of features with scores above the threshold: 34\n",
      "470:\n",
      "\n",
      "Threshold: 94.0199\n",
      "number of features with scores above the threshold: 34\n",
      "471:\n",
      "\n",
      "Threshold: 94.2199\n",
      "number of features with scores above the threshold: 34\n",
      "472:\n",
      "\n",
      "Threshold: 94.42\n",
      "number of features with scores above the threshold: 34\n",
      "473:\n",
      "\n",
      "Threshold: 94.62\n",
      "number of features with scores above the threshold: 34\n",
      "474:\n",
      "\n",
      "Threshold: 94.8201\n",
      "number of features with scores above the threshold: 34\n",
      "475:\n",
      "\n",
      "Threshold: 95.0201\n",
      "number of features with scores above the threshold: 34\n",
      "476:\n",
      "\n",
      "Threshold: 95.2202\n",
      "number of features with scores above the threshold: 34\n",
      "477:\n",
      "\n",
      "Threshold: 95.4202\n",
      "number of features with scores above the threshold: 34\n",
      "478:\n",
      "\n",
      "Threshold: 95.6202\n",
      "number of features with scores above the threshold: 34\n",
      "479:\n",
      "\n",
      "Threshold: 95.8203\n",
      "number of features with scores above the threshold: 34\n",
      "480:\n",
      "\n",
      "Threshold: 96.0203\n",
      "number of features with scores above the threshold: 34\n",
      "481:\n",
      "\n",
      "Threshold: 96.2204\n",
      "number of features with scores above the threshold: 34\n",
      "482:\n",
      "\n",
      "Threshold: 96.4204\n",
      "number of features with scores above the threshold: 34\n",
      "483:\n",
      "\n",
      "Threshold: 96.6205\n",
      "number of features with scores above the threshold: 34\n",
      "484:\n",
      "\n",
      "Threshold: 96.8205\n",
      "number of features with scores above the threshold: 34\n",
      "485:\n",
      "\n",
      "Threshold: 97.0205\n",
      "number of features with scores above the threshold: 34\n",
      "486:\n",
      "\n",
      "Threshold: 97.2206\n",
      "number of features with scores above the threshold: 34\n",
      "487:\n",
      "\n",
      "Threshold: 97.4206\n",
      "number of features with scores above the threshold: 34\n",
      "488:\n",
      "\n",
      "Threshold: 97.6207\n",
      "number of features with scores above the threshold: 34\n",
      "489:\n",
      "\n",
      "Threshold: 97.8207\n",
      "number of features with scores above the threshold: 34\n",
      "490:\n",
      "\n",
      "Threshold: 98.0208\n",
      "number of features with scores above the threshold: 34\n",
      "491:\n",
      "\n",
      "Threshold: 98.2208\n",
      "number of features with scores above the threshold: 34\n",
      "492:\n",
      "\n",
      "Threshold: 98.4208\n",
      "number of features with scores above the threshold: 34\n",
      "493:\n",
      "\n",
      "Threshold: 98.6209\n",
      "number of features with scores above the threshold: 34\n",
      "494:\n",
      "\n",
      "Threshold: 98.8209\n",
      "number of features with scores above the threshold: 34\n",
      "495:\n",
      "\n",
      "Threshold: 99.021\n",
      "number of features with scores above the threshold: 34\n",
      "496:\n",
      "\n",
      "Threshold: 99.221\n",
      "number of features with scores above the threshold: 34\n",
      "497:\n",
      "\n",
      "Threshold: 99.4211\n",
      "number of features with scores above the threshold: 34\n",
      "498:\n",
      "\n",
      "Threshold: 99.6211\n",
      "number of features with scores above the threshold: 34\n",
      "499:\n",
      "\n",
      "Threshold: 99.8211\n",
      "number of features with scores above the threshold: 34\n",
      "500:\n",
      "\n",
      "Threshold: 100.0212\n",
      "number of features with scores above the threshold: 34\n",
      "501:\n",
      "\n",
      "Threshold: 100.2212\n",
      "number of features with scores above the threshold: 33\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5037762884125205 \n",
      "test accuracy: 0.5695 \n",
      "train accuracy: 0.5821 \n",
      "ROAUC: 0.6266917843576882 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.56      0.68      4807\n",
      "           1       0.22      0.63      0.32       945\n",
      "\n",
      "    accuracy                           0.57      5752\n",
      "   macro avg       0.55      0.59      0.50      5752\n",
      "weighted avg       0.77      0.57      0.63      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4995358706475088 \n",
      "test accuracy: 0.5622 \n",
      "train accuracy: 0.5753 \n",
      "ROAUC: 0.6273855477516805 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.55      0.68      4807\n",
      "           1       0.22      0.63      0.32       945\n",
      "\n",
      "    accuracy                           0.56      5752\n",
      "   macro avg       0.55      0.59      0.50      5752\n",
      "weighted avg       0.77      0.56      0.62      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "502:\n",
      "\n",
      "Threshold: 100.4213\n",
      "number of features with scores above the threshold: 30\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5448678032226973 \n",
      "test accuracy: 0.6678 \n",
      "train accuracy: 0.6666 \n",
      "ROAUC: 0.6096315668398048 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.71      0.78      4807\n",
      "           1       0.23      0.45      0.31       945\n",
      "\n",
      "    accuracy                           0.67      5752\n",
      "   macro avg       0.55      0.58      0.54      5752\n",
      "weighted avg       0.76      0.67      0.70      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5454201857903794 \n",
      "test accuracy: 0.6692 \n",
      "train accuracy: 0.6685 \n",
      "ROAUC: 0.6093426363449247 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.71      0.78      4807\n",
      "           1       0.23      0.45      0.31       945\n",
      "\n",
      "    accuracy                           0.67      5752\n",
      "   macro avg       0.55      0.58      0.55      5752\n",
      "weighted avg       0.76      0.67      0.70      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "503:\n",
      "\n",
      "Threshold: 100.6213\n",
      "number of features with scores above the threshold: 30\n",
      "504:\n",
      "\n",
      "Threshold: 100.8213\n",
      "number of features with scores above the threshold: 30\n",
      "505:\n",
      "\n",
      "Threshold: 101.0214\n",
      "number of features with scores above the threshold: 30\n",
      "506:\n",
      "\n",
      "Threshold: 101.2214\n",
      "number of features with scores above the threshold: 30\n",
      "507:\n",
      "\n",
      "Threshold: 101.4215\n",
      "number of features with scores above the threshold: 29\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5401997070834235 \n",
      "test accuracy: 0.6540 \n",
      "train accuracy: 0.6510 \n",
      "ROAUC: 0.6116865505881524 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.69      0.77      4807\n",
      "           1       0.23      0.48      0.31       945\n",
      "\n",
      "    accuracy                           0.65      5752\n",
      "   macro avg       0.55      0.58      0.54      5752\n",
      "weighted avg       0.77      0.65      0.69      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.539737596236271 \n",
      "test accuracy: 0.6537 \n",
      "train accuracy: 0.6508 \n",
      "ROAUC: 0.61080060713928 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.69      0.77      4807\n",
      "           1       0.23      0.48      0.31       945\n",
      "\n",
      "    accuracy                           0.65      5752\n",
      "   macro avg       0.55      0.58      0.54      5752\n",
      "weighted avg       0.76      0.65      0.69      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "508:\n",
      "\n",
      "Threshold: 101.6215\n",
      "number of features with scores above the threshold: 29\n",
      "509:\n",
      "\n",
      "Threshold: 101.8216\n",
      "number of features with scores above the threshold: 29\n",
      "510:\n",
      "\n",
      "Threshold: 102.0216\n",
      "number of features with scores above the threshold: 29\n",
      "511:\n",
      "\n",
      "Threshold: 102.2216\n",
      "number of features with scores above the threshold: 29\n",
      "512:\n",
      "\n",
      "Threshold: 102.4217\n",
      "number of features with scores above the threshold: 29\n",
      "513:\n",
      "\n",
      "Threshold: 102.6217\n",
      "number of features with scores above the threshold: 29\n",
      "514:\n",
      "\n",
      "Threshold: 102.8218\n",
      "number of features with scores above the threshold: 29\n",
      "515:\n",
      "\n",
      "Threshold: 103.0218\n",
      "number of features with scores above the threshold: 29\n",
      "516:\n",
      "\n",
      "Threshold: 103.2219\n",
      "number of features with scores above the threshold: 29\n",
      "517:\n",
      "\n",
      "Threshold: 103.4219\n",
      "number of features with scores above the threshold: 29\n",
      "518:\n",
      "\n",
      "Threshold: 103.6219\n",
      "number of features with scores above the threshold: 29\n",
      "519:\n",
      "\n",
      "Threshold: 103.822\n",
      "number of features with scores above the threshold: 29\n",
      "520:\n",
      "\n",
      "Threshold: 104.022\n",
      "number of features with scores above the threshold: 29\n",
      "521:\n",
      "\n",
      "Threshold: 104.2221\n",
      "number of features with scores above the threshold: 29\n",
      "522:\n",
      "\n",
      "Threshold: 104.4221\n",
      "number of features with scores above the threshold: 29\n",
      "523:\n",
      "\n",
      "Threshold: 104.6222\n",
      "number of features with scores above the threshold: 29\n",
      "524:\n",
      "\n",
      "Threshold: 104.8222\n",
      "number of features with scores above the threshold: 29\n",
      "525:\n",
      "\n",
      "Threshold: 105.0222\n",
      "number of features with scores above the threshold: 29\n",
      "526:\n",
      "\n",
      "Threshold: 105.2223\n",
      "number of features with scores above the threshold: 29\n",
      "527:\n",
      "\n",
      "Threshold: 105.4223\n",
      "number of features with scores above the threshold: 29\n",
      "528:\n",
      "\n",
      "Threshold: 105.6224\n",
      "number of features with scores above the threshold: 29\n",
      "529:\n",
      "\n",
      "Threshold: 105.8224\n",
      "number of features with scores above the threshold: 29\n",
      "530:\n",
      "\n",
      "Threshold: 106.0224\n",
      "number of features with scores above the threshold: 29\n",
      "531:\n",
      "\n",
      "Threshold: 106.2225\n",
      "number of features with scores above the threshold: 28\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5401997070834235 \n",
      "test accuracy: 0.6540 \n",
      "train accuracy: 0.6508 \n",
      "ROAUC: 0.6095988764180985 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.69      0.77      4807\n",
      "           1       0.23      0.48      0.31       945\n",
      "\n",
      "    accuracy                           0.65      5752\n",
      "   macro avg       0.55      0.58      0.54      5752\n",
      "weighted avg       0.77      0.65      0.69      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5399880914718992 \n",
      "test accuracy: 0.6540 \n",
      "train accuracy: 0.6513 \n",
      "ROAUC: 0.6088504088504088 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.69      0.77      4807\n",
      "           1       0.23      0.48      0.31       945\n",
      "\n",
      "    accuracy                           0.65      5752\n",
      "   macro avg       0.55      0.58      0.54      5752\n",
      "weighted avg       0.76      0.65      0.69      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "532:\n",
      "\n",
      "Threshold: 106.4225\n",
      "number of features with scores above the threshold: 28\n",
      "533:\n",
      "\n",
      "Threshold: 106.6226\n",
      "number of features with scores above the threshold: 28\n",
      "534:\n",
      "\n",
      "Threshold: 106.8226\n",
      "number of features with scores above the threshold: 28\n",
      "535:\n",
      "\n",
      "Threshold: 107.0227\n",
      "number of features with scores above the threshold: 28\n",
      "536:\n",
      "\n",
      "Threshold: 107.2227\n",
      "number of features with scores above the threshold: 28\n",
      "537:\n",
      "\n",
      "Threshold: 107.4227\n",
      "number of features with scores above the threshold: 28\n",
      "538:\n",
      "\n",
      "Threshold: 107.6228\n",
      "number of features with scores above the threshold: 28\n",
      "539:\n",
      "\n",
      "Threshold: 107.8228\n",
      "number of features with scores above the threshold: 28\n",
      "540:\n",
      "\n",
      "Threshold: 108.0229\n",
      "number of features with scores above the threshold: 28\n",
      "541:\n",
      "\n",
      "Threshold: 108.2229\n",
      "number of features with scores above the threshold: 28\n",
      "542:\n",
      "\n",
      "Threshold: 108.423\n",
      "number of features with scores above the threshold: 28\n",
      "543:\n",
      "\n",
      "Threshold: 108.623\n",
      "number of features with scores above the threshold: 28\n",
      "544:\n",
      "\n",
      "Threshold: 108.823\n",
      "number of features with scores above the threshold: 28\n",
      "545:\n",
      "\n",
      "Threshold: 109.0231\n",
      "number of features with scores above the threshold: 28\n",
      "546:\n",
      "\n",
      "Threshold: 109.2231\n",
      "number of features with scores above the threshold: 28\n",
      "547:\n",
      "\n",
      "Threshold: 109.4232\n",
      "number of features with scores above the threshold: 28\n",
      "548:\n",
      "\n",
      "Threshold: 109.6232\n",
      "number of features with scores above the threshold: 28\n",
      "549:\n",
      "\n",
      "Threshold: 109.8233\n",
      "number of features with scores above the threshold: 28\n",
      "550:\n",
      "\n",
      "Threshold: 110.0233\n",
      "number of features with scores above the threshold: 28\n",
      "551:\n",
      "\n",
      "Threshold: 110.2233\n",
      "number of features with scores above the threshold: 28\n",
      "552:\n",
      "\n",
      "Threshold: 110.4234\n",
      "number of features with scores above the threshold: 28\n",
      "553:\n",
      "\n",
      "Threshold: 110.6234\n",
      "number of features with scores above the threshold: 28\n",
      "554:\n",
      "\n",
      "Threshold: 110.8235\n",
      "number of features with scores above the threshold: 28\n",
      "555:\n",
      "\n",
      "Threshold: 111.0235\n",
      "number of features with scores above the threshold: 28\n",
      "556:\n",
      "\n",
      "Threshold: 111.2235\n",
      "number of features with scores above the threshold: 28\n",
      "557:\n",
      "\n",
      "Threshold: 111.4236\n",
      "number of features with scores above the threshold: 27\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5546924880079349 \n",
      "test accuracy: 0.7248 \n",
      "train accuracy: 0.7185 \n",
      "ROAUC: 0.5916793520912516 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83      4807\n",
      "           1       0.25      0.32      0.28       945\n",
      "\n",
      "    accuracy                           0.72      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.72      0.74      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5544959437246363 \n",
      "test accuracy: 0.7241 \n",
      "train accuracy: 0.7176 \n",
      "ROAUC: 0.5916994946743231 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83      4807\n",
      "           1       0.24      0.33      0.28       945\n",
      "\n",
      "    accuracy                           0.72      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.72      0.74      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "558:\n",
      "\n",
      "Threshold: 111.6236\n",
      "number of features with scores above the threshold: 27\n",
      "559:\n",
      "\n",
      "Threshold: 111.8237\n",
      "number of features with scores above the threshold: 27\n",
      "560:\n",
      "\n",
      "Threshold: 112.0237\n",
      "number of features with scores above the threshold: 27\n",
      "561:\n",
      "\n",
      "Threshold: 112.2238\n",
      "number of features with scores above the threshold: 27\n",
      "562:\n",
      "\n",
      "Threshold: 112.4238\n",
      "number of features with scores above the threshold: 27\n",
      "563:\n",
      "\n",
      "Threshold: 112.6238\n",
      "number of features with scores above the threshold: 27\n",
      "564:\n",
      "\n",
      "Threshold: 112.8239\n",
      "number of features with scores above the threshold: 27\n",
      "565:\n",
      "\n",
      "Threshold: 113.0239\n",
      "number of features with scores above the threshold: 27\n",
      "566:\n",
      "\n",
      "Threshold: 113.224\n",
      "number of features with scores above the threshold: 27\n",
      "567:\n",
      "\n",
      "Threshold: 113.424\n",
      "number of features with scores above the threshold: 27\n",
      "568:\n",
      "\n",
      "Threshold: 113.6241\n",
      "number of features with scores above the threshold: 27\n",
      "569:\n",
      "\n",
      "Threshold: 113.8241\n",
      "number of features with scores above the threshold: 27\n",
      "570:\n",
      "\n",
      "Threshold: 114.0241\n",
      "number of features with scores above the threshold: 27\n",
      "571:\n",
      "\n",
      "Threshold: 114.2242\n",
      "number of features with scores above the threshold: 27\n",
      "572:\n",
      "\n",
      "Threshold: 114.4242\n",
      "number of features with scores above the threshold: 27\n",
      "573:\n",
      "\n",
      "Threshold: 114.6243\n",
      "number of features with scores above the threshold: 27\n",
      "574:\n",
      "\n",
      "Threshold: 114.8243\n",
      "number of features with scores above the threshold: 27\n",
      "575:\n",
      "\n",
      "Threshold: 115.0244\n",
      "number of features with scores above the threshold: 27\n",
      "576:\n",
      "\n",
      "Threshold: 115.2244\n",
      "number of features with scores above the threshold: 27\n",
      "577:\n",
      "\n",
      "Threshold: 115.4244\n",
      "number of features with scores above the threshold: 27\n",
      "578:\n",
      "\n",
      "Threshold: 115.6245\n",
      "number of features with scores above the threshold: 27\n",
      "579:\n",
      "\n",
      "Threshold: 115.8245\n",
      "number of features with scores above the threshold: 27\n",
      "580:\n",
      "\n",
      "Threshold: 116.0246\n",
      "number of features with scores above the threshold: 27\n",
      "581:\n",
      "\n",
      "Threshold: 116.2246\n",
      "number of features with scores above the threshold: 27\n",
      "582:\n",
      "\n",
      "Threshold: 116.4247\n",
      "number of features with scores above the threshold: 27\n",
      "583:\n",
      "\n",
      "Threshold: 116.6247\n",
      "number of features with scores above the threshold: 27\n",
      "584:\n",
      "\n",
      "Threshold: 116.8247\n",
      "number of features with scores above the threshold: 27\n",
      "585:\n",
      "\n",
      "Threshold: 117.0248\n",
      "number of features with scores above the threshold: 27\n",
      "586:\n",
      "\n",
      "Threshold: 117.2248\n",
      "number of features with scores above the threshold: 27\n",
      "587:\n",
      "\n",
      "Threshold: 117.4249\n",
      "number of features with scores above the threshold: 27\n",
      "588:\n",
      "\n",
      "Threshold: 117.6249\n",
      "number of features with scores above the threshold: 27\n",
      "589:\n",
      "\n",
      "Threshold: 117.8249\n",
      "number of features with scores above the threshold: 27\n",
      "590:\n",
      "\n",
      "Threshold: 118.025\n",
      "number of features with scores above the threshold: 27\n",
      "591:\n",
      "\n",
      "Threshold: 118.225\n",
      "number of features with scores above the threshold: 27\n",
      "592:\n",
      "\n",
      "Threshold: 118.4251\n",
      "number of features with scores above the threshold: 27\n",
      "593:\n",
      "\n",
      "Threshold: 118.6251\n",
      "number of features with scores above the threshold: 27\n",
      "594:\n",
      "\n",
      "Threshold: 118.8252\n",
      "number of features with scores above the threshold: 27\n",
      "595:\n",
      "\n",
      "Threshold: 119.0252\n",
      "number of features with scores above the threshold: 27\n",
      "596:\n",
      "\n",
      "Threshold: 119.2252\n",
      "number of features with scores above the threshold: 27\n",
      "597:\n",
      "\n",
      "Threshold: 119.4253\n",
      "number of features with scores above the threshold: 27\n",
      "598:\n",
      "\n",
      "Threshold: 119.6253\n",
      "number of features with scores above the threshold: 27\n",
      "599:\n",
      "\n",
      "Threshold: 119.8254\n",
      "number of features with scores above the threshold: 27\n",
      "600:\n",
      "\n",
      "Threshold: 120.0254\n",
      "number of features with scores above the threshold: 27\n",
      "601:\n",
      "\n",
      "Threshold: 120.2255\n",
      "number of features with scores above the threshold: 27\n",
      "602:\n",
      "\n",
      "Threshold: 120.4255\n",
      "number of features with scores above the threshold: 27\n",
      "603:\n",
      "\n",
      "Threshold: 120.6255\n",
      "number of features with scores above the threshold: 27\n",
      "604:\n",
      "\n",
      "Threshold: 120.8256\n",
      "number of features with scores above the threshold: 27\n",
      "605:\n",
      "\n",
      "Threshold: 121.0256\n",
      "number of features with scores above the threshold: 27\n",
      "606:\n",
      "\n",
      "Threshold: 121.2257\n",
      "number of features with scores above the threshold: 27\n",
      "607:\n",
      "\n",
      "Threshold: 121.4257\n",
      "number of features with scores above the threshold: 27\n",
      "608:\n",
      "\n",
      "Threshold: 121.6258\n",
      "number of features with scores above the threshold: 27\n",
      "609:\n",
      "\n",
      "Threshold: 121.8258\n",
      "number of features with scores above the threshold: 27\n",
      "610:\n",
      "\n",
      "Threshold: 122.0258\n",
      "number of features with scores above the threshold: 27\n",
      "611:\n",
      "\n",
      "Threshold: 122.2259\n",
      "number of features with scores above the threshold: 27\n",
      "612:\n",
      "\n",
      "Threshold: 122.4259\n",
      "number of features with scores above the threshold: 27\n",
      "613:\n",
      "\n",
      "Threshold: 122.626\n",
      "number of features with scores above the threshold: 27\n",
      "614:\n",
      "\n",
      "Threshold: 122.826\n",
      "number of features with scores above the threshold: 27\n",
      "615:\n",
      "\n",
      "Threshold: 123.026\n",
      "number of features with scores above the threshold: 27\n",
      "616:\n",
      "\n",
      "Threshold: 123.2261\n",
      "number of features with scores above the threshold: 27\n",
      "617:\n",
      "\n",
      "Threshold: 123.4261\n",
      "number of features with scores above the threshold: 27\n",
      "618:\n",
      "\n",
      "Threshold: 123.6262\n",
      "number of features with scores above the threshold: 27\n",
      "619:\n",
      "\n",
      "Threshold: 123.8262\n",
      "number of features with scores above the threshold: 26\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5546924880079349 \n",
      "test accuracy: 0.7248 \n",
      "train accuracy: 0.7184 \n",
      "ROAUC: 0.5911265867787608 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83      4807\n",
      "           1       0.25      0.32      0.28       945\n",
      "\n",
      "    accuracy                           0.72      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.72      0.74      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5546924880079349 \n",
      "test accuracy: 0.7248 \n",
      "train accuracy: 0.7182 \n",
      "ROAUC: 0.5916023039592834 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83      4807\n",
      "           1       0.25      0.32      0.28       945\n",
      "\n",
      "    accuracy                           0.72      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.72      0.74      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "620:\n",
      "\n",
      "Threshold: 124.0263\n",
      "number of features with scores above the threshold: 25\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5546924880079349 \n",
      "test accuracy: 0.7248 \n",
      "train accuracy: 0.7183 \n",
      "ROAUC: 0.5915367029783506 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83      4807\n",
      "           1       0.25      0.32      0.28       945\n",
      "\n",
      "    accuracy                           0.72      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.72      0.74      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5546924880079349 \n",
      "test accuracy: 0.7248 \n",
      "train accuracy: 0.7182 \n",
      "ROAUC: 0.591916660337713 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83      4807\n",
      "           1       0.25      0.32      0.28       945\n",
      "\n",
      "    accuracy                           0.72      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.72      0.74      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "621:\n",
      "\n",
      "Threshold: 124.2263\n",
      "number of features with scores above the threshold: 24\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5543132963339326 \n",
      "test accuracy: 0.7243 \n",
      "train accuracy: 0.7176 \n",
      "ROAUC: 0.5905413511820833 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83      4807\n",
      "           1       0.24      0.32      0.28       945\n",
      "\n",
      "    accuracy                           0.72      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.72      0.74      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5541869875042874 \n",
      "test accuracy: 0.7241 \n",
      "train accuracy: 0.7176 \n",
      "ROAUC: 0.5905337564376465 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83      4807\n",
      "           1       0.24      0.32      0.28       945\n",
      "\n",
      "    accuracy                           0.72      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.72      0.74      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "622:\n",
      "\n",
      "Threshold: 124.4263\n",
      "number of features with scores above the threshold: 24\n",
      "623:\n",
      "\n",
      "Threshold: 124.6264\n",
      "number of features with scores above the threshold: 24\n",
      "624:\n",
      "\n",
      "Threshold: 124.8264\n",
      "number of features with scores above the threshold: 24\n",
      "625:\n",
      "\n",
      "Threshold: 125.0265\n",
      "number of features with scores above the threshold: 23\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5544396493056905 \n",
      "test accuracy: 0.7244 \n",
      "train accuracy: 0.7175 \n",
      "ROAUC: 0.5901323356700932 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83      4807\n",
      "           1       0.24      0.32      0.28       945\n",
      "\n",
      "    accuracy                           0.72      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.72      0.74      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5546353025803439 \n",
      "test accuracy: 0.7251 \n",
      "train accuracy: 0.7181 \n",
      "ROAUC: 0.5900799429403548 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83      4807\n",
      "           1       0.25      0.32      0.28       945\n",
      "\n",
      "    accuracy                           0.73      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.73      0.74      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "626:\n",
      "\n",
      "Threshold: 125.2265\n",
      "number of features with scores above the threshold: 22\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.550917117432105 \n",
      "test accuracy: 0.7121 \n",
      "train accuracy: 0.7019 \n",
      "ROAUC: 0.5695485970085512 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82      4807\n",
      "           1       0.24      0.34      0.28       945\n",
      "\n",
      "    accuracy                           0.71      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.71      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5510424008645662 \n",
      "test accuracy: 0.7123 \n",
      "train accuracy: 0.7021 \n",
      "ROAUC: 0.5704454372646592 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82      4807\n",
      "           1       0.24      0.34      0.28       945\n",
      "\n",
      "    accuracy                           0.71      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.71      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "627:\n",
      "\n",
      "Threshold: 125.4266\n",
      "number of features with scores above the threshold: 22\n",
      "628:\n",
      "\n",
      "Threshold: 125.6266\n",
      "number of features with scores above the threshold: 22\n",
      "629:\n",
      "\n",
      "Threshold: 125.8266\n",
      "number of features with scores above the threshold: 20\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5510424008645662 \n",
      "test accuracy: 0.7123 \n",
      "train accuracy: 0.7018 \n",
      "ROAUC: 0.570320839428391 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82      4807\n",
      "           1       0.24      0.34      0.28       945\n",
      "\n",
      "    accuracy                           0.71      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.71      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5512930852019474 \n",
      "test accuracy: 0.7126 \n",
      "train accuracy: 0.7020 \n",
      "ROAUC: 0.5704359713513032 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82      4807\n",
      "           1       0.24      0.34      0.28       945\n",
      "\n",
      "    accuracy                           0.71      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.71      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "630:\n",
      "\n",
      "Threshold: 126.0267\n",
      "number of features with scores above the threshold: 17\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5517530804264371 \n",
      "test accuracy: 0.7137 \n",
      "train accuracy: 0.7025 \n",
      "ROAUC: 0.570559468499972 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82      4807\n",
      "           1       0.24      0.34      0.28       945\n",
      "\n",
      "    accuracy                           0.71      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.71      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5520041998363416 \n",
      "test accuracy: 0.7140 \n",
      "train accuracy: 0.7026 \n",
      "ROAUC: 0.5708196710485041 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82      4807\n",
      "           1       0.24      0.34      0.28       945\n",
      "\n",
      "    accuracy                           0.71      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.71      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "631:\n",
      "\n",
      "Threshold: 126.2267\n",
      "number of features with scores above the threshold: 17\n",
      "632:\n",
      "\n",
      "Threshold: 126.4268\n",
      "number of features with scores above the threshold: 16\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5517530804264371 \n",
      "test accuracy: 0.7137 \n",
      "train accuracy: 0.7024 \n",
      "ROAUC: 0.5698802341822937 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82      4807\n",
      "           1       0.24      0.34      0.28       945\n",
      "\n",
      "    accuracy                           0.71      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.71      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5522973996973217 \n",
      "test accuracy: 0.7140 \n",
      "train accuracy: 0.7026 \n",
      "ROAUC: 0.5705119187956716 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82      4807\n",
      "           1       0.24      0.34      0.28       945\n",
      "\n",
      "    accuracy                           0.71      5752\n",
      "   macro avg       0.55      0.57      0.55      5752\n",
      "weighted avg       0.76      0.71      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "633:\n",
      "\n",
      "Threshold: 126.6268\n",
      "number of features with scores above the threshold: 16\n",
      "634:\n",
      "\n",
      "Threshold: 126.8269\n",
      "number of features with scores above the threshold: 16\n",
      "635:\n",
      "\n",
      "Threshold: 127.0269\n",
      "number of features with scores above the threshold: 16\n",
      "636:\n",
      "\n",
      "Threshold: 127.2269\n",
      "number of features with scores above the threshold: 15\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.552171721605512 \n",
      "test accuracy: 0.7138 \n",
      "train accuracy: 0.7023 \n",
      "ROAUC: 0.5710204364666608 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82      4807\n",
      "           1       0.24      0.34      0.28       945\n",
      "\n",
      "    accuracy                           0.71      5752\n",
      "   macro avg       0.55      0.57      0.55      5752\n",
      "weighted avg       0.76      0.71      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5522973996973217 \n",
      "test accuracy: 0.7140 \n",
      "train accuracy: 0.7025 \n",
      "ROAUC: 0.5712624776698002 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82      4807\n",
      "           1       0.24      0.34      0.28       945\n",
      "\n",
      "    accuracy                           0.71      5752\n",
      "   macro avg       0.55      0.57      0.55      5752\n",
      "weighted avg       0.76      0.71      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "637:\n",
      "\n",
      "Threshold: 127.427\n",
      "number of features with scores above the threshold: 14\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5520460833140766 \n",
      "test accuracy: 0.7137 \n",
      "train accuracy: 0.7023 \n",
      "ROAUC: 0.5709300700147383 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82      4807\n",
      "           1       0.24      0.34      0.28       945\n",
      "\n",
      "    accuracy                           0.71      5752\n",
      "   macro avg       0.55      0.57      0.55      5752\n",
      "weighted avg       0.76      0.71      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.552171721605512 \n",
      "test accuracy: 0.7138 \n",
      "train accuracy: 0.7024 \n",
      "ROAUC: 0.5710461925564899 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82      4807\n",
      "           1       0.24      0.34      0.28       945\n",
      "\n",
      "    accuracy                           0.71      5752\n",
      "   macro avg       0.55      0.57      0.55      5752\n",
      "weighted avg       0.76      0.71      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "638:\n",
      "\n",
      "Threshold: 127.627\n",
      "number of features with scores above the threshold: 13\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5520460833140766 \n",
      "test accuracy: 0.7137 \n",
      "train accuracy: 0.7021 \n",
      "ROAUC: 0.5713674832667969 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82      4807\n",
      "           1       0.24      0.34      0.28       945\n",
      "\n",
      "    accuracy                           0.71      5752\n",
      "   macro avg       0.55      0.57      0.55      5752\n",
      "weighted avg       0.76      0.71      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.552171721605512 \n",
      "test accuracy: 0.7138 \n",
      "train accuracy: 0.7023 \n",
      "ROAUC: 0.5716183299707325 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82      4807\n",
      "           1       0.24      0.34      0.28       945\n",
      "\n",
      "    accuracy                           0.71      5752\n",
      "   macro avg       0.55      0.57      0.55      5752\n",
      "weighted avg       0.76      0.71      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "639:\n",
      "\n",
      "Threshold: 127.8271\n",
      "number of features with scores above the threshold: 12\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5513340675393151 \n",
      "test accuracy: 0.7123 \n",
      "train accuracy: 0.7010 \n",
      "ROAUC: 0.5702993760201998 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82      4807\n",
      "           1       0.24      0.34      0.28       945\n",
      "\n",
      "    accuracy                           0.71      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.71      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5519204847483771 \n",
      "test accuracy: 0.7135 \n",
      "train accuracy: 0.7021 \n",
      "ROAUC: 0.5705888568588798 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82      4807\n",
      "           1       0.24      0.34      0.28       945\n",
      "\n",
      "    accuracy                           0.71      5752\n",
      "   macro avg       0.55      0.57      0.55      5752\n",
      "weighted avg       0.76      0.71      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "640:\n",
      "\n",
      "Threshold: 128.0271\n",
      "number of features with scores above the threshold: 12\n",
      "641:\n",
      "\n",
      "Threshold: 128.2271\n",
      "number of features with scores above the threshold: 12\n",
      "642:\n",
      "\n",
      "Threshold: 128.4272\n",
      "number of features with scores above the threshold: 11\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5514594880632258 \n",
      "test accuracy: 0.7124 \n",
      "train accuracy: 0.7013 \n",
      "ROAUC: 0.5704500601525774 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82      4807\n",
      "           1       0.24      0.34      0.28       945\n",
      "\n",
      "    accuracy                           0.71      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.71      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5514594880632258 \n",
      "test accuracy: 0.7124 \n",
      "train accuracy: 0.7013 \n",
      "ROAUC: 0.5706763615230435 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82      4807\n",
      "           1       0.24      0.34      0.28       945\n",
      "\n",
      "    accuracy                           0.71      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.71      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "643:\n",
      "\n",
      "Threshold: 128.6272\n",
      "number of features with scores above the threshold: 11\n",
      "644:\n",
      "\n",
      "Threshold: 128.8273\n",
      "number of features with scores above the threshold: 11\n",
      "645:\n",
      "\n",
      "Threshold: 129.0273\n",
      "number of features with scores above the threshold: 11\n",
      "646:\n",
      "\n",
      "Threshold: 129.2274\n",
      "number of features with scores above the threshold: 11\n",
      "647:\n",
      "\n",
      "Threshold: 129.4274\n",
      "number of features with scores above the threshold: 10\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5565051254429866 \n",
      "test accuracy: 0.7870 \n",
      "train accuracy: 0.7815 \n",
      "ROAUC: 0.5533831284403369 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      4807\n",
      "           1       0.29      0.20      0.24       945\n",
      "\n",
      "    accuracy                           0.79      5752\n",
      "   macro avg       0.57      0.55      0.56      5752\n",
      "weighted avg       0.76      0.79      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 0 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5563837973929147 \n",
      "test accuracy: 0.7856 \n",
      "train accuracy: 0.7806 \n",
      "ROAUC: 0.5533835687153765 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      4807\n",
      "           1       0.29      0.20      0.24       945\n",
      "\n",
      "    accuracy                           0.79      5752\n",
      "   macro avg       0.57      0.55      0.56      5752\n",
      "weighted avg       0.76      0.79      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 0 seconds\n",
      "648:\n",
      "\n",
      "Threshold: 129.6274\n",
      "number of features with scores above the threshold: 10\n",
      "649:\n",
      "\n",
      "Threshold: 129.8275\n",
      "number of features with scores above the threshold: 10\n",
      "650:\n",
      "\n",
      "Threshold: 130.0275\n",
      "number of features with scores above the threshold: 10\n",
      "651:\n",
      "\n",
      "Threshold: 130.2276\n",
      "number of features with scores above the threshold: 10\n",
      "652:\n",
      "\n",
      "Threshold: 130.4276\n",
      "number of features with scores above the threshold: 10\n",
      "653:\n",
      "\n",
      "Threshold: 130.6277\n",
      "number of features with scores above the threshold: 10\n",
      "654:\n",
      "\n",
      "Threshold: 130.8277\n",
      "number of features with scores above the threshold: 10\n",
      "655:\n",
      "\n",
      "Threshold: 131.0277\n",
      "number of features with scores above the threshold: 10\n",
      "656:\n",
      "\n",
      "Threshold: 131.2278\n",
      "number of features with scores above the threshold: 10\n",
      "657:\n",
      "\n",
      "Threshold: 131.4278\n",
      "number of features with scores above the threshold: 10\n",
      "658:\n",
      "\n",
      "Threshold: 131.6279\n",
      "number of features with scores above the threshold: 10\n",
      "659:\n",
      "\n",
      "Threshold: 131.8279\n",
      "number of features with scores above the threshold: 10\n",
      "660:\n",
      "\n",
      "Threshold: 132.028\n",
      "number of features with scores above the threshold: 10\n",
      "661:\n",
      "\n",
      "Threshold: 132.228\n",
      "number of features with scores above the threshold: 10\n",
      "662:\n",
      "\n",
      "Threshold: 132.428\n",
      "number of features with scores above the threshold: 10\n",
      "663:\n",
      "\n",
      "Threshold: 132.6281\n",
      "number of features with scores above the threshold: 10\n",
      "664:\n",
      "\n",
      "Threshold: 132.8281\n",
      "number of features with scores above the threshold: 10\n",
      "665:\n",
      "\n",
      "Threshold: 133.0282\n",
      "number of features with scores above the threshold: 10\n",
      "666:\n",
      "\n",
      "Threshold: 133.2282\n",
      "number of features with scores above the threshold: 10\n",
      "667:\n",
      "\n",
      "Threshold: 133.4283\n",
      "number of features with scores above the threshold: 10\n",
      "668:\n",
      "\n",
      "Threshold: 133.6283\n",
      "number of features with scores above the threshold: 10\n",
      "669:\n",
      "\n",
      "Threshold: 133.8283\n",
      "number of features with scores above the threshold: 10\n",
      "670:\n",
      "\n",
      "Threshold: 134.0284\n",
      "number of features with scores above the threshold: 10\n",
      "671:\n",
      "\n",
      "Threshold: 134.2284\n",
      "number of features with scores above the threshold: 10\n",
      "672:\n",
      "\n",
      "Threshold: 134.4285\n",
      "number of features with scores above the threshold: 10\n",
      "673:\n",
      "\n",
      "Threshold: 134.6285\n",
      "number of features with scores above the threshold: 10\n",
      "674:\n",
      "\n",
      "Threshold: 134.8285\n",
      "number of features with scores above the threshold: 10\n",
      "675:\n",
      "\n",
      "Threshold: 135.0286\n",
      "number of features with scores above the threshold: 10\n",
      "676:\n",
      "\n",
      "Threshold: 135.2286\n",
      "number of features with scores above the threshold: 10\n",
      "677:\n",
      "\n",
      "Threshold: 135.4287\n",
      "number of features with scores above the threshold: 10\n",
      "678:\n",
      "\n",
      "Threshold: 135.6287\n",
      "number of features with scores above the threshold: 10\n",
      "679:\n",
      "\n",
      "Threshold: 135.8288\n",
      "number of features with scores above the threshold: 10\n",
      "680:\n",
      "\n",
      "Threshold: 136.0288\n",
      "number of features with scores above the threshold: 10\n",
      "681:\n",
      "\n",
      "Threshold: 136.2288\n",
      "number of features with scores above the threshold: 10\n",
      "682:\n",
      "\n",
      "Threshold: 136.4289\n",
      "number of features with scores above the threshold: 10\n",
      "683:\n",
      "\n",
      "Threshold: 136.6289\n",
      "number of features with scores above the threshold: 10\n",
      "684:\n",
      "\n",
      "Threshold: 136.829\n",
      "number of features with scores above the threshold: 10\n",
      "685:\n",
      "\n",
      "Threshold: 137.029\n",
      "number of features with scores above the threshold: 10\n",
      "686:\n",
      "\n",
      "Threshold: 137.2291\n",
      "number of features with scores above the threshold: 10\n",
      "687:\n",
      "\n",
      "Threshold: 137.4291\n",
      "number of features with scores above the threshold: 10\n",
      "688:\n",
      "\n",
      "Threshold: 137.6291\n",
      "number of features with scores above the threshold: 10\n",
      "689:\n",
      "\n",
      "Threshold: 137.8292\n",
      "number of features with scores above the threshold: 10\n",
      "690:\n",
      "\n",
      "Threshold: 138.0292\n",
      "number of features with scores above the threshold: 10\n",
      "691:\n",
      "\n",
      "Threshold: 138.2293\n",
      "number of features with scores above the threshold: 10\n",
      "692:\n",
      "\n",
      "Threshold: 138.4293\n",
      "number of features with scores above the threshold: 10\n",
      "693:\n",
      "\n",
      "Threshold: 138.6294\n",
      "number of features with scores above the threshold: 10\n",
      "694:\n",
      "\n",
      "Threshold: 138.8294\n",
      "number of features with scores above the threshold: 10\n",
      "695:\n",
      "\n",
      "Threshold: 139.0294\n",
      "number of features with scores above the threshold: 10\n",
      "696:\n",
      "\n",
      "Threshold: 139.2295\n",
      "number of features with scores above the threshold: 10\n",
      "697:\n",
      "\n",
      "Threshold: 139.4295\n",
      "number of features with scores above the threshold: 10\n",
      "698:\n",
      "\n",
      "Threshold: 139.6296\n",
      "number of features with scores above the threshold: 10\n",
      "699:\n",
      "\n",
      "Threshold: 139.8296\n",
      "number of features with scores above the threshold: 10\n",
      "700:\n",
      "\n",
      "Threshold: 140.0296\n",
      "number of features with scores above the threshold: 10\n",
      "701:\n",
      "\n",
      "Threshold: 140.2297\n",
      "number of features with scores above the threshold: 10\n",
      "702:\n",
      "\n",
      "Threshold: 140.4297\n",
      "number of features with scores above the threshold: 10\n",
      "703:\n",
      "\n",
      "Threshold: 140.6298\n",
      "number of features with scores above the threshold: 10\n",
      "704:\n",
      "\n",
      "Threshold: 140.8298\n",
      "number of features with scores above the threshold: 10\n",
      "705:\n",
      "\n",
      "Threshold: 141.0299\n",
      "number of features with scores above the threshold: 10\n",
      "706:\n",
      "\n",
      "Threshold: 141.2299\n",
      "number of features with scores above the threshold: 10\n",
      "707:\n",
      "\n",
      "Threshold: 141.4299\n",
      "number of features with scores above the threshold: 10\n",
      "708:\n",
      "\n",
      "Threshold: 141.63\n",
      "number of features with scores above the threshold: 10\n",
      "709:\n",
      "\n",
      "Threshold: 141.83\n",
      "number of features with scores above the threshold: 10\n",
      "710:\n",
      "\n",
      "Threshold: 142.0301\n",
      "number of features with scores above the threshold: 10\n",
      "711:\n",
      "\n",
      "Threshold: 142.2301\n",
      "number of features with scores above the threshold: 10\n",
      "712:\n",
      "\n",
      "Threshold: 142.4302\n",
      "number of features with scores above the threshold: 10\n",
      "713:\n",
      "\n",
      "Threshold: 142.6302\n",
      "number of features with scores above the threshold: 10\n",
      "714:\n",
      "\n",
      "Threshold: 142.8302\n",
      "number of features with scores above the threshold: 10\n",
      "715:\n",
      "\n",
      "Threshold: 143.0303\n",
      "number of features with scores above the threshold: 10\n",
      "716:\n",
      "\n",
      "Threshold: 143.2303\n",
      "number of features with scores above the threshold: 10\n",
      "717:\n",
      "\n",
      "Threshold: 143.4304\n",
      "number of features with scores above the threshold: 10\n",
      "718:\n",
      "\n",
      "Threshold: 143.6304\n",
      "number of features with scores above the threshold: 10\n",
      "719:\n",
      "\n",
      "Threshold: 143.8305\n",
      "number of features with scores above the threshold: 10\n",
      "720:\n",
      "\n",
      "Threshold: 144.0305\n",
      "number of features with scores above the threshold: 10\n",
      "721:\n",
      "\n",
      "Threshold: 144.2305\n",
      "number of features with scores above the threshold: 10\n",
      "722:\n",
      "\n",
      "Threshold: 144.4306\n",
      "number of features with scores above the threshold: 10\n",
      "723:\n",
      "\n",
      "Threshold: 144.6306\n",
      "number of features with scores above the threshold: 10\n",
      "724:\n",
      "\n",
      "Threshold: 144.8307\n",
      "number of features with scores above the threshold: 10\n",
      "725:\n",
      "\n",
      "Threshold: 145.0307\n",
      "number of features with scores above the threshold: 10\n",
      "726:\n",
      "\n",
      "Threshold: 145.2307\n",
      "number of features with scores above the threshold: 10\n",
      "727:\n",
      "\n",
      "Threshold: 145.4308\n",
      "number of features with scores above the threshold: 10\n",
      "728:\n",
      "\n",
      "Threshold: 145.6308\n",
      "number of features with scores above the threshold: 10\n",
      "729:\n",
      "\n",
      "Threshold: 145.8309\n",
      "number of features with scores above the threshold: 10\n",
      "730:\n",
      "\n",
      "Threshold: 146.0309\n",
      "number of features with scores above the threshold: 10\n",
      "731:\n",
      "\n",
      "Threshold: 146.231\n",
      "number of features with scores above the threshold: 10\n",
      "732:\n",
      "\n",
      "Threshold: 146.431\n",
      "number of features with scores above the threshold: 10\n",
      "733:\n",
      "\n",
      "Threshold: 146.631\n",
      "number of features with scores above the threshold: 10\n",
      "734:\n",
      "\n",
      "Threshold: 146.8311\n",
      "number of features with scores above the threshold: 10\n",
      "735:\n",
      "\n",
      "Threshold: 147.0311\n",
      "number of features with scores above the threshold: 10\n",
      "736:\n",
      "\n",
      "Threshold: 147.2312\n",
      "number of features with scores above the threshold: 10\n",
      "737:\n",
      "\n",
      "Threshold: 147.4312\n",
      "number of features with scores above the threshold: 10\n",
      "738:\n",
      "\n",
      "Threshold: 147.6313\n",
      "number of features with scores above the threshold: 10\n",
      "739:\n",
      "\n",
      "Threshold: 147.8313\n",
      "number of features with scores above the threshold: 10\n",
      "740:\n",
      "\n",
      "Threshold: 148.0313\n",
      "number of features with scores above the threshold: 10\n",
      "741:\n",
      "\n",
      "Threshold: 148.2314\n",
      "number of features with scores above the threshold: 10\n",
      "742:\n",
      "\n",
      "Threshold: 148.4314\n",
      "number of features with scores above the threshold: 10\n",
      "743:\n",
      "\n",
      "Threshold: 148.6315\n",
      "number of features with scores above the threshold: 10\n",
      "744:\n",
      "\n",
      "Threshold: 148.8315\n",
      "number of features with scores above the threshold: 10\n",
      "745:\n",
      "\n",
      "Threshold: 149.0316\n",
      "number of features with scores above the threshold: 10\n",
      "746:\n",
      "\n",
      "Threshold: 149.2316\n",
      "number of features with scores above the threshold: 10\n",
      "747:\n",
      "\n",
      "Threshold: 149.4316\n",
      "number of features with scores above the threshold: 10\n",
      "748:\n",
      "\n",
      "Threshold: 149.6317\n",
      "number of features with scores above the threshold: 10\n",
      "749:\n",
      "\n",
      "Threshold: 149.8317\n",
      "number of features with scores above the threshold: 10\n",
      "750:\n",
      "\n",
      "Threshold: 150.0318\n",
      "number of features with scores above the threshold: 10\n",
      "751:\n",
      "\n",
      "Threshold: 150.2318\n",
      "number of features with scores above the threshold: 10\n",
      "752:\n",
      "\n",
      "Threshold: 150.4319\n",
      "number of features with scores above the threshold: 10\n",
      "753:\n",
      "\n",
      "Threshold: 150.6319\n",
      "number of features with scores above the threshold: 10\n",
      "754:\n",
      "\n",
      "Threshold: 150.8319\n",
      "number of features with scores above the threshold: 10\n",
      "755:\n",
      "\n",
      "Threshold: 151.032\n",
      "number of features with scores above the threshold: 10\n",
      "756:\n",
      "\n",
      "Threshold: 151.232\n",
      "number of features with scores above the threshold: 10\n",
      "757:\n",
      "\n",
      "Threshold: 151.4321\n",
      "number of features with scores above the threshold: 10\n",
      "758:\n",
      "\n",
      "Threshold: 151.6321\n",
      "number of features with scores above the threshold: 10\n",
      "759:\n",
      "\n",
      "Threshold: 151.8321\n",
      "number of features with scores above the threshold: 10\n",
      "760:\n",
      "\n",
      "Threshold: 152.0322\n",
      "number of features with scores above the threshold: 10\n",
      "761:\n",
      "\n",
      "Threshold: 152.2322\n",
      "number of features with scores above the threshold: 10\n",
      "762:\n",
      "\n",
      "Threshold: 152.4323\n",
      "number of features with scores above the threshold: 10\n",
      "763:\n",
      "\n",
      "Threshold: 152.6323\n",
      "number of features with scores above the threshold: 10\n",
      "764:\n",
      "\n",
      "Threshold: 152.8324\n",
      "number of features with scores above the threshold: 10\n",
      "765:\n",
      "\n",
      "Threshold: 153.0324\n",
      "number of features with scores above the threshold: 10\n",
      "766:\n",
      "\n",
      "Threshold: 153.2324\n",
      "number of features with scores above the threshold: 10\n",
      "767:\n",
      "\n",
      "Threshold: 153.4325\n",
      "number of features with scores above the threshold: 10\n",
      "768:\n",
      "\n",
      "Threshold: 153.6325\n",
      "number of features with scores above the threshold: 10\n",
      "769:\n",
      "\n",
      "Threshold: 153.8326\n",
      "number of features with scores above the threshold: 10\n",
      "770:\n",
      "\n",
      "Threshold: 154.0326\n",
      "number of features with scores above the threshold: 10\n",
      "771:\n",
      "\n",
      "Threshold: 154.2327\n",
      "number of features with scores above the threshold: 10\n",
      "772:\n",
      "\n",
      "Threshold: 154.4327\n",
      "number of features with scores above the threshold: 10\n",
      "773:\n",
      "\n",
      "Threshold: 154.6327\n",
      "number of features with scores above the threshold: 10\n",
      "774:\n",
      "\n",
      "Threshold: 154.8328\n",
      "number of features with scores above the threshold: 10\n",
      "775:\n",
      "\n",
      "Threshold: 155.0328\n",
      "number of features with scores above the threshold: 10\n",
      "776:\n",
      "\n",
      "Threshold: 155.2329\n",
      "number of features with scores above the threshold: 10\n",
      "777:\n",
      "\n",
      "Threshold: 155.4329\n",
      "number of features with scores above the threshold: 10\n",
      "778:\n",
      "\n",
      "Threshold: 155.633\n",
      "number of features with scores above the threshold: 10\n",
      "779:\n",
      "\n",
      "Threshold: 155.833\n",
      "number of features with scores above the threshold: 10\n",
      "780:\n",
      "\n",
      "Threshold: 156.033\n",
      "number of features with scores above the threshold: 10\n",
      "781:\n",
      "\n",
      "Threshold: 156.2331\n",
      "number of features with scores above the threshold: 10\n",
      "782:\n",
      "\n",
      "Threshold: 156.4331\n",
      "number of features with scores above the threshold: 10\n",
      "783:\n",
      "\n",
      "Threshold: 156.6332\n",
      "number of features with scores above the threshold: 10\n",
      "784:\n",
      "\n",
      "Threshold: 156.8332\n",
      "number of features with scores above the threshold: 10\n",
      "785:\n",
      "\n",
      "Threshold: 157.0332\n",
      "number of features with scores above the threshold: 10\n",
      "786:\n",
      "\n",
      "Threshold: 157.2333\n",
      "number of features with scores above the threshold: 10\n",
      "787:\n",
      "\n",
      "Threshold: 157.4333\n",
      "number of features with scores above the threshold: 10\n",
      "788:\n",
      "\n",
      "Threshold: 157.6334\n",
      "number of features with scores above the threshold: 10\n",
      "789:\n",
      "\n",
      "Threshold: 157.8334\n",
      "number of features with scores above the threshold: 10\n",
      "790:\n",
      "\n",
      "Threshold: 158.0335\n",
      "number of features with scores above the threshold: 10\n",
      "791:\n",
      "\n",
      "Threshold: 158.2335\n",
      "number of features with scores above the threshold: 10\n",
      "792:\n",
      "\n",
      "Threshold: 158.4335\n",
      "number of features with scores above the threshold: 10\n",
      "793:\n",
      "\n",
      "Threshold: 158.6336\n",
      "number of features with scores above the threshold: 10\n",
      "794:\n",
      "\n",
      "Threshold: 158.8336\n",
      "number of features with scores above the threshold: 10\n",
      "795:\n",
      "\n",
      "Threshold: 159.0337\n",
      "number of features with scores above the threshold: 10\n",
      "796:\n",
      "\n",
      "Threshold: 159.2337\n",
      "number of features with scores above the threshold: 10\n",
      "797:\n",
      "\n",
      "Threshold: 159.4338\n",
      "number of features with scores above the threshold: 10\n",
      "798:\n",
      "\n",
      "Threshold: 159.6338\n",
      "number of features with scores above the threshold: 10\n",
      "799:\n",
      "\n",
      "Threshold: 159.8338\n",
      "number of features with scores above the threshold: 10\n",
      "800:\n",
      "\n",
      "Threshold: 160.0339\n",
      "number of features with scores above the threshold: 10\n",
      "801:\n",
      "\n",
      "Threshold: 160.2339\n",
      "number of features with scores above the threshold: 10\n",
      "802:\n",
      "\n",
      "Threshold: 160.434\n",
      "number of features with scores above the threshold: 10\n",
      "803:\n",
      "\n",
      "Threshold: 160.634\n",
      "number of features with scores above the threshold: 10\n",
      "804:\n",
      "\n",
      "Threshold: 160.8341\n",
      "number of features with scores above the threshold: 10\n",
      "805:\n",
      "\n",
      "Threshold: 161.0341\n",
      "number of features with scores above the threshold: 10\n",
      "806:\n",
      "\n",
      "Threshold: 161.2341\n",
      "number of features with scores above the threshold: 10\n",
      "807:\n",
      "\n",
      "Threshold: 161.4342\n",
      "number of features with scores above the threshold: 10\n",
      "808:\n",
      "\n",
      "Threshold: 161.6342\n",
      "number of features with scores above the threshold: 10\n",
      "809:\n",
      "\n",
      "Threshold: 161.8343\n",
      "number of features with scores above the threshold: 10\n",
      "810:\n",
      "\n",
      "Threshold: 162.0343\n",
      "number of features with scores above the threshold: 10\n",
      "811:\n",
      "\n",
      "Threshold: 162.2343\n",
      "number of features with scores above the threshold: 10\n",
      "812:\n",
      "\n",
      "Threshold: 162.4344\n",
      "number of features with scores above the threshold: 10\n",
      "813:\n",
      "\n",
      "Threshold: 162.6344\n",
      "number of features with scores above the threshold: 10\n",
      "814:\n",
      "\n",
      "Threshold: 162.8345\n",
      "number of features with scores above the threshold: 10\n",
      "815:\n",
      "\n",
      "Threshold: 163.0345\n",
      "number of features with scores above the threshold: 10\n",
      "816:\n",
      "\n",
      "Threshold: 163.2346\n",
      "number of features with scores above the threshold: 10\n",
      "817:\n",
      "\n",
      "Threshold: 163.4346\n",
      "number of features with scores above the threshold: 10\n",
      "818:\n",
      "\n",
      "Threshold: 163.6346\n",
      "number of features with scores above the threshold: 10\n",
      "819:\n",
      "\n",
      "Threshold: 163.8347\n",
      "number of features with scores above the threshold: 10\n",
      "820:\n",
      "\n",
      "Threshold: 164.0347\n",
      "number of features with scores above the threshold: 10\n",
      "821:\n",
      "\n",
      "Threshold: 164.2348\n",
      "number of features with scores above the threshold: 10\n",
      "822:\n",
      "\n",
      "Threshold: 164.4348\n",
      "number of features with scores above the threshold: 10\n",
      "823:\n",
      "\n",
      "Threshold: 164.6349\n",
      "number of features with scores above the threshold: 10\n",
      "824:\n",
      "\n",
      "Threshold: 164.8349\n",
      "number of features with scores above the threshold: 10\n",
      "825:\n",
      "\n",
      "Threshold: 165.0349\n",
      "number of features with scores above the threshold: 10\n",
      "826:\n",
      "\n",
      "Threshold: 165.235\n",
      "number of features with scores above the threshold: 10\n",
      "827:\n",
      "\n",
      "Threshold: 165.435\n",
      "number of features with scores above the threshold: 10\n",
      "828:\n",
      "\n",
      "Threshold: 165.6351\n",
      "number of features with scores above the threshold: 10\n",
      "829:\n",
      "\n",
      "Threshold: 165.8351\n",
      "number of features with scores above the threshold: 10\n",
      "830:\n",
      "\n",
      "Threshold: 166.0352\n",
      "number of features with scores above the threshold: 10\n",
      "831:\n",
      "\n",
      "Threshold: 166.2352\n",
      "number of features with scores above the threshold: 10\n",
      "832:\n",
      "\n",
      "Threshold: 166.4352\n",
      "number of features with scores above the threshold: 10\n",
      "833:\n",
      "\n",
      "Threshold: 166.6353\n",
      "number of features with scores above the threshold: 10\n",
      "834:\n",
      "\n",
      "Threshold: 166.8353\n",
      "number of features with scores above the threshold: 10\n",
      "835:\n",
      "\n",
      "Threshold: 167.0354\n",
      "number of features with scores above the threshold: 10\n",
      "836:\n",
      "\n",
      "Threshold: 167.2354\n",
      "number of features with scores above the threshold: 10\n",
      "837:\n",
      "\n",
      "Threshold: 167.4355\n",
      "number of features with scores above the threshold: 10\n",
      "838:\n",
      "\n",
      "Threshold: 167.6355\n",
      "number of features with scores above the threshold: 10\n",
      "839:\n",
      "\n",
      "Threshold: 167.8355\n",
      "number of features with scores above the threshold: 10\n",
      "840:\n",
      "\n",
      "Threshold: 168.0356\n",
      "number of features with scores above the threshold: 10\n",
      "841:\n",
      "\n",
      "Threshold: 168.2356\n",
      "number of features with scores above the threshold: 10\n",
      "842:\n",
      "\n",
      "Threshold: 168.4357\n",
      "number of features with scores above the threshold: 10\n",
      "843:\n",
      "\n",
      "Threshold: 168.6357\n",
      "number of features with scores above the threshold: 10\n",
      "844:\n",
      "\n",
      "Threshold: 168.8357\n",
      "number of features with scores above the threshold: 10\n",
      "845:\n",
      "\n",
      "Threshold: 169.0358\n",
      "number of features with scores above the threshold: 10\n",
      "846:\n",
      "\n",
      "Threshold: 169.2358\n",
      "number of features with scores above the threshold: 10\n",
      "847:\n",
      "\n",
      "Threshold: 169.4359\n",
      "number of features with scores above the threshold: 10\n",
      "848:\n",
      "\n",
      "Threshold: 169.6359\n",
      "number of features with scores above the threshold: 10\n",
      "849:\n",
      "\n",
      "Threshold: 169.836\n",
      "number of features with scores above the threshold: 10\n",
      "850:\n",
      "\n",
      "Threshold: 170.036\n",
      "number of features with scores above the threshold: 10\n",
      "851:\n",
      "\n",
      "Threshold: 170.236\n",
      "number of features with scores above the threshold: 10\n",
      "852:\n",
      "\n",
      "Threshold: 170.4361\n",
      "number of features with scores above the threshold: 10\n",
      "853:\n",
      "\n",
      "Threshold: 170.6361\n",
      "number of features with scores above the threshold: 10\n",
      "854:\n",
      "\n",
      "Threshold: 170.8362\n",
      "number of features with scores above the threshold: 10\n",
      "855:\n",
      "\n",
      "Threshold: 171.0362\n",
      "number of features with scores above the threshold: 10\n",
      "856:\n",
      "\n",
      "Threshold: 171.2363\n",
      "number of features with scores above the threshold: 10\n",
      "857:\n",
      "\n",
      "Threshold: 171.4363\n",
      "number of features with scores above the threshold: 10\n",
      "858:\n",
      "\n",
      "Threshold: 171.6363\n",
      "number of features with scores above the threshold: 10\n",
      "859:\n",
      "\n",
      "Threshold: 171.8364\n",
      "number of features with scores above the threshold: 10\n",
      "860:\n",
      "\n",
      "Threshold: 172.0364\n",
      "number of features with scores above the threshold: 10\n",
      "861:\n",
      "\n",
      "Threshold: 172.2365\n",
      "number of features with scores above the threshold: 10\n",
      "862:\n",
      "\n",
      "Threshold: 172.4365\n",
      "number of features with scores above the threshold: 10\n",
      "863:\n",
      "\n",
      "Threshold: 172.6366\n",
      "number of features with scores above the threshold: 10\n",
      "864:\n",
      "\n",
      "Threshold: 172.8366\n",
      "number of features with scores above the threshold: 10\n",
      "865:\n",
      "\n",
      "Threshold: 173.0366\n",
      "number of features with scores above the threshold: 10\n",
      "866:\n",
      "\n",
      "Threshold: 173.2367\n",
      "number of features with scores above the threshold: 10\n",
      "867:\n",
      "\n",
      "Threshold: 173.4367\n",
      "number of features with scores above the threshold: 10\n",
      "868:\n",
      "\n",
      "Threshold: 173.6368\n",
      "number of features with scores above the threshold: 10\n",
      "869:\n",
      "\n",
      "Threshold: 173.8368\n",
      "number of features with scores above the threshold: 10\n",
      "870:\n",
      "\n",
      "Threshold: 174.0368\n",
      "number of features with scores above the threshold: 10\n",
      "871:\n",
      "\n",
      "Threshold: 174.2369\n",
      "number of features with scores above the threshold: 10\n",
      "872:\n",
      "\n",
      "Threshold: 174.4369\n",
      "number of features with scores above the threshold: 10\n",
      "873:\n",
      "\n",
      "Threshold: 174.637\n",
      "number of features with scores above the threshold: 10\n",
      "874:\n",
      "\n",
      "Threshold: 174.837\n",
      "number of features with scores above the threshold: 10\n",
      "875:\n",
      "\n",
      "Threshold: 175.0371\n",
      "number of features with scores above the threshold: 10\n",
      "876:\n",
      "\n",
      "Threshold: 175.2371\n",
      "number of features with scores above the threshold: 10\n",
      "877:\n",
      "\n",
      "Threshold: 175.4371\n",
      "number of features with scores above the threshold: 10\n",
      "878:\n",
      "\n",
      "Threshold: 175.6372\n",
      "number of features with scores above the threshold: 10\n",
      "879:\n",
      "\n",
      "Threshold: 175.8372\n",
      "number of features with scores above the threshold: 10\n",
      "880:\n",
      "\n",
      "Threshold: 176.0373\n",
      "number of features with scores above the threshold: 10\n",
      "881:\n",
      "\n",
      "Threshold: 176.2373\n",
      "number of features with scores above the threshold: 10\n",
      "882:\n",
      "\n",
      "Threshold: 176.4374\n",
      "number of features with scores above the threshold: 10\n",
      "883:\n",
      "\n",
      "Threshold: 176.6374\n",
      "number of features with scores above the threshold: 10\n",
      "884:\n",
      "\n",
      "Threshold: 176.8374\n",
      "number of features with scores above the threshold: 10\n",
      "885:\n",
      "\n",
      "Threshold: 177.0375\n",
      "number of features with scores above the threshold: 10\n",
      "886:\n",
      "\n",
      "Threshold: 177.2375\n",
      "number of features with scores above the threshold: 10\n",
      "887:\n",
      "\n",
      "Threshold: 177.4376\n",
      "number of features with scores above the threshold: 10\n",
      "888:\n",
      "\n",
      "Threshold: 177.6376\n",
      "number of features with scores above the threshold: 10\n",
      "889:\n",
      "\n",
      "Threshold: 177.8377\n",
      "number of features with scores above the threshold: 10\n",
      "890:\n",
      "\n",
      "Threshold: 178.0377\n",
      "number of features with scores above the threshold: 10\n",
      "891:\n",
      "\n",
      "Threshold: 178.2377\n",
      "number of features with scores above the threshold: 10\n",
      "892:\n",
      "\n",
      "Threshold: 178.4378\n",
      "number of features with scores above the threshold: 10\n",
      "893:\n",
      "\n",
      "Threshold: 178.6378\n",
      "number of features with scores above the threshold: 10\n",
      "894:\n",
      "\n",
      "Threshold: 178.8379\n",
      "number of features with scores above the threshold: 10\n",
      "895:\n",
      "\n",
      "Threshold: 179.0379\n",
      "number of features with scores above the threshold: 10\n",
      "896:\n",
      "\n",
      "Threshold: 179.2379\n",
      "number of features with scores above the threshold: 10\n",
      "897:\n",
      "\n",
      "Threshold: 179.438\n",
      "number of features with scores above the threshold: 10\n",
      "898:\n",
      "\n",
      "Threshold: 179.638\n",
      "number of features with scores above the threshold: 10\n",
      "899:\n",
      "\n",
      "Threshold: 179.8381\n",
      "number of features with scores above the threshold: 10\n",
      "900:\n",
      "\n",
      "Threshold: 180.0381\n",
      "number of features with scores above the threshold: 10\n",
      "901:\n",
      "\n",
      "Threshold: 180.2382\n",
      "number of features with scores above the threshold: 10\n",
      "902:\n",
      "\n",
      "Threshold: 180.4382\n",
      "number of features with scores above the threshold: 10\n",
      "903:\n",
      "\n",
      "Threshold: 180.6382\n",
      "number of features with scores above the threshold: 10\n",
      "904:\n",
      "\n",
      "Threshold: 180.8383\n",
      "number of features with scores above the threshold: 10\n",
      "905:\n",
      "\n",
      "Threshold: 181.0383\n",
      "number of features with scores above the threshold: 10\n",
      "906:\n",
      "\n",
      "Threshold: 181.2384\n",
      "number of features with scores above the threshold: 10\n",
      "907:\n",
      "\n",
      "Threshold: 181.4384\n",
      "number of features with scores above the threshold: 10\n",
      "908:\n",
      "\n",
      "Threshold: 181.6385\n",
      "number of features with scores above the threshold: 10\n",
      "909:\n",
      "\n",
      "Threshold: 181.8385\n",
      "number of features with scores above the threshold: 10\n",
      "910:\n",
      "\n",
      "Threshold: 182.0385\n",
      "number of features with scores above the threshold: 10\n",
      "911:\n",
      "\n",
      "Threshold: 182.2386\n",
      "number of features with scores above the threshold: 10\n",
      "912:\n",
      "\n",
      "Threshold: 182.4386\n",
      "number of features with scores above the threshold: 10\n",
      "913:\n",
      "\n",
      "Threshold: 182.6387\n",
      "number of features with scores above the threshold: 10\n",
      "914:\n",
      "\n",
      "Threshold: 182.8387\n",
      "number of features with scores above the threshold: 10\n",
      "915:\n",
      "\n",
      "Threshold: 183.0388\n",
      "number of features with scores above the threshold: 10\n",
      "916:\n",
      "\n",
      "Threshold: 183.2388\n",
      "number of features with scores above the threshold: 10\n",
      "917:\n",
      "\n",
      "Threshold: 183.4388\n",
      "number of features with scores above the threshold: 10\n",
      "918:\n",
      "\n",
      "Threshold: 183.6389\n",
      "number of features with scores above the threshold: 10\n",
      "919:\n",
      "\n",
      "Threshold: 183.8389\n",
      "number of features with scores above the threshold: 10\n",
      "920:\n",
      "\n",
      "Threshold: 184.039\n",
      "number of features with scores above the threshold: 10\n",
      "921:\n",
      "\n",
      "Threshold: 184.239\n",
      "number of features with scores above the threshold: 10\n",
      "922:\n",
      "\n",
      "Threshold: 184.4391\n",
      "number of features with scores above the threshold: 10\n",
      "923:\n",
      "\n",
      "Threshold: 184.6391\n",
      "number of features with scores above the threshold: 10\n",
      "924:\n",
      "\n",
      "Threshold: 184.8391\n",
      "number of features with scores above the threshold: 10\n",
      "925:\n",
      "\n",
      "Threshold: 185.0392\n",
      "number of features with scores above the threshold: 10\n",
      "926:\n",
      "\n",
      "Threshold: 185.2392\n",
      "number of features with scores above the threshold: 10\n",
      "927:\n",
      "\n",
      "Threshold: 185.4393\n",
      "number of features with scores above the threshold: 10\n",
      "928:\n",
      "\n",
      "Threshold: 185.6393\n",
      "number of features with scores above the threshold: 10\n",
      "929:\n",
      "\n",
      "Threshold: 185.8393\n",
      "number of features with scores above the threshold: 9\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5563746478086444 \n",
      "test accuracy: 0.7869 \n",
      "train accuracy: 0.7815 \n",
      "ROAUC: 0.5527590385713954 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      4807\n",
      "           1       0.29      0.20      0.24       945\n",
      "\n",
      "    accuracy                           0.79      5752\n",
      "   macro avg       0.57      0.55      0.56      5752\n",
      "weighted avg       0.76      0.79      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5565757275568228 \n",
      "test accuracy: 0.7865 \n",
      "train accuracy: 0.7815 \n",
      "ROAUC: 0.5527707058599506 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      4807\n",
      "           1       0.29      0.20      0.24       945\n",
      "\n",
      "    accuracy                           0.79      5752\n",
      "   macro avg       0.57      0.55      0.56      5752\n",
      "weighted avg       0.76      0.79      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 0 seconds\n",
      "930:\n",
      "\n",
      "Threshold: 186.0394\n",
      "number of features with scores above the threshold: 9\n",
      "931:\n",
      "\n",
      "Threshold: 186.2394\n",
      "number of features with scores above the threshold: 8\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5563746478086444 \n",
      "test accuracy: 0.7869 \n",
      "train accuracy: 0.7814 \n",
      "ROAUC: 0.5529198490296887 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      4807\n",
      "           1       0.29      0.20      0.24       945\n",
      "\n",
      "    accuracy                           0.79      5752\n",
      "   macro avg       0.57      0.55      0.56      5752\n",
      "weighted avg       0.76      0.79      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5568247443870451 \n",
      "test accuracy: 0.7881 \n",
      "train accuracy: 0.7824 \n",
      "ROAUC: 0.5512507663537412 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      4807\n",
      "           1       0.29      0.20      0.24       945\n",
      "\n",
      "    accuracy                           0.79      5752\n",
      "   macro avg       0.57      0.55      0.56      5752\n",
      "weighted avg       0.76      0.79      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 0 seconds\n",
      "932:\n",
      "\n",
      "Threshold: 186.4395\n",
      "number of features with scores above the threshold: 8\n",
      "933:\n",
      "\n",
      "Threshold: 186.6395\n",
      "number of features with scores above the threshold: 8\n",
      "934:\n",
      "\n",
      "Threshold: 186.8396\n",
      "number of features with scores above the threshold: 8\n",
      "935:\n",
      "\n",
      "Threshold: 187.0396\n",
      "number of features with scores above the threshold: 8\n",
      "936:\n",
      "\n",
      "Threshold: 187.2396\n",
      "number of features with scores above the threshold: 8\n",
      "937:\n",
      "\n",
      "Threshold: 187.4397\n",
      "number of features with scores above the threshold: 8\n",
      "938:\n",
      "\n",
      "Threshold: 187.6397\n",
      "number of features with scores above the threshold: 8\n",
      "939:\n",
      "\n",
      "Threshold: 187.8398\n",
      "number of features with scores above the threshold: 8\n",
      "940:\n",
      "\n",
      "Threshold: 188.0398\n",
      "number of features with scores above the threshold: 8\n",
      "941:\n",
      "\n",
      "Threshold: 188.2399\n",
      "number of features with scores above the threshold: 8\n",
      "942:\n",
      "\n",
      "Threshold: 188.4399\n",
      "number of features with scores above the threshold: 8\n",
      "943:\n",
      "\n",
      "Threshold: 188.6399\n",
      "number of features with scores above the threshold: 7\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5554635420691865 \n",
      "test accuracy: 0.7856 \n",
      "train accuracy: 0.7800 \n",
      "ROAUC: 0.5510745462690542 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      4807\n",
      "           1       0.28      0.20      0.24       945\n",
      "\n",
      "    accuracy                           0.79      5752\n",
      "   macro avg       0.57      0.55      0.56      5752\n",
      "weighted avg       0.76      0.79      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 0 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5559112320209577 \n",
      "test accuracy: 0.7869 \n",
      "train accuracy: 0.7810 \n",
      "ROAUC: 0.5493970983673501 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      4807\n",
      "           1       0.29      0.20      0.24       945\n",
      "\n",
      "    accuracy                           0.79      5752\n",
      "   macro avg       0.57      0.55      0.56      5752\n",
      "weighted avg       0.76      0.79      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 0 seconds\n",
      "944:\n",
      "\n",
      "Threshold: 188.84\n",
      "number of features with scores above the threshold: 7\n",
      "945:\n",
      "\n",
      "Threshold: 189.04\n",
      "number of features with scores above the threshold: 7\n",
      "946:\n",
      "\n",
      "Threshold: 189.2401\n",
      "number of features with scores above the threshold: 7\n",
      "947:\n",
      "\n",
      "Threshold: 189.4401\n",
      "number of features with scores above the threshold: 7\n",
      "948:\n",
      "\n",
      "Threshold: 189.6402\n",
      "number of features with scores above the threshold: 7\n",
      "949:\n",
      "\n",
      "Threshold: 189.8402\n",
      "number of features with scores above the threshold: 7\n",
      "950:\n",
      "\n",
      "Threshold: 190.0402\n",
      "number of features with scores above the threshold: 7\n",
      "951:\n",
      "\n",
      "Threshold: 190.2403\n",
      "number of features with scores above the threshold: 7\n",
      "952:\n",
      "\n",
      "Threshold: 190.4403\n",
      "number of features with scores above the threshold: 7\n",
      "953:\n",
      "\n",
      "Threshold: 190.6404\n",
      "number of features with scores above the threshold: 7\n",
      "954:\n",
      "\n",
      "Threshold: 190.8404\n",
      "number of features with scores above the threshold: 7\n",
      "955:\n",
      "\n",
      "Threshold: 191.0404\n",
      "number of features with scores above the threshold: 6\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5554635420691865 \n",
      "test accuracy: 0.7856 \n",
      "train accuracy: 0.7798 \n",
      "ROAUC: 0.5508647552125813 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      4807\n",
      "           1       0.28      0.20      0.24       945\n",
      "\n",
      "    accuracy                           0.79      5752\n",
      "   macro avg       0.57      0.55      0.56      5752\n",
      "weighted avg       0.76      0.79      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 0 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5559112320209577 \n",
      "test accuracy: 0.7869 \n",
      "train accuracy: 0.7808 \n",
      "ROAUC: 0.5508640948000216 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      4807\n",
      "           1       0.29      0.20      0.24       945\n",
      "\n",
      "    accuracy                           0.79      5752\n",
      "   macro avg       0.57      0.55      0.56      5752\n",
      "weighted avg       0.76      0.79      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 0 seconds\n",
      "956:\n",
      "\n",
      "Threshold: 191.2405\n",
      "number of features with scores above the threshold: 6\n",
      "957:\n",
      "\n",
      "Threshold: 191.4405\n",
      "number of features with scores above the threshold: 6\n",
      "958:\n",
      "\n",
      "Threshold: 191.6406\n",
      "number of features with scores above the threshold: 6\n",
      "959:\n",
      "\n",
      "Threshold: 191.8406\n",
      "number of features with scores above the threshold: 6\n",
      "960:\n",
      "\n",
      "Threshold: 192.0407\n",
      "number of features with scores above the threshold: 6\n",
      "961:\n",
      "\n",
      "Threshold: 192.2407\n",
      "number of features with scores above the threshold: 6\n",
      "962:\n",
      "\n",
      "Threshold: 192.4407\n",
      "number of features with scores above the threshold: 5\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5552039402068847 \n",
      "test accuracy: 0.7853 \n",
      "train accuracy: 0.7795 \n",
      "ROAUC: 0.551658350971852 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      4807\n",
      "           1       0.28      0.20      0.24       945\n",
      "\n",
      "    accuracy                           0.79      5752\n",
      "   macro avg       0.57      0.55      0.56      5752\n",
      "weighted avg       0.76      0.79      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 0 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5556509522912034 \n",
      "test accuracy: 0.7865 \n",
      "train accuracy: 0.7807 \n",
      "ROAUC: 0.5516617631034105 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      4807\n",
      "           1       0.29      0.20      0.24       945\n",
      "\n",
      "    accuracy                           0.79      5752\n",
      "   macro avg       0.57      0.55      0.56      5752\n",
      "weighted avg       0.76      0.79      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 0 seconds\n",
      "963:\n",
      "\n",
      "Threshold: 192.6408\n",
      "number of features with scores above the threshold: 5\n",
      "964:\n",
      "\n",
      "Threshold: 192.8408\n",
      "number of features with scores above the threshold: 5\n",
      "965:\n",
      "\n",
      "Threshold: 193.0409\n",
      "number of features with scores above the threshold: 5\n",
      "966:\n",
      "\n",
      "Threshold: 193.2409\n",
      "number of features with scores above the threshold: 5\n",
      "967:\n",
      "\n",
      "Threshold: 193.441\n",
      "number of features with scores above the threshold: 5\n",
      "968:\n",
      "\n",
      "Threshold: 193.641\n",
      "number of features with scores above the threshold: 5\n",
      "969:\n",
      "\n",
      "Threshold: 193.841\n",
      "number of features with scores above the threshold: 5\n",
      "970:\n",
      "\n",
      "Threshold: 194.0411\n",
      "number of features with scores above the threshold: 4\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5553909916866758 \n",
      "test accuracy: 0.7862 \n",
      "train accuracy: 0.7805 \n",
      "ROAUC: 0.5495682552890788 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      4807\n",
      "           1       0.29      0.20      0.24       945\n",
      "\n",
      "    accuracy                           0.79      5752\n",
      "   macro avg       0.57      0.55      0.56      5752\n",
      "weighted avg       0.76      0.79      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 0 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5565633366891662 \n",
      "test accuracy: 0.7877 \n",
      "train accuracy: 0.7814 \n",
      "ROAUC: 0.5512584711669378 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      4807\n",
      "           1       0.29      0.20      0.24       945\n",
      "\n",
      "    accuracy                           0.79      5752\n",
      "   macro avg       0.57      0.55      0.56      5752\n",
      "weighted avg       0.76      0.79      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 0 seconds\n",
      "971:\n",
      "\n",
      "Threshold: 194.2411\n",
      "number of features with scores above the threshold: 4\n",
      "972:\n",
      "\n",
      "Threshold: 194.4412\n",
      "number of features with scores above the threshold: 4\n",
      "973:\n",
      "\n",
      "Threshold: 194.6412\n",
      "number of features with scores above the threshold: 4\n",
      "974:\n",
      "\n",
      "Threshold: 194.8413\n",
      "number of features with scores above the threshold: 4\n",
      "975:\n",
      "\n",
      "Threshold: 195.0413\n",
      "number of features with scores above the threshold: 4\n",
      "976:\n",
      "\n",
      "Threshold: 195.2413\n",
      "number of features with scores above the threshold: 4\n",
      "977:\n",
      "\n",
      "Threshold: 195.4414\n",
      "number of features with scores above the threshold: 4\n",
      "978:\n",
      "\n",
      "Threshold: 195.6414\n",
      "number of features with scores above the threshold: 4\n",
      "979:\n",
      "\n",
      "Threshold: 195.8415\n",
      "number of features with scores above the threshold: 4\n",
      "980:\n",
      "\n",
      "Threshold: 196.0415\n",
      "number of features with scores above the threshold: 3\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5552611306223111 \n",
      "test accuracy: 0.7860 \n",
      "train accuracy: 0.7804 \n",
      "ROAUC: 0.5497663790569969 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      4807\n",
      "           1       0.28      0.20      0.23       945\n",
      "\n",
      "    accuracy                           0.79      5752\n",
      "   macro avg       0.57      0.55      0.56      5752\n",
      "weighted avg       0.76      0.79      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 0 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5565633366891662 \n",
      "test accuracy: 0.7877 \n",
      "train accuracy: 0.7814 \n",
      "ROAUC: 0.5497714422199547 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      4807\n",
      "           1       0.29      0.20      0.24       945\n",
      "\n",
      "    accuracy                           0.79      5752\n",
      "   macro avg       0.57      0.55      0.56      5752\n",
      "weighted avg       0.76      0.79      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 0 seconds\n",
      "981:\n",
      "\n",
      "Threshold: 196.2416\n",
      "number of features with scores above the threshold: 3\n",
      "982:\n",
      "\n",
      "Threshold: 196.4416\n",
      "number of features with scores above the threshold: 3\n",
      "983:\n",
      "\n",
      "Threshold: 196.6416\n",
      "number of features with scores above the threshold: 3\n",
      "984:\n",
      "\n",
      "Threshold: 196.8417\n",
      "number of features with scores above the threshold: 3\n",
      "985:\n",
      "\n",
      "Threshold: 197.0417\n",
      "number of features with scores above the threshold: 3\n",
      "986:\n",
      "\n",
      "Threshold: 197.2418\n",
      "number of features with scores above the threshold: 3\n",
      "987:\n",
      "\n",
      "Threshold: 197.4418\n",
      "number of features with scores above the threshold: 2\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5564327544426495 \n",
      "test accuracy: 0.7876 \n",
      "train accuracy: 0.7812 \n",
      "ROAUC: 0.5508802749077348 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      4807\n",
      "           1       0.29      0.20      0.24       945\n",
      "\n",
      "    accuracy                           0.79      5752\n",
      "   macro avg       0.57      0.55      0.56      5752\n",
      "weighted avg       0.76      0.79      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 0 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5564327544426495 \n",
      "test accuracy: 0.7876 \n",
      "train accuracy: 0.7812 \n",
      "ROAUC: 0.5508945838465289 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      4807\n",
      "           1       0.29      0.20      0.24       945\n",
      "\n",
      "    accuracy                           0.79      5752\n",
      "   macro avg       0.57      0.55      0.56      5752\n",
      "weighted avg       0.76      0.79      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 0 seconds\n",
      "988:\n",
      "\n",
      "Threshold: 197.6418\n",
      "number of features with scores above the threshold: 2\n",
      "989:\n",
      "\n",
      "Threshold: 197.8419\n",
      "number of features with scores above the threshold: 2\n",
      "990:\n",
      "\n",
      "Threshold: 198.0419\n",
      "number of features with scores above the threshold: 2\n",
      "991:\n",
      "\n",
      "Threshold: 198.242\n",
      "number of features with scores above the threshold: 2\n",
      "992:\n",
      "\n",
      "Threshold: 198.442\n",
      "number of features with scores above the threshold: 2\n",
      "993:\n",
      "\n",
      "Threshold: 198.6421\n",
      "number of features with scores above the threshold: 2\n",
      "994:\n",
      "\n",
      "Threshold: 198.8421\n",
      "number of features with scores above the threshold: 2\n",
      "995:\n",
      "\n",
      "Threshold: 199.0421\n",
      "number of features with scores above the threshold: 2\n",
      "996:\n",
      "\n",
      "Threshold: 199.2422\n",
      "number of features with scores above the threshold: 1\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5547424772550246 \n",
      "test accuracy: 0.7853 \n",
      "train accuracy: 0.7799 \n",
      "ROAUC: 0.5501768254628666 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      4807\n",
      "           1       0.28      0.20      0.23       945\n",
      "\n",
      "    accuracy                           0.79      5752\n",
      "   macro avg       0.57      0.55      0.55      5752\n",
      "weighted avg       0.76      0.79      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 0 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5547424772550246 \n",
      "test accuracy: 0.7853 \n",
      "train accuracy: 0.7799 \n",
      "ROAUC: 0.5501768254628666 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      4807\n",
      "           1       0.28      0.20      0.23       945\n",
      "\n",
      "    accuracy                           0.79      5752\n",
      "   macro avg       0.57      0.55      0.55      5752\n",
      "weighted avg       0.76      0.79      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 0 seconds\n",
      "997:\n",
      "\n",
      "Threshold: 199.4422\n",
      "number of features with scores above the threshold: 1\n",
      "998:\n",
      "\n",
      "Threshold: 199.6423\n",
      "number of features with scores above the threshold: 1\n",
      "999:\n",
      "\n",
      "Threshold: 199.8423\n",
      "number of features with scores above the threshold: 1\n",
      "1000:\n",
      "\n",
      "Threshold: 200.0424\n",
      "number of features with scores above the threshold: 0\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "prev_num_features = 0\n",
    "for i in range(1001):\n",
    "    print(f\"{i}:\\n\")\n",
    "    threshold_itr = threshold_chi2 + round((range_chi2 * i / 1000), 4)\n",
    "    print(f\"Threshold: {threshold_itr}\")\n",
    "    num_features_itr = len([sc for sc in scores if sc > threshold_itr])\n",
    "    print(f\"number of features with scores above the threshold: {num_features_itr}\")\n",
    "    if prev_num_features != num_features_itr:\n",
    "        prev_num_features = num_features_itr\n",
    "    else:\n",
    "        continue\n",
    "    if num_features_itr == 0:\n",
    "        break\n",
    "    X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test, chi2, num_features_itr)\n",
    "    models, test_accuracies = train_random_forests(X_train_fs, y_train, X_test_fs, y_test, 2)\n",
    "    accuracy_scores.append((threshold_itr,np.mean(test_accuracies),num_features_itr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_th_chi2 = [i[0] for i in accuracy_scores]\n",
    "list_ac_chi2 = [i[1] for i in accuracy_scores]\n",
    "list_num_feat_chi2 = [i[2] for i in accuracy_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the min of accuracy or number of features\n",
    "min_ac_chi2 = min(list_ac_chi2)\n",
    "min_num_feat_chi2 = min(list_num_feat_chi2)\n",
    "min_pt = min(min_ac_chi2, min_num_feat_chi2)\n",
    "# the max of accuracy or number of features\n",
    "max_ac_chi2 = max(list_ac_chi2)\n",
    "max_num_feat_chi2 = max(list_num_feat_chi2)\n",
    "max_pt = max(max_ac_chi2, max_num_feat_chi2)\n",
    "\n",
    "# min and max of the thresholds RECORDER not corrosponding to the min and max of the accuracy\n",
    "min_th_chi2 = min(list_th_chi2)\n",
    "max_th_chi2 = max(list_th_chi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the accuracy scores\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(list_th_chi2, list_ac_chi2)\n",
    "plt.yticks(np.arange(min_pt, max_pt + (max_pt * 0.01), max_pt * 0.001))\n",
    "# red dot for the highest accuracy with the corresponding threshold rounded to 5 decimal places\n",
    "plt.plot(round(list_th_chi2[list_ac_chi2.index(max_ac_chi2)], 5), max_ac_chi2, 'ro')\n",
    "plt.annotate(f\"(Threshold: {round(list_th_chi2[list_ac_chi2.index(max_ac_chi2)], 5)}\\n, Accuracy: {round(max_ac_chi2, 5)})\", (round(list_th_chi2[list_ac_chi2.index(max_ac_chi2)], 5), max_ac_chi2))\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Threshold vs Accuracy')\n",
    "plt.savefig('outputs/00_feature_select_29/chi2_threshold_vs_accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold for the max accuracy: 21.0044\n"
     ]
    }
   ],
   "source": [
    "# get the threshold for the max accuracy\n",
    "th_max = [i[0] for i in accuracy_scores if i[1] == max_ac_chi2][0]\n",
    "print(f\"Threshold for the max accuracy: {round(th_max, 5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 63.0132\n",
      "number of features with scores above the threshold: 43\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5311105812329309 \n",
      "test accuracy: 0.6519 \n",
      "train accuracy: 0.7274 \n",
      "ROAUC: 0.5925988665119101 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.69      0.77      4807\n",
      "           1       0.22      0.44      0.29       945\n",
      "\n",
      "    accuracy                           0.65      5752\n",
      "   macro avg       0.54      0.57      0.53      5752\n",
      "weighted avg       0.76      0.65      0.69      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5294211659567926 \n",
      "test accuracy: 0.6483 \n",
      "train accuracy: 0.7245 \n",
      "ROAUC: 0.5930752441049925 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.69      0.77      4807\n",
      "           1       0.22      0.44      0.29       945\n",
      "\n",
      "    accuracy                           0.65      5752\n",
      "   macro avg       0.54      0.57      0.53      5752\n",
      "weighted avg       0.76      0.65      0.69      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "average test accuracy: 0.6501216968011126\n",
      "Threshold: 62.383067999999994\n",
      "number of features with scores above the threshold: 44\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5300512604486809 \n",
      "test accuracy: 0.6511 \n",
      "train accuracy: 0.7420 \n",
      "ROAUC: 0.5895426973230178 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.69      0.77      4807\n",
      "           1       0.22      0.44      0.29       945\n",
      "\n",
      "    accuracy                           0.65      5752\n",
      "   macro avg       0.54      0.57      0.53      5752\n",
      "weighted avg       0.76      0.65      0.69      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5323387129558113 \n",
      "test accuracy: 0.6537 \n",
      "train accuracy: 0.7447 \n",
      "ROAUC: 0.5914276248372358 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.70      0.77      4807\n",
      "           1       0.22      0.44      0.29       945\n",
      "\n",
      "    accuracy                           0.65      5752\n",
      "   macro avg       0.54      0.57      0.53      5752\n",
      "weighted avg       0.76      0.65      0.69      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "average test accuracy: 0.6523817802503478\n",
      "Threshold: 61.75293599999999\n",
      "number of features with scores above the threshold: 44\n",
      "Threshold: 61.12280399999999\n",
      "number of features with scores above the threshold: 45\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5352781096808682 \n",
      "test accuracy: 0.6737 \n",
      "train accuracy: 0.7756 \n",
      "ROAUC: 0.5938062107398492 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.73      0.79      4807\n",
      "           1       0.22      0.39      0.28       945\n",
      "\n",
      "    accuracy                           0.67      5752\n",
      "   macro avg       0.54      0.56      0.54      5752\n",
      "weighted avg       0.75      0.67      0.71      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5364131820062983 \n",
      "test accuracy: 0.6728 \n",
      "train accuracy: 0.7739 \n",
      "ROAUC: 0.5939356516015555 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.73      0.79      4807\n",
      "           1       0.22      0.40      0.28       945\n",
      "\n",
      "    accuracy                           0.67      5752\n",
      "   macro avg       0.54      0.56      0.54      5752\n",
      "weighted avg       0.76      0.67      0.71      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "average test accuracy: 0.6732440890125174\n",
      "Threshold: 60.492671999999985\n",
      "number of features with scores above the threshold: 45\n",
      "Threshold: 59.86253999999998\n",
      "number of features with scores above the threshold: 46\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5412292380109075 \n",
      "test accuracy: 0.6895 \n",
      "train accuracy: 0.7997 \n",
      "ROAUC: 0.605800293443314 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80      4807\n",
      "           1       0.23      0.37      0.28       945\n",
      "\n",
      "    accuracy                           0.69      5752\n",
      "   macro avg       0.54      0.56      0.54      5752\n",
      "weighted avg       0.75      0.69      0.72      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.54344598206596 \n",
      "test accuracy: 0.6904 \n",
      "train accuracy: 0.8015 \n",
      "ROAUC: 0.6045285589908016 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80      4807\n",
      "           1       0.23      0.37      0.28       945\n",
      "\n",
      "    accuracy                           0.69      5752\n",
      "   macro avg       0.54      0.56      0.54      5752\n",
      "weighted avg       0.76      0.69      0.72      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "average test accuracy: 0.6899339360222532\n",
      "Threshold: 59.23240799999998\n",
      "number of features with scores above the threshold: 46\n",
      "Threshold: 58.602275999999975\n",
      "number of features with scores above the threshold: 46\n",
      "Threshold: 57.97214399999997\n",
      "number of features with scores above the threshold: 47\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5406347175809896 \n",
      "test accuracy: 0.6937 \n",
      "train accuracy: 0.8083 \n",
      "ROAUC: 0.6062821744743941 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.76      0.81      4807\n",
      "           1       0.23      0.35      0.28       945\n",
      "\n",
      "    accuracy                           0.69      5752\n",
      "   macro avg       0.54      0.56      0.54      5752\n",
      "weighted avg       0.75      0.69      0.72      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.539714051160424 \n",
      "test accuracy: 0.6932 \n",
      "train accuracy: 0.8097 \n",
      "ROAUC: 0.6025419279423856 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.76      0.81      4807\n",
      "           1       0.22      0.35      0.27       945\n",
      "\n",
      "    accuracy                           0.69      5752\n",
      "   macro avg       0.54      0.56      0.54      5752\n",
      "weighted avg       0.75      0.69      0.72      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.6934109874826148\n",
      "Threshold: 57.34201199999997\n",
      "number of features with scores above the threshold: 47\n",
      "Threshold: 56.711879999999965\n",
      "number of features with scores above the threshold: 47\n",
      "Threshold: 56.08174799999996\n",
      "number of features with scores above the threshold: 48\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5490393836060232 \n",
      "test accuracy: 0.7055 \n",
      "train accuracy: 0.8256 \n",
      "ROAUC: 0.6133138071353175 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.77      0.81      4807\n",
      "           1       0.24      0.35      0.28       945\n",
      "\n",
      "    accuracy                           0.71      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.71      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5410871537246422 \n",
      "test accuracy: 0.7011 \n",
      "train accuracy: 0.8273 \n",
      "ROAUC: 0.6068414338437221 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.77      0.81      4807\n",
      "           1       0.23      0.34      0.27       945\n",
      "\n",
      "    accuracy                           0.70      5752\n",
      "   macro avg       0.54      0.55      0.54      5752\n",
      "weighted avg       0.75      0.70      0.72      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "average test accuracy: 0.7033205841446453\n",
      "Threshold: 55.45161599999996\n",
      "number of features with scores above the threshold: 48\n",
      "Threshold: 54.821483999999955\n",
      "number of features with scores above the threshold: 48\n",
      "Threshold: 54.19135199999995\n",
      "number of features with scores above the threshold: 48\n",
      "Threshold: 53.56121999999995\n",
      "number of features with scores above the threshold: 48\n",
      "Threshold: 52.931087999999946\n",
      "number of features with scores above the threshold: 48\n",
      "Threshold: 52.30095599999994\n",
      "number of features with scores above the threshold: 48\n",
      "Threshold: 51.67082399999994\n",
      "number of features with scores above the threshold: 50\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5501117360761819 \n",
      "test accuracy: 0.7337 \n",
      "train accuracy: 0.8585 \n",
      "ROAUC: 0.613874277261005 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.84      4807\n",
      "           1       0.24      0.29      0.26       945\n",
      "\n",
      "    accuracy                           0.73      5752\n",
      "   macro avg       0.55      0.55      0.55      5752\n",
      "weighted avg       0.75      0.73      0.74      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5543659233153065 \n",
      "test accuracy: 0.7340 \n",
      "train accuracy: 0.8587 \n",
      "ROAUC: 0.6120497774960018 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84      4807\n",
      "           1       0.25      0.30      0.27       945\n",
      "\n",
      "    accuracy                           0.73      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.73      0.74      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.7338317107093185\n",
      "Threshold: 51.040691999999936\n",
      "number of features with scores above the threshold: 50\n",
      "Threshold: 50.41055999999993\n",
      "number of features with scores above the threshold: 51\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5525423060326429 \n",
      "test accuracy: 0.7394 \n",
      "train accuracy: 0.8668 \n",
      "ROAUC: 0.6150304395155654 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84      4807\n",
      "           1       0.25      0.28      0.26       945\n",
      "\n",
      "    accuracy                           0.74      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.75      0.74      0.75      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.553357535786878 \n",
      "test accuracy: 0.7396 \n",
      "train accuracy: 0.8674 \n",
      "ROAUC: 0.6133942673988441 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84      4807\n",
      "           1       0.25      0.29      0.26       945\n",
      "\n",
      "    accuracy                           0.74      5752\n",
      "   macro avg       0.55      0.56      0.55      5752\n",
      "weighted avg       0.76      0.74      0.75      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.739481919332406\n",
      "Threshold: 49.78042799999993\n",
      "number of features with scores above the threshold: 51\n",
      "Threshold: 49.150295999999926\n",
      "number of features with scores above the threshold: 52\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5449964566508542 \n",
      "test accuracy: 0.7470 \n",
      "train accuracy: 0.8859 \n",
      "ROAUC: 0.6108647772263334 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85      4807\n",
      "           1       0.24      0.25      0.24       945\n",
      "\n",
      "    accuracy                           0.75      5752\n",
      "   macro avg       0.54      0.55      0.54      5752\n",
      "weighted avg       0.75      0.75      0.75      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5397075411967223 \n",
      "test accuracy: 0.7450 \n",
      "train accuracy: 0.8869 \n",
      "ROAUC: 0.612080266542509 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85      4807\n",
      "           1       0.23      0.23      0.23       945\n",
      "\n",
      "    accuracy                           0.74      5752\n",
      "   macro avg       0.54      0.54      0.54      5752\n",
      "weighted avg       0.75      0.74      0.75      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.7460013908205841\n",
      "Threshold: 48.52016399999992\n",
      "number of features with scores above the threshold: 52\n",
      "Threshold: 47.89003199999992\n",
      "number of features with scores above the threshold: 52\n",
      "Threshold: 47.25989999999992\n",
      "number of features with scores above the threshold: 53\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5466364237453639 \n",
      "test accuracy: 0.7622 \n",
      "train accuracy: 0.9018 \n",
      "ROAUC: 0.6192319842205426 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86      4807\n",
      "           1       0.25      0.22      0.23       945\n",
      "\n",
      "    accuracy                           0.76      5752\n",
      "   macro avg       0.55      0.54      0.55      5752\n",
      "weighted avg       0.75      0.76      0.76      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.549949981392473 \n",
      "test accuracy: 0.7616 \n",
      "train accuracy: 0.9025 \n",
      "ROAUC: 0.617545950955562 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86      4807\n",
      "           1       0.25      0.23      0.24       945\n",
      "\n",
      "    accuracy                           0.76      5752\n",
      "   macro avg       0.55      0.55      0.55      5752\n",
      "weighted avg       0.75      0.76      0.76      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.7619089012517385\n",
      "Threshold: 46.62976799999991\n",
      "number of features with scores above the threshold: 54\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5478002756804068 \n",
      "test accuracy: 0.7783 \n",
      "train accuracy: 0.9251 \n",
      "ROAUC: 0.6184373978424322 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      4807\n",
      "           1       0.26      0.20      0.22       945\n",
      "\n",
      "    accuracy                           0.78      5752\n",
      "   macro avg       0.56      0.54      0.55      5752\n",
      "weighted avg       0.75      0.78      0.76      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5456722769777264 \n",
      "test accuracy: 0.7773 \n",
      "train accuracy: 0.9266 \n",
      "ROAUC: 0.6171621411896011 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      4807\n",
      "           1       0.26      0.19      0.22       945\n",
      "\n",
      "    accuracy                           0.78      5752\n",
      "   macro avg       0.55      0.54      0.55      5752\n",
      "weighted avg       0.75      0.78      0.76      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.777816411682893\n",
      "Threshold: 45.99963599999991\n",
      "number of features with scores above the threshold: 54\n",
      "Threshold: 45.36950399999991\n",
      "number of features with scores above the threshold: 56\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5340344020491079 \n",
      "test accuracy: 0.7959 \n",
      "train accuracy: 0.9525 \n",
      "ROAUC: 0.6067394001032445 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88      4807\n",
      "           1       0.27      0.14      0.18       945\n",
      "\n",
      "    accuracy                           0.80      5752\n",
      "   macro avg       0.56      0.53      0.53      5752\n",
      "weighted avg       0.75      0.80      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5325271103945663 \n",
      "test accuracy: 0.7945 \n",
      "train accuracy: 0.9523 \n",
      "ROAUC: 0.6115551284887669 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88      4807\n",
      "           1       0.26      0.14      0.18       945\n",
      "\n",
      "    accuracy                           0.79      5752\n",
      "   macro avg       0.55      0.53      0.53      5752\n",
      "weighted avg       0.75      0.79      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.795201668984701\n",
      "Threshold: 44.7393719999999\n",
      "number of features with scores above the threshold: 57\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5329907938233495 \n",
      "test accuracy: 0.8018 \n",
      "train accuracy: 0.9599 \n",
      "ROAUC: 0.6127948329321328 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89      4807\n",
      "           1       0.28      0.13      0.18       945\n",
      "\n",
      "    accuracy                           0.80      5752\n",
      "   macro avg       0.56      0.53      0.53      5752\n",
      "weighted avg       0.75      0.80      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5280680504522827 \n",
      "test accuracy: 0.8006 \n",
      "train accuracy: 0.9597 \n",
      "ROAUC: 0.613512701384555 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.89      4807\n",
      "           1       0.27      0.12      0.17       945\n",
      "\n",
      "    accuracy                           0.80      5752\n",
      "   macro avg       0.56      0.53      0.53      5752\n",
      "weighted avg       0.75      0.80      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8011995827538247\n",
      "Threshold: 44.1092399999999\n",
      "number of features with scores above the threshold: 57\n",
      "Threshold: 43.4791079999999\n",
      "number of features with scores above the threshold: 57\n",
      "Threshold: 42.848975999999894\n",
      "number of features with scores above the threshold: 57\n",
      "Threshold: 42.21884399999989\n",
      "number of features with scores above the threshold: 57\n",
      "Threshold: 41.58871199999989\n",
      "number of features with scores above the threshold: 57\n",
      "Threshold: 40.958579999999884\n",
      "number of features with scores above the threshold: 60\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5288833650503292 \n",
      "test accuracy: 0.8147 \n",
      "train accuracy: 0.9752 \n",
      "ROAUC: 0.6284273485646483 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.90      4807\n",
      "           1       0.31      0.11      0.16       945\n",
      "\n",
      "    accuracy                           0.81      5752\n",
      "   macro avg       0.58      0.53      0.53      5752\n",
      "weighted avg       0.76      0.81      0.78      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5267176841529402 \n",
      "test accuracy: 0.8124 \n",
      "train accuracy: 0.9750 \n",
      "ROAUC: 0.6242770959018099 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      4807\n",
      "           1       0.30      0.11      0.16       945\n",
      "\n",
      "    accuracy                           0.81      5752\n",
      "   macro avg       0.57      0.53      0.53      5752\n",
      "weighted avg       0.76      0.81      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8135431154381085\n",
      "Threshold: 40.32844799999988\n",
      "number of features with scores above the threshold: 60\n",
      "Threshold: 39.69831599999988\n",
      "number of features with scores above the threshold: 60\n",
      "Threshold: 39.068183999999874\n",
      "number of features with scores above the threshold: 61\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5191176619330825 \n",
      "test accuracy: 0.8161 \n",
      "train accuracy: 0.9814 \n",
      "ROAUC: 0.6286024679617357 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90      4807\n",
      "           1       0.30      0.09      0.14       945\n",
      "\n",
      "    accuracy                           0.82      5752\n",
      "   macro avg       0.57      0.53      0.52      5752\n",
      "weighted avg       0.75      0.82      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5254809442893554 \n",
      "test accuracy: 0.8185 \n",
      "train accuracy: 0.9812 \n",
      "ROAUC: 0.6245407105819003 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90      4807\n",
      "           1       0.33      0.10      0.15       945\n",
      "\n",
      "    accuracy                           0.82      5752\n",
      "   macro avg       0.59      0.53      0.53      5752\n",
      "weighted avg       0.76      0.82      0.78      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8172809457579973\n",
      "Threshold: 38.43805199999987\n",
      "number of features with scores above the threshold: 63\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5136755560517208 \n",
      "test accuracy: 0.8209 \n",
      "train accuracy: 0.9855 \n",
      "ROAUC: 0.6423441123669956 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90      4807\n",
      "           1       0.32      0.08      0.13       945\n",
      "\n",
      "    accuracy                           0.82      5752\n",
      "   macro avg       0.58      0.52      0.51      5752\n",
      "weighted avg       0.76      0.82      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5203306164919194 \n",
      "test accuracy: 0.8223 \n",
      "train accuracy: 0.9854 \n",
      "ROAUC: 0.6373608593288227 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90      4807\n",
      "           1       0.34      0.09      0.14       945\n",
      "\n",
      "    accuracy                           0.82      5752\n",
      "   macro avg       0.59      0.53      0.52      5752\n",
      "weighted avg       0.76      0.82      0.78      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8216272600834492\n",
      "Threshold: 37.80791999999987\n",
      "number of features with scores above the threshold: 63\n",
      "Threshold: 37.177787999999865\n",
      "number of features with scores above the threshold: 65\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5159716320358032 \n",
      "test accuracy: 0.8270 \n",
      "train accuracy: 0.9891 \n",
      "ROAUC: 0.6436884922010779 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90      4807\n",
      "           1       0.37      0.08      0.13       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.61      0.53      0.52      5752\n",
      "weighted avg       0.77      0.83      0.78      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5209041599375352 \n",
      "test accuracy: 0.8277 \n",
      "train accuracy: 0.9891 \n",
      "ROAUC: 0.6475154729159306 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90      4807\n",
      "           1       0.39      0.08      0.14       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.62      0.53      0.52      5752\n",
      "weighted avg       0.77      0.83      0.78      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8273643949930458\n",
      "Threshold: 36.54765599999986\n",
      "number of features with scores above the threshold: 65\n",
      "Threshold: 35.91752399999986\n",
      "number of features with scores above the threshold: 68\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5054377686903638 \n",
      "test accuracy: 0.8289 \n",
      "train accuracy: 0.9929 \n",
      "ROAUC: 0.6484966258421636 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91      4807\n",
      "           1       0.37      0.06      0.11       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.61      0.52      0.51      5752\n",
      "weighted avg       0.76      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.49695114562533915 \n",
      "test accuracy: 0.8268 \n",
      "train accuracy: 0.9930 \n",
      "ROAUC: 0.6442682243597575 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.90      4807\n",
      "           1       0.33      0.05      0.09       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.58      0.52      0.50      5752\n",
      "weighted avg       0.76      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8278859527121001\n",
      "Threshold: 35.287391999999855\n",
      "number of features with scores above the threshold: 68\n",
      "Threshold: 34.65725999999985\n",
      "number of features with scores above the threshold: 69\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4972456723799778 \n",
      "test accuracy: 0.8289 \n",
      "train accuracy: 0.9935 \n",
      "ROAUC: 0.649944690448123 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91      4807\n",
      "           1       0.36      0.05      0.09       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.60      0.52      0.50      5752\n",
      "weighted avg       0.76      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.49900367209013907 \n",
      "test accuracy: 0.8291 \n",
      "train accuracy: 0.9936 \n",
      "ROAUC: 0.6484937640544048 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91      4807\n",
      "           1       0.36      0.05      0.09       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.60      0.52      0.50      5752\n",
      "weighted avg       0.76      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8290159944367177\n",
      "Threshold: 34.02712799999985\n",
      "number of features with scores above the threshold: 69\n",
      "Threshold: 33.396995999999845\n",
      "number of features with scores above the threshold: 69\n",
      "Threshold: 32.76686399999984\n",
      "number of features with scores above the threshold: 70\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5020995721764131 \n",
      "test accuracy: 0.8288 \n",
      "train accuracy: 0.9937 \n",
      "ROAUC: 0.6486496214185002 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91      4807\n",
      "           1       0.36      0.06      0.10       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.60      0.52      0.50      5752\n",
      "weighted avg       0.76      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.49944837454984525 \n",
      "test accuracy: 0.8284 \n",
      "train accuracy: 0.9938 \n",
      "ROAUC: 0.6507448903329911 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91      4807\n",
      "           1       0.35      0.05      0.09       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.60      0.52      0.50      5752\n",
      "weighted avg       0.76      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8285813630041725\n",
      "Threshold: 32.13673199999984\n",
      "number of features with scores above the threshold: 70\n",
      "Threshold: 31.50659999999984\n",
      "number of features with scores above the threshold: 73\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.49672561920083785 \n",
      "test accuracy: 0.8343 \n",
      "train accuracy: 0.9978 \n",
      "ROAUC: 0.6578908844355068 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.46      0.05      0.08       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.65      0.52      0.50      5752\n",
      "weighted avg       0.78      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.49108841891535954 \n",
      "test accuracy: 0.8336 \n",
      "train accuracy: 0.9978 \n",
      "ROAUC: 0.6563592776407422 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.43      0.04      0.07       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.64      0.51      0.49      5752\n",
      "weighted avg       0.77      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8339707927677329\n",
      "Threshold: 30.87646799999984\n",
      "number of features with scores above the threshold: 73\n",
      "Threshold: 30.24633599999984\n",
      "number of features with scores above the threshold: 73\n",
      "Threshold: 29.61620399999984\n",
      "number of features with scores above the threshold: 76\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.49063386127510467 \n",
      "test accuracy: 0.8345 \n",
      "train accuracy: 0.9985 \n",
      "ROAUC: 0.6709705753184014 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.46      0.04      0.07       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.65      0.52      0.49      5752\n",
      "weighted avg       0.78      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.49277405513529315 \n",
      "test accuracy: 0.8352 \n",
      "train accuracy: 0.9985 \n",
      "ROAUC: 0.6645208761913567 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.48      0.04      0.08       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.66      0.52      0.49      5752\n",
      "weighted avg       0.78      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8348400556328233\n",
      "Threshold: 28.98607199999984\n",
      "number of features with scores above the threshold: 77\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.49491424899548186 \n",
      "test accuracy: 0.8359 \n",
      "train accuracy: 0.9986 \n",
      "ROAUC: 0.6621386580196649 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.51      0.04      0.08       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.67      0.52      0.49      5752\n",
      "weighted avg       0.79      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4969616294012228 \n",
      "test accuracy: 0.8364 \n",
      "train accuracy: 0.9986 \n",
      "ROAUC: 0.6617055374492447 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.52      0.05      0.08       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.68      0.52      0.50      5752\n",
      "weighted avg       0.79      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8361439499304589\n",
      "Threshold: 28.35593999999984\n",
      "number of features with scores above the threshold: 77\n",
      "Threshold: 27.72580799999984\n",
      "number of features with scores above the threshold: 77\n",
      "Threshold: 27.09567599999984\n",
      "number of features with scores above the threshold: 78\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4899092694922728 \n",
      "test accuracy: 0.8348 \n",
      "train accuracy: 0.9987 \n",
      "ROAUC: 0.6614685594090629 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.47      0.04      0.07       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.65      0.51      0.49      5752\n",
      "weighted avg       0.78      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.49420477038075894 \n",
      "test accuracy: 0.8362 \n",
      "train accuracy: 0.9987 \n",
      "ROAUC: 0.6698959740149673 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.52      0.04      0.08       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.68      0.52      0.49      5752\n",
      "weighted avg       0.79      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8355354659248957\n",
      "Threshold: 26.46554399999984\n",
      "number of features with scores above the threshold: 79\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.48827005891998054 \n",
      "test accuracy: 0.8352 \n",
      "train accuracy: 0.9992 \n",
      "ROAUC: 0.6666460838085553 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.48      0.04      0.07       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.66      0.51      0.49      5752\n",
      "weighted avg       0.78      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.48861018144447343 \n",
      "test accuracy: 0.8359 \n",
      "train accuracy: 0.9992 \n",
      "ROAUC: 0.6675007677296007 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.51      0.04      0.07       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.67      0.51      0.49      5752\n",
      "weighted avg       0.79      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8355354659248957\n",
      "Threshold: 25.83541199999984\n",
      "number of features with scores above the threshold: 80\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4846833336502537 \n",
      "test accuracy: 0.8354 \n",
      "train accuracy: 0.9992 \n",
      "ROAUC: 0.6710181250227018 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.48      0.03      0.06       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.66      0.51      0.48      5752\n",
      "weighted avg       0.78      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4929439934661303 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 0.9992 \n",
      "ROAUC: 0.6727657967932567 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.57      0.04      0.08       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.70      0.52      0.49      5752\n",
      "weighted avg       0.80      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8363178025034771\n",
      "Threshold: 25.205279999999842\n",
      "number of features with scores above the threshold: 81\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4870270042302063 \n",
      "test accuracy: 0.8364 \n",
      "train accuracy: 0.9995 \n",
      "ROAUC: 0.6714261499158525 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.53      0.03      0.06       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.69      0.51      0.49      5752\n",
      "weighted avg       0.79      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.48886585759134915 \n",
      "test accuracy: 0.8364 \n",
      "train accuracy: 0.9995 \n",
      "ROAUC: 0.665156743417613 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.53      0.04      0.07       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.69      0.51      0.49      5752\n",
      "weighted avg       0.79      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8364047287899861\n",
      "Threshold: 24.575147999999842\n",
      "number of features with scores above the threshold: 82\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4893787355199424 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 0.9995 \n",
      "ROAUC: 0.6792128542700625 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.59      0.04      0.07       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.71      0.52      0.49      5752\n",
      "weighted avg       0.80      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.49095135928687217 \n",
      "test accuracy: 0.8369 \n",
      "train accuracy: 0.9995 \n",
      "ROAUC: 0.667697680741159 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.55      0.04      0.07       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.70      0.52      0.49      5752\n",
      "weighted avg       0.79      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8371870653685675\n",
      "Threshold: 23.945015999999843\n",
      "number of features with scores above the threshold: 86\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.485747214016736 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 0.9997 \n",
      "ROAUC: 0.6703748831895285 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.61      0.03      0.06       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.73      0.51      0.49      5752\n",
      "weighted avg       0.80      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.48727796739410156 \n",
      "test accuracy: 0.8369 \n",
      "train accuracy: 0.9997 \n",
      "ROAUC: 0.668054413592171 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.56      0.03      0.06       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.70      0.51      0.49      5752\n",
      "weighted avg       0.79      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8372739916550764\n",
      "Threshold: 23.314883999999843\n",
      "number of features with scores above the threshold: 87\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.48260206461432714 \n",
      "test accuracy: 0.8369 \n",
      "train accuracy: 0.9997 \n",
      "ROAUC: 0.6782800215294496 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.57      0.03      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.71      0.51      0.48      5752\n",
      "weighted avg       0.80      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4862675171158462 \n",
      "test accuracy: 0.8368 \n",
      "train accuracy: 0.9997 \n",
      "ROAUC: 0.6757126677035145 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.55      0.03      0.06       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.70      0.51      0.49      5752\n",
      "weighted avg       0.79      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8368393602225312\n",
      "Threshold: 22.684751999999843\n",
      "number of features with scores above the threshold: 89\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.48591164629056804 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6668743664167006 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.64      0.03      0.06       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.74      0.51      0.49      5752\n",
      "weighted avg       0.81      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4834647115107367 \n",
      "test accuracy: 0.8368 \n",
      "train accuracy: 0.9998 \n",
      "ROAUC: 0.6788462152306546 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.56      0.03      0.06       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.70      0.51      0.48      5752\n",
      "weighted avg       0.79      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8373609179415855\n",
      "Threshold: 22.054619999999844\n",
      "number of features with scores above the threshold: 95\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4833968281374182 \n",
      "test accuracy: 0.8387 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.672929248901789 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.73      0.03      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.78      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4844294842954695 \n",
      "test accuracy: 0.8388 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6767864985256289 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.03      0.06       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8387517385257302\n",
      "Threshold: 21.424487999999844\n",
      "number of features with scores above the threshold: 98\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4803635520108548 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6759124425028316 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.73      0.03      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.78      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4832375034776964 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6761588864563693 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.69      0.03      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.77      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.838317107093185\n",
      "Threshold: 20.794355999999844\n",
      "number of features with scores above the threshold: 103\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47939764063979273 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6809991601753616 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.02      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4783528764267676 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6807378569392302 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.73      0.02      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8382301808066759\n",
      "Threshold: 20.164223999999844\n",
      "number of features with scores above the threshold: 106\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47939764063979273 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6811475328637799 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.02      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47939764063979273 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6700702128619749 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.02      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.838317107093185\n",
      "Threshold: 19.534091999999845\n",
      "number of features with scores above the threshold: 109\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4773799040721842 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6791117010796645 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.75      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47939764063979273 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6788141852215078 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.02      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8382301808066759\n",
      "Threshold: 18.903959999999845\n",
      "number of features with scores above the threshold: 113\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47640288581529305 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.686947936375854 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.77      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47556564110178945 \n",
      "test accuracy: 0.8385 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6862348008801098 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.86      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.85      0.51      0.48      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.838317107093185\n",
      "Threshold: 18.273827999999845\n",
      "number of features with scores above the threshold: 116\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4782780656734266 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6873559612690048 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.71      0.02      0.05       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.77      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4764757809273457 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6809540319837804 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.80      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8381432545201669\n",
      "Threshold: 17.643695999999846\n",
      "number of features with scores above the threshold: 118\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47422406385606547 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6887280784305957 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.72      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.78      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4774537798971271 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6810015816880806 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.78      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8379694019471489\n",
      "Threshold: 17.013563999999846\n",
      "number of features with scores above the threshold: 122\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47534992239170554 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6877385602786059 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.76      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47654871005929905 \n",
      "test accuracy: 0.8385 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6871820526282769 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.83      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.48      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8382301808066759\n",
      "Threshold: 16.383431999999846\n",
      "number of features with scores above the threshold: 126\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4764757809273457 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.678348594366901 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.80      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47640288581529305 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6889433729250664 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.77      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8382301808066759\n",
      "Threshold: 15.753299999999847\n",
      "number of features with scores above the threshold: 127\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47633002458507795 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6782554761959796 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47640288581529305 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6866640690439317 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.77      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.48      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8380563282336579\n",
      "Threshold: 15.123167999999847\n",
      "number of features with scores above the threshold: 133\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4733774289007111 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6828460038986354 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.81      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47662167334977434 \n",
      "test accuracy: 0.8387 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6790616197938852 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.87      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.85      0.51      0.48      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.838317107093185\n",
      "Threshold: 14.493035999999847\n",
      "number of features with scores above the threshold: 135\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4722473375464208 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.686931205924341 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.76      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47457845938131593 \n",
      "test accuracy: 0.8385 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6890559732664996 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.90      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.87      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8380563282336578\n",
      "Threshold: 13.862903999999848\n",
      "number of features with scores above the threshold: 142\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4752780799846063 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6827560777217527 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.73      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.78      0.51      0.48      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47330758142946133 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6866277463531468 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.77      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8377955493741307\n",
      "Threshold: 13.232771999999848\n",
      "number of features with scores above the threshold: 147\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4713205607772173 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6851552464824776 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.83      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4711172461921304 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6919228241882703 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.71      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.78      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8375347705146037\n",
      "Threshold: 12.602639999999848\n",
      "number of features with scores above the threshold: 151\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47252273945501033 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.68531803817845 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.94      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.89      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4734473042884878 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6944799416195298 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.85      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8382301808066759\n",
      "Threshold: 11.972507999999848\n",
      "number of features with scores above the threshold: 156\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4723849866542789 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.676104402420192 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.84      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4722473375464208 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6798543350030765 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.76      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8377955493741307\n",
      "Threshold: 11.342375999999849\n",
      "number of features with scores above the threshold: 159\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4711172461921304 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6877495671546014 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.71      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.78      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4734473042884878 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6842635794580876 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.85      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8377086230876217\n",
      "Threshold: 10.712243999999849\n",
      "number of features with scores above the threshold: 163\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4713205607772173 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.688912553672279 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.83      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47032079024673057 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6826029720766563 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.88      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.86      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8377955493741307\n",
      "Threshold: 10.08211199999985\n",
      "number of features with scores above the threshold: 168\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4724538500360015 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6828894810588174 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.89      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.86      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4733774289007111 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6822478902570436 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.81      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8380563282336579\n",
      "Threshold: 9.45197999999985\n",
      "number of features with scores above the threshold: 176\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47450752025500137 \n",
      "test accuracy: 0.8383 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6847922397121482 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.86      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.85      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4711172461921304 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.689216563587273 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.71      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.78      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "average test accuracy: 0.8377955493741307\n",
      "Threshold: 8.82184799999985\n",
      "number of features with scores above the threshold: 178\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4701872715184332 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6893421520423808 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.78      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4733774289007111 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6835837947966094 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.81      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "average test accuracy: 0.8377086230876217\n",
      "Threshold: 8.19171599999985\n",
      "number of features with scores above the threshold: 187\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4744366112656254 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6867523441894151 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.82      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.83      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4713205607772173 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6855038342452531 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.83      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "average test accuracy: 0.8379694019471489\n",
      "Threshold: 7.561583999999851\n",
      "number of features with scores above the threshold: 198\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4731679697582828 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6828367581227994 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.71      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.77      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47323776175505317 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.68698172748516 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "average test accuracy: 0.8375347705146037\n",
      "Threshold: 6.931451999999851\n",
      "number of features with scores above the threshold: 206\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4723849866542789 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6866067232199956 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.84      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47217855159329725 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6932324222942072 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.73      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.78      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "average test accuracy: 0.8377086230876217\n",
      "Threshold: 6.301319999999851\n",
      "number of features with scores above the threshold: 214\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4691196603547202 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6757951092047202 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.76      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47012054453691526 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.674800197683493 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.74      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "average test accuracy: 0.8372739916550765\n",
      "Threshold: 5.671187999999852\n",
      "number of features with scores above the threshold: 224\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4731679697582828 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6929104711713407 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.71      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.77      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4723161491956597 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6837782862954488 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.80      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "average test accuracy: 0.8376216968011126\n",
      "Threshold: 5.041055999999852\n",
      "number of features with scores above the threshold: 236\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4723161491956597 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.690699079715098 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.80      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47138837975491366 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6874760462861149 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.88      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.86      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "average test accuracy: 0.8378824756606398\n",
      "Threshold: 4.410923999999852\n",
      "number of features with scores above the threshold: 257\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4713205607772173 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6838649104095328 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.83      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47118499410283154 \n",
      "test accuracy: 0.8374 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6863174625188355 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.75      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.79      0.51      0.47      5752\n",
      "weighted avg       0.82      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "average test accuracy: 0.8376216968011126\n",
      "Threshold: 3.780791999999852\n",
      "number of features with scores above the threshold: 275\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.46898832347823344 \n",
      "test accuracy: 0.8369 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6877285440214501 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.68      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.76      0.51      0.47      5752\n",
      "weighted avg       0.81      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4723849866542789 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6759047376896347 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.84      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "average test accuracy: 0.8374478442280946\n",
      "Threshold: 3.150659999999852\n",
      "number of features with scores above the threshold: 290\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4733774289007111 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6854941481943772 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.81      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4744366112656254 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6891981821043607 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.82      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.83      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "average test accuracy: 0.8380563282336579\n",
      "Threshold: 2.5205279999998518\n",
      "number of features with scores above the threshold: 300\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4722473375464208 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6859870361014525 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.76      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4744366112656254 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.693404129559736 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.82      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.83      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "average test accuracy: 0.8378824756606398\n",
      "Threshold: 1.8903959999998516\n",
      "number of features with scores above the threshold: 316\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4744366112656254 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6793238035800966 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.82      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.83      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 3 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4723161491956597 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6826909170158598 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.80      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 3 seconds\n",
      "average test accuracy: 0.8379694019471489\n",
      "Threshold: 1.2602639999998515\n",
      "number of features with scores above the threshold: 340\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4723849866542789 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6884225275529623 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.84      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 4 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4743657322866269 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6876578798775596 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.78      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.81      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 4 seconds\n",
      "average test accuracy: 0.8379694019471489\n",
      "Threshold: 0.6301319999998515\n",
      "number of features with scores above the threshold: 367\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47032079024673057 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6851893677980635 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.88      0.01      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.86      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 4 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47138837975491366 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6828720901947446 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.88      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.86      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 4 seconds\n",
      "average test accuracy: 0.8378824756606398\n"
     ]
    }
   ],
   "source": [
    "low_min = th_max - min_th_chi2\n",
    "high_min = max_th_chi2 - th_max\n",
    "if low_min < high_min:\n",
    "    low_end = min_th_chi2\n",
    "    high_end = th_max + (low_min * 2)\n",
    "else:\n",
    "    low_end = th_max - (high_min * 2)\n",
    "    high_end = max_th_chi2\n",
    "\n",
    "th = high_end\n",
    "reduction = (high_end - low_end) / 100\n",
    "\n",
    "accuracy_scores_limited = []\n",
    "prev_num_feat = 0\n",
    "while th > 0:\n",
    "    print(f\"Threshold: {th}\")\n",
    "    num_features = len([sc for sc in scores if sc > th])\n",
    "    print(f\"number of features with scores above the threshold: {num_features}\")\n",
    "    if prev_num_feat != num_features:\n",
    "        prev_num_feat = num_features\n",
    "    else:\n",
    "        th -= reduction\n",
    "        continue\n",
    "    if th < low_end:\n",
    "        break\n",
    "    X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test, chi2, num_features)\n",
    "    models, test_accuracies = train_random_forests(X_train_fs, y_train, X_test_fs, y_test, 2)\n",
    "    accuracy_scores_limited.append((th,np.mean(test_accuracies),num_features))\n",
    "    print(f\"average test accuracy: {np.mean(test_accuracies)}\")\n",
    "    th -= reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_th_chi2_limited = [i[0] for i in accuracy_scores_limited]\n",
    "list_ac_chi2_limited = [i[1] for i in accuracy_scores_limited]\n",
    "list_num_feat_chi2_limited = [i[2] for i in accuracy_scores_limited]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the min of accuracy or number of features\n",
    "min_ac_chi2_limited = min(list_ac_chi2_limited)\n",
    "min_num_feat_chi2_limited = min(list_num_feat_chi2_limited)\n",
    "min_pt_limited = min(min_ac_chi2_limited, min_num_feat_chi2_limited)\n",
    "# the max of accuracy or number of features\n",
    "max_ac_chi2_limited = max(list_ac_chi2_limited)\n",
    "max_num_feat_chi2_limited = max(list_num_feat_chi2_limited)\n",
    "max_pt_limited = max(max_ac_chi2_limited, max_num_feat_chi2_limited)\n",
    "\n",
    "# min and max of the thresholds RECORDER not corrosponding to the min and max of the accuracy\n",
    "min_th_chi2_limited = min(list_th_chi2_limited)\n",
    "max_th_chi2_limited = max(list_th_chi2_limited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_th = round(list_th_chi2_limited[list_ac_chi2_limited.index(max_ac_chi2_limited)], 5)\n",
    "best_nf = round(list_num_feat_chi2_limited[list_ac_chi2_limited.index(max_ac_chi2_limited)], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the accuracy (left y axis) vs threshold\n",
    "# plot the number of features (right y axis) vs threshold\n",
    "# red dot for the highest accuracy with the corresponding threshold rounded to 5 decimal places\n",
    "fig, ax1 = plt.subplots(figsize=(10,10))\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Threshold')\n",
    "ax1.set_ylabel('Accuracy', color=color)\n",
    "ax1.plot(list_th_chi2_limited, list_ac_chi2_limited, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "# ax1.yaxis.set_ticks(np.arange(min_pt_limited, max_pt_limited + (max_pt_limited * 0.01), max_pt_limited * 0.0001))\n",
    "ax1.plot(round(list_th_chi2_limited[list_ac_chi2_limited.index(max_ac_chi2_limited)], 5), max_ac_chi2_limited, 'ro')\n",
    "ax1.annotate(f\"(Threshold: {best_th}\\n, Accuracy: {round(max_ac_chi2_limited, 5)})\", (round(list_th_chi2_limited[list_ac_chi2_limited.index(max_ac_chi2_limited)], 5), max_ac_chi2_limited))\n",
    "# black dotted line at annotated point vertically\n",
    "plt.axvline(x=best_th, color='black', linestyle='dotted')\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Number of Features', color=color)\n",
    "ax2.plot(list_th_chi2_limited, list_num_feat_chi2_limited, color=color, linestyle='dashed')\n",
    "# black dotted line at best_nf\n",
    "plt.axhline(y=best_nf, color='black', linestyle='dotted')\n",
    "ax2.annotate(f\"{best_nf}\", (max_th_chi2_limited, best_nf +1))\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "# ax2.yaxis.set_ticks(np.arange(min_num_feat_chi2_limited, max_num_feat_chi2_limited + (max_num_feat_chi2_limited * 0.01), max_num_feat_chi2_limited * 0.1))\n",
    "plt.title('Threshold vs Accuracy and Number of Features')\n",
    "plt.savefig('outputs/00_feature_select_29/chi2_threshold_vs_accuracy_limited.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual info class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 0.003507\n",
      "Feature 1: 0.000000\n",
      "Feature 2: 0.003932\n",
      "Feature 3: 0.003754\n",
      "Feature 4: 0.005044\n",
      "Feature 5: 0.001666\n",
      "Feature 6: 0.000000\n",
      "Feature 7: 0.001124\n",
      "Feature 8: 0.002837\n",
      "Feature 9: 0.000000\n",
      "Feature 10: 0.005108\n",
      "Feature 11: 0.000000\n",
      "Feature 12: 0.003025\n",
      "Feature 13: 0.000402\n",
      "Feature 14: 0.003607\n",
      "Feature 15: 0.000266\n",
      "Feature 16: 0.003458\n",
      "Feature 17: 0.003779\n",
      "Feature 18: 0.000000\n",
      "Feature 19: 0.000000\n",
      "Feature 20: 0.001922\n",
      "Feature 21: 0.000266\n",
      "Feature 22: 0.003839\n",
      "Feature 23: 0.000000\n",
      "Feature 24: 0.000000\n",
      "Feature 25: 0.000269\n",
      "Feature 26: 0.001830\n",
      "Feature 27: 0.000000\n",
      "Feature 28: 0.000000\n",
      "Feature 29: 0.001134\n",
      "Feature 30: 0.001637\n",
      "Feature 31: 0.001575\n",
      "Feature 32: 0.002931\n",
      "Feature 33: 0.000000\n",
      "Feature 34: 0.002715\n",
      "Feature 35: 0.000805\n",
      "Feature 36: 0.001465\n",
      "Feature 37: 0.000000\n",
      "Feature 38: 0.003234\n",
      "Feature 39: 0.000000\n",
      "Feature 40: 0.002976\n",
      "Feature 41: 0.000000\n",
      "Feature 42: 0.005189\n",
      "Feature 43: 0.002551\n",
      "Feature 44: 0.000000\n",
      "Feature 45: 0.000768\n",
      "Feature 46: 0.000000\n",
      "Feature 47: 0.001294\n",
      "Feature 48: 0.000000\n",
      "Feature 49: 0.000000\n",
      "Feature 50: 0.002347\n",
      "Feature 51: 0.000652\n",
      "Feature 52: 0.002987\n",
      "Feature 53: 0.002120\n",
      "Feature 54: 0.000000\n",
      "Feature 55: 0.001610\n",
      "Feature 56: 0.000000\n",
      "Feature 57: 0.001752\n",
      "Feature 58: 0.003310\n",
      "Feature 59: 0.000207\n",
      "Feature 60: 0.001156\n",
      "Feature 61: 0.001848\n",
      "Feature 62: 0.002064\n",
      "Feature 63: 0.002530\n",
      "Feature 64: 0.000000\n",
      "Feature 65: 0.000000\n",
      "Feature 66: 0.002987\n",
      "Feature 67: 0.001822\n",
      "Feature 68: 0.000000\n",
      "Feature 69: 0.000000\n",
      "Feature 70: 0.000000\n",
      "Feature 71: 0.000680\n",
      "Feature 72: 0.000000\n",
      "Feature 73: 0.000000\n",
      "Feature 74: 0.000561\n",
      "Feature 75: 0.009627\n",
      "Feature 76: 0.000087\n",
      "Feature 77: 0.004990\n",
      "Feature 78: 0.003045\n",
      "Feature 79: 0.000000\n",
      "Feature 80: 0.000000\n",
      "Feature 81: 0.001357\n",
      "Feature 82: 0.003553\n",
      "Feature 83: 0.000291\n",
      "Feature 84: 0.000000\n",
      "Feature 85: 0.000000\n",
      "Feature 86: 0.002119\n",
      "Feature 87: 0.003980\n",
      "Feature 88: 0.000000\n",
      "Feature 89: 0.004890\n",
      "Feature 90: 0.002569\n",
      "Feature 91: 0.000000\n",
      "Feature 92: 0.000000\n",
      "Feature 93: 0.004191\n",
      "Feature 94: 0.000000\n",
      "Feature 95: 0.001262\n",
      "Feature 96: 0.010496\n",
      "Feature 97: 0.000000\n",
      "Feature 98: 0.000331\n",
      "Feature 99: 0.002366\n",
      "Feature 100: 0.000000\n",
      "Feature 101: 0.001301\n",
      "Feature 102: 0.006022\n",
      "Feature 103: 0.000000\n",
      "Feature 104: 0.000000\n",
      "Feature 105: 0.001298\n",
      "Feature 106: 0.001576\n",
      "Feature 107: 0.000000\n",
      "Feature 108: 0.000934\n",
      "Feature 109: 0.006323\n",
      "Feature 110: 0.000000\n",
      "Feature 111: 0.000000\n",
      "Feature 112: 0.000000\n",
      "Feature 113: 0.004410\n",
      "Feature 114: 0.002160\n",
      "Feature 115: 0.000000\n",
      "Feature 116: 0.000000\n",
      "Feature 117: 0.000000\n",
      "Feature 118: 0.000000\n",
      "Feature 119: 0.001009\n",
      "Feature 120: 0.001149\n",
      "Feature 121: 0.000000\n",
      "Feature 122: 0.002103\n",
      "Feature 123: 0.000000\n",
      "Feature 124: 0.002487\n",
      "Feature 125: 0.000000\n",
      "Feature 126: 0.002195\n",
      "Feature 127: 0.000000\n",
      "Feature 128: 0.000000\n",
      "Feature 129: 0.004420\n",
      "Feature 130: 0.000000\n",
      "Feature 131: 0.000047\n",
      "Feature 132: 0.002565\n",
      "Feature 133: 0.000949\n",
      "Feature 134: 0.003865\n",
      "Feature 135: 0.001332\n",
      "Feature 136: 0.000000\n",
      "Feature 137: 0.000331\n",
      "Feature 138: 0.002322\n",
      "Feature 139: 0.004262\n",
      "Feature 140: 0.000000\n",
      "Feature 141: 0.000929\n",
      "Feature 142: 0.003363\n",
      "Feature 143: 0.002541\n",
      "Feature 144: 0.001890\n",
      "Feature 145: 0.001558\n",
      "Feature 146: 0.000000\n",
      "Feature 147: 0.004270\n",
      "Feature 148: 0.000021\n",
      "Feature 149: 0.001907\n",
      "Feature 150: 0.001122\n",
      "Feature 151: 0.000428\n",
      "Feature 152: 0.000060\n",
      "Feature 153: 0.000000\n",
      "Feature 154: 0.003473\n",
      "Feature 155: 0.004799\n",
      "Feature 156: 0.000000\n",
      "Feature 157: 0.000000\n",
      "Feature 158: 0.000000\n",
      "Feature 159: 0.005532\n",
      "Feature 160: 0.003226\n",
      "Feature 161: 0.000000\n",
      "Feature 162: 0.000015\n",
      "Feature 163: 0.000000\n",
      "Feature 164: 0.002042\n",
      "Feature 165: 0.001405\n",
      "Feature 166: 0.000924\n",
      "Feature 167: 0.000000\n",
      "Feature 168: 0.000000\n",
      "Feature 169: 0.004257\n",
      "Feature 170: 0.000000\n",
      "Feature 171: 0.001566\n",
      "Feature 172: 0.002310\n",
      "Feature 173: 0.000000\n",
      "Feature 174: 0.001110\n",
      "Feature 175: 0.001121\n",
      "Feature 176: 0.000000\n",
      "Feature 177: 0.003269\n",
      "Feature 178: 0.001401\n",
      "Feature 179: 0.002761\n",
      "Feature 180: 0.001711\n",
      "Feature 181: 0.000000\n",
      "Feature 182: 0.000000\n",
      "Feature 183: 0.000000\n",
      "Feature 184: 0.002363\n",
      "Feature 185: 0.000000\n",
      "Feature 186: 0.003556\n",
      "Feature 187: 0.002191\n",
      "Feature 188: 0.000298\n",
      "Feature 189: 0.004751\n",
      "Feature 190: 0.000000\n",
      "Feature 191: 0.005032\n",
      "Feature 192: 0.000000\n",
      "Feature 193: 0.000000\n",
      "Feature 194: 0.007068\n",
      "Feature 195: 0.000139\n",
      "Feature 196: 0.001792\n",
      "Feature 197: 0.006117\n",
      "Feature 198: 0.000000\n",
      "Feature 199: 0.011400\n",
      "Feature 200: 0.001231\n",
      "Feature 201: 0.000000\n",
      "Feature 202: 0.000463\n",
      "Feature 203: 0.000000\n",
      "Feature 204: 0.002715\n",
      "Feature 205: 0.001454\n",
      "Feature 206: 0.000000\n",
      "Feature 207: 0.000321\n",
      "Feature 208: 0.000000\n",
      "Feature 209: 0.001404\n",
      "Feature 210: 0.000808\n",
      "Feature 211: 0.000853\n",
      "Feature 212: 0.005572\n",
      "Feature 213: 0.000000\n",
      "Feature 214: 0.002116\n",
      "Feature 215: 0.011252\n",
      "Feature 216: 0.000000\n",
      "Feature 217: 0.003536\n",
      "Feature 218: 0.000000\n",
      "Feature 219: 0.002094\n",
      "Feature 220: 0.009050\n",
      "Feature 221: 0.007253\n",
      "Feature 222: 0.000000\n",
      "Feature 223: 0.002719\n",
      "Feature 224: 0.008360\n",
      "Feature 225: 0.000562\n",
      "Feature 226: 0.003928\n",
      "Feature 227: 0.002424\n",
      "Feature 228: 0.001100\n",
      "Feature 229: 0.003450\n",
      "Feature 230: 0.002628\n",
      "Feature 231: 0.003473\n",
      "Feature 232: 0.003419\n",
      "Feature 233: 0.005550\n",
      "Feature 234: 0.003259\n",
      "Feature 235: 0.004669\n",
      "Feature 236: 0.007300\n",
      "Feature 237: 0.002086\n",
      "Feature 238: 0.003908\n",
      "Feature 239: 0.000000\n",
      "Feature 240: 0.002421\n",
      "Feature 241: 0.006980\n",
      "Feature 242: 0.004895\n",
      "Feature 243: 0.001557\n",
      "Feature 244: 0.006962\n",
      "Feature 245: 0.004998\n",
      "Feature 246: 0.001611\n",
      "Feature 247: 0.005327\n",
      "Feature 248: 0.004328\n",
      "Feature 249: 0.000945\n",
      "Feature 250: 0.002428\n",
      "Feature 251: 0.004509\n",
      "Feature 252: 0.002350\n",
      "Feature 253: 0.000886\n",
      "Feature 254: 0.001766\n",
      "Feature 255: 0.003860\n",
      "Feature 256: 0.003193\n",
      "Feature 257: 0.005659\n",
      "Feature 258: 0.001401\n",
      "Feature 259: 0.001836\n",
      "Feature 260: 0.001750\n",
      "Feature 261: 0.002731\n",
      "Feature 262: 0.004685\n",
      "Feature 263: 0.004537\n",
      "Feature 264: 0.000000\n",
      "Feature 265: 0.001145\n",
      "Feature 266: 0.000000\n",
      "Feature 267: 0.007027\n",
      "Feature 268: 0.002164\n",
      "Feature 269: 0.002484\n",
      "Feature 270: 0.001545\n",
      "Feature 271: 0.000000\n",
      "Feature 272: 0.000127\n",
      "Feature 273: 0.005021\n",
      "Feature 274: 0.005496\n",
      "Feature 275: 0.001894\n",
      "Feature 276: 0.002073\n",
      "Feature 277: 0.002467\n",
      "Feature 278: 0.002756\n",
      "Feature 279: 0.000000\n",
      "Feature 280: 0.000832\n",
      "Feature 281: 0.004495\n",
      "Feature 282: 0.004668\n",
      "Feature 283: 0.001031\n",
      "Feature 284: 0.004086\n",
      "Feature 285: 0.000837\n",
      "Feature 286: 0.000587\n",
      "Feature 287: 0.000000\n",
      "Feature 288: 0.000000\n",
      "Feature 289: 0.003102\n",
      "Feature 290: 0.005352\n",
      "Feature 291: 0.000000\n",
      "Feature 292: 0.000000\n",
      "Feature 293: 0.004418\n",
      "Feature 294: 0.001516\n",
      "Feature 295: 0.004945\n",
      "Feature 296: 0.000468\n",
      "Feature 297: 0.005875\n",
      "Feature 298: 0.001716\n",
      "Feature 299: 0.000000\n",
      "Feature 300: 0.000391\n",
      "Feature 301: 0.001960\n",
      "Feature 302: 0.002521\n",
      "Feature 303: 0.002796\n",
      "Feature 304: 0.000000\n",
      "Feature 305: 0.004098\n",
      "Feature 306: 0.000000\n",
      "Feature 307: 0.004286\n",
      "Feature 308: 0.001398\n",
      "Feature 309: 0.000000\n",
      "Feature 310: 0.000195\n",
      "Feature 311: 0.000834\n",
      "Feature 312: 0.007505\n",
      "Feature 313: 0.004195\n",
      "Feature 314: 0.000250\n",
      "Feature 315: 0.000000\n",
      "Feature 316: 0.002361\n",
      "Feature 317: 0.004845\n",
      "Feature 318: 0.001572\n",
      "Feature 319: 0.000000\n",
      "Feature 320: 0.000000\n",
      "Feature 321: 0.000000\n",
      "Feature 322: 0.001462\n",
      "Feature 323: 0.002871\n",
      "Feature 324: 0.001299\n",
      "Feature 325: 0.004371\n",
      "Feature 326: 0.000000\n",
      "Feature 327: 0.000000\n",
      "Feature 328: 0.001449\n",
      "Feature 329: 0.005716\n",
      "Feature 330: 0.000000\n",
      "Feature 331: 0.000000\n",
      "Feature 332: 0.000000\n",
      "Feature 333: 0.002533\n",
      "Feature 334: 0.000628\n",
      "Feature 335: 0.000000\n",
      "Feature 336: 0.002147\n",
      "Feature 337: 0.004268\n",
      "Feature 338: 0.000693\n",
      "Feature 339: 0.000000\n",
      "Feature 340: 0.002775\n",
      "Feature 341: 0.000000\n",
      "Feature 342: 0.004155\n",
      "Feature 343: 0.000000\n",
      "Feature 344: 0.001476\n",
      "Feature 345: 0.003626\n",
      "Feature 346: 0.000000\n",
      "Feature 347: 0.000000\n",
      "Feature 348: 0.001674\n",
      "Feature 349: 0.005648\n",
      "Feature 350: 0.000000\n",
      "Feature 351: 0.001690\n",
      "Feature 352: 0.005865\n",
      "Feature 353: 0.004738\n",
      "Feature 354: 0.000615\n",
      "Feature 355: 0.002838\n",
      "Feature 356: 0.000000\n",
      "Feature 357: 0.000000\n",
      "Feature 358: 0.001147\n",
      "Feature 359: 0.001620\n",
      "Feature 360: 0.001112\n",
      "Feature 361: 0.005106\n",
      "Feature 362: 0.000828\n",
      "Feature 363: 0.003507\n",
      "Feature 364: 0.000000\n",
      "Feature 365: 0.000000\n",
      "Feature 366: 0.000000\n",
      "Feature 367: 0.000445\n",
      "Feature 368: 0.001718\n",
      "Feature 369: 0.000000\n",
      "Feature 370: 0.000000\n",
      "Feature 371: 0.002948\n",
      "Feature 372: 0.000000\n",
      "Feature 373: 0.005279\n",
      "Feature 374: 0.000000\n",
      "Feature 375: 0.000000\n",
      "Feature 376: 0.000435\n",
      "Feature 377: 0.002025\n",
      "Feature 378: 0.002850\n",
      "Feature 379: 0.001865\n",
      "Feature 380: 0.000000\n",
      "Feature 381: 0.000931\n",
      "Feature 382: 0.000766\n",
      "Feature 383: 0.006101\n",
      "Feature 384: 0.006448\n",
      "Feature 385: 0.000000\n",
      "Feature 386: 0.000246\n",
      "Feature 387: 0.004594\n",
      "Feature 388: 0.000000\n",
      "Feature 389: 0.000000\n",
      "Feature 390: 0.000000\n",
      "Feature 391: 0.004732\n",
      "Feature 392: 0.000078\n",
      "Feature 393: 0.000000\n",
      "Feature 394: 0.001762\n",
      "Feature 395: 0.002575\n",
      "Feature 396: 0.000000\n",
      "Feature 397: 0.003264\n",
      "Feature 398: 0.000000\n",
      "Feature 399: 0.000000\n",
      "Feature 400: 0.000020\n",
      "Feature 401: 0.002944\n",
      "Feature 402: 0.001848\n",
      "Feature 403: 0.000000\n",
      "Feature 404: 0.007174\n",
      "Feature 405: 0.001953\n",
      "Feature 406: 0.000000\n",
      "Feature 407: 0.000000\n",
      "Feature 408: 0.000000\n",
      "Feature 409: 0.006683\n",
      "Feature 410: 0.000000\n",
      "Feature 411: 0.000998\n",
      "Feature 412: 0.000000\n",
      "Feature 413: 0.000000\n",
      "Feature 414: 0.001043\n",
      "Feature 415: 0.005023\n",
      "Feature 416: 0.000000\n",
      "Feature 417: 0.000000\n",
      "Feature 418: 0.000441\n",
      "Feature 419: 0.005329\n",
      "Feature 420: 0.003365\n",
      "Feature 421: 0.001372\n",
      "Feature 422: 0.000000\n",
      "Feature 423: 0.000000\n",
      "Feature 424: 0.002906\n",
      "Feature 425: 0.000702\n",
      "Feature 426: 0.000983\n",
      "Feature 427: 0.005218\n",
      "Feature 428: 0.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test, mutual_info_classif, 'all')\n",
    "# what are scores for the features\n",
    "for i in range(len(fs.scores_)):\n",
    " print('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "# plot the scores\n",
    "plt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "plt.savefig('outputs/00_feature_select_29/feat_imp_mutual_info.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 0.0\n",
      "max: 0.01140041760974042\n"
     ]
    }
   ],
   "source": [
    "# get the scores for the features and remove the nan values\n",
    "scores = []\n",
    "for i in range(len(fs.scores_)):\n",
    "    if np.isnan(fs.scores_[i]):\n",
    "        continue\n",
    "    else:\n",
    "        scores.append(fs.scores_[i])\n",
    "\n",
    "# get the min and max scores\n",
    "min_mic_imp = min(scores)\n",
    "max_mic_imp = max(scores)\n",
    "print(f\"min: {min_mic_imp}\")\n",
    "print(f\"max: {max_mic_imp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABlMAAAYvCAYAAAAUNwnDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABfE0lEQVR4nOzdfYxddV7H8e+UWTqFpRXB7RS2u7dqFRBopZVSJMFsJg5m1jARK2Ky1IZASLabYhPIhS3tpmA68mRB2FRMMGJCaBpNVS5WsYgx0pRQyib84UoikxLrFMiGdtOV8tDxD8JlZ5l+trdAbx9er+Rmztz5nXO/d/5953dOz/j4+HgBAAAAAAAwqSndHgAAAAAAAOBYJqYAAAAAAAAEYgoAAAAAAEAgpgAAAAAAAARiCgAAAAAAQCCmAAAAAAAABGIKAAAAAABA0NvtAY6WgwcP1u7du+uMM86onp6ebo8DAAAAAAB00fj4eP3whz+sc845p6ZMyXtPTpqYsnv37po9e3a3xwAAAAAAAI4hr7/+en35y1+Oa06amHLGGWdU1Yf/lOnTp3d5GgAAAAAAoJv27dtXs2fPbveD5KSJKR/d2mv69OliCgAAAAAAUFV1WI8G8QB6AAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMoaqqGs1WNZqtbo8BAAAAAADHHDEFAAAAAAAgEFMAAAAAAAACMQUAAAAAACAQUwAAAAAAAAIxBQAAAAAAIBBTAAAAAAAAAjEFAAAAAAAgEFMAAAAAAAACMQUAAAAAACAQUwAAAAAAAAIxBQAAAAAAIBBTAAAAAAAAAjEFAAAAAAAgEFMAAAAAAAACMQUAAAAAACAQUwAAAAAAAAIxBQAAAAAAIBBTAAAAAAAAgt5uD8Cxp9FstY9HR4a6OAkAAAAAAHSfnSkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQ9HZ7AI5tjWarfTw6MtTFSQAAAAAAoDvsTAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIjiimPPLII9VoNKqvr68WLVpUL7zwQly/adOmOu+886qvr68uuuiievrppyf8/W//9m/rN3/zN+uss86qnp6eevnllz9xjXfeeae++c1v1llnnVVf/OIX65prrqk9e/YcyfgAAAAAAACHreOYsnHjxlq5cmWtWbOmXnrppZo3b14NDg7WG2+8Men6559/vq677rq64YYbaufOnTU8PFzDw8P1yiuvtNfs37+/rrjiivqTP/mTQ37uH/3RH9U//MM/1KZNm+rf/u3favfu3fU7v/M7nY4PAAAAAADQkZ7x8fHxTk5YtGhR/dqv/Vo9/PDDVVV18ODBmj17dn3rW9+qZrP5ifXXXntt7d+/v5566qn2e5dddlnNnz+/NmzYMGHt6OhozZkzp3bu3Fnz589vv7937976uZ/7uXriiSfqd3/3d6uq6j//8z/r/PPPr23bttVll132U+fet29fzZgxo/bu3VvTp0/v5CufFBrNVlVVjY4MtY9/0ujI0NEcCQAAAAAAPjeddIOOdqa8++67tWPHjhoYGPj4AlOm1MDAQG3btm3Sc7Zt2zZhfVXV4ODgIddPZseOHfXee+9NuM55551XX/nKVw55nQMHDtS+ffsmvAAAAAAAADrVUUx566236oMPPqiZM2dOeH/mzJk1NjY26TljY2MdrT/UNU499dT6mZ/5mcO+zrp162rGjBnt1+zZsw/78wAAAAAAAD5yRA+gPx7cfvvttXfv3vbr9ddf7/ZIAAAAAADAcai3k8Vnn312nXLKKbVnz54J7+/Zs6f6+/snPae/v7+j9Ye6xrvvvltvv/32hN0p6TpTp06tqVOnHvZnAAAAAAAATKajnSmnnnpqLViwoLZu3dp+7+DBg7V169ZavHjxpOcsXrx4wvqqqmeeeeaQ6yezYMGC+sIXvjDhOt///vdr165dHV0HAAAAAACgUx3tTKmqWrlyZS1durQWLlxYl156aa1fv772799fy5Ytq6qq66+/vs4999xat25dVVWtWLGirrzyyrr//vtraGionnzyyXrxxRfr0UcfbV/zBz/4Qe3atat2795dVR+GkqoPd6T09/fXjBkz6oYbbqiVK1fWz/7sz9b06dPrW9/6Vi1evLguu+yyT/1PAAAAAAAAOJSOY8q1115bb775Zq1evbrGxsZq/vz5tWXLlvZD5nft2lVTpny84eXyyy+vJ554olatWlV33HFHzZ07tzZv3lwXXnhhe83f//3ft2NMVdXv//7vV1XVmjVr6jvf+U5VVf3pn/5pTZkypa655po6cOBADQ4O1ne/+90j+tIAAAAAAACHq2d8fHy820McDfv27asZM2bU3r17a/r06d0e55jTaLaqqmp0ZKh9/JNGR4aO5kgAAAAAAPC56aQbdPTMFAAAAAAAgJONmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZhCRxrNVjWarW6PAQAAAAAAR42YAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpHLFGs1WNZqvbYwAAAAAAwOdKTAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAoLfbA3BiaDRb7ePRkaEuTgIAAAAAAJ8tO1MAAAAAAAACMQUAAAAAACAQUwAAAAAAAAIxBQAAAAAAIBBTAAAAAAAAAjEFAAAAAAAgEFMAAAAAAAACMQUAAAAAACAQUwAAAAAAAAIxBQAAAAAAIBBTAAAAAAAAAjEFAAAAAAAgEFMAAAAAAAACMQUAAAAAACAQUwAAAAAAAAIxBQAAAAAAIBBTAAAAAAAAAjEFAAAAAAAgEFMAAAAAAAACMQUAAAAAACAQUwAAAAAAAAIxBQAAAAAAIBBTAAAAAAAAAjEFAAAAAAAgEFMAAAAAAAACMQUAAAAAACAQUwAAAAAAAAIxBQAAAAAAIBBTAAAAAAAAAjEFAAAAAAAgEFMAAAAAAAACMQUAAAAAACAQUwAAAAAAAAIxBQAAAAAAIBBTAAAAAAAAAjEFAAAAAAAgEFMAAAAAAAACMQUAAAAAACAQUwAAAAAAAAIxBQAAAAAAIBBTAAAAAAAAgiOKKY888kg1Go3q6+urRYsW1QsvvBDXb9q0qc4777zq6+uriy66qJ5++ukJfx8fH6/Vq1fXrFmzatq0aTUwMFCvvvrqhDX/9V//VVdffXWdffbZNX369LriiivqX//1X49kfAAAAAAAgMPWcUzZuHFjrVy5stasWVMvvfRSzZs3rwYHB+uNN96YdP3zzz9f1113Xd1www21c+fOGh4eruHh4XrllVfaa+6555566KGHasOGDbV9+/Y6/fTTa3BwsN555532mq9//ev1/vvv17PPPls7duyoefPm1de//vUaGxs7gq8NAAAAAABweDqOKQ888EDdeOONtWzZsrrgggtqw4YNddppp9Vjjz026foHH3ywrrrqqrr11lvr/PPPr7vuuqsuueSSevjhh6vqw10p69evr1WrVtXVV19dF198cT3++OO1e/fu2rx5c1VVvfXWW/Xqq69Ws9msiy++uObOnVsjIyP1ox/9aEKUAQAAAAAA+Kx1FFPefffd2rFjRw0MDHx8gSlTamBgoLZt2zbpOdu2bZuwvqpqcHCwvf61116rsbGxCWtmzJhRixYtaq8566yz6pd/+Zfr8ccfr/3799f7779ff/7nf15f+tKXasGCBZN+7oEDB2rfvn0TXgAAAAAAAJ3qKKa89dZb9cEHH9TMmTMnvD9z5sxD3m5rbGwsrv/oZ1rT09NT//Iv/1I7d+6sM844o/r6+uqBBx6oLVu21Jlnnjnp565bt65mzJjRfs2ePbuTrwoAAAAAAFBVR/gA+qNtfHy8vvnNb9aXvvSl+vd///d64YUXanh4uH77t3+7/vd//3fSc26//fbau3dv+/X6668f5akBAAAAAIATQUcx5eyzz65TTjml9uzZM+H9PXv2VH9//6Tn9Pf3x/Uf/Uxrnn322XrqqafqySefrF//9V+vSy65pL773e/WtGnT6q/+6q8m/dypU6fW9OnTJ7wAAAAAAAA61VFMOfXUU2vBggW1devW9nsHDx6srVu31uLFiyc9Z/HixRPWV1U988wz7fVz5syp/v7+CWv27dtX27dvb6/50Y9+9OGwUyaOO2XKlDp48GAnXwEAAAAAAKAjvZ2esHLlylq6dGktXLiwLr300lq/fn3t37+/li1bVlVV119/fZ177rm1bt26qqpasWJFXXnllXX//ffX0NBQPfnkk/Xiiy/Wo48+WlUfPg/llltuqbvvvrvmzp1bc+bMqTvvvLPOOeecGh4erqoPg8yZZ55ZS5curdWrV9e0adPqL/7iL+q1116roaGhz+hfAQAAAAAA8Ekdx5Rrr7223nzzzVq9enWNjY3V/Pnza8uWLe0HyO/atWvCDpLLL7+8nnjiiVq1alXdcccdNXfu3Nq8eXNdeOGF7TW33XZb7d+/v2666aZ6++2364orrqgtW7ZUX19fVX14e7EtW7bUt7/97fra175W7733Xv3Kr/xK/d3f/V3Nmzfv0/4PAAAAAAAADqnjmFJVtXz58lq+fPmkf3vuuec+8d6SJUtqyZIlh7xeT09PrV27ttauXXvINQsXLqx/+qd/6nhWAAAAAACAT6OjZ6YAAAAAAACcbMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIers9ACeeRrPVPh4dGeriJAAAAAAA8OnZmQIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKXzuGs1WNZqtbo8BAAAAAABHREwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACHq7PQAnl0az1T4eHRnq4iQAAAAAAHB47EwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAh6uz0AJ69Gs9U+Hh0Z6uIkAAAAAABwaHamAAAAAAAABGIKAAAAAABAIKYAAAAAAAAEYgoAAAAAAEAgpgAAAAAAAARiCgAAAAAAQCCmAAAAAAAABGIKAAAAAABAIKYAAAAAAAAEYgoAAAAAAEAgpgAAAAAAAARiCgAAAAAAQCCmAAAAAAAABGIKx4xGs1WNZqvbYwAAAAAAwARiCgAAAAAAQCCmAAAAAAAABGIKAAAAAABAIKYAAAAAAAAEYgrHJA+jBwAAAADgWCGmAAAAAAAABGIKAAAAAABAIKYAAAAAAAAEYgoAAAAAAEAgpgAAAAAAAAS93R4AfppGs9U+Hh0Z6uIkAAAAAACcjOxMAQAAAAAACMQUAAAAAACAwG2+OK645RcAAAAAAEebnSkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpHNcazVY1mq1ujwEAAAAAwAlMTAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAICgt9sDwGel0Wy1j0dHhro4CQAAAAAAJxI7UwAAAAAAAAIxBQAAAAAAIBBTAAAAAAAAAjEFAAAAAAAgEFMAAAAAAAACMQUAAAAAACAQUwAAAAAAAAIxBQAAAAAAIBBTAAAAAAAAAjEFAAAAAAAgEFMAAAAAAAACMQUAAAAAACAQUwAAAAAAAAIxBQAAAAAAIBBTAAAAAAAAgt5uDwCfh0az1T4eHRnq4iQAAAAAABzv7EwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBROCo1mqxrNVrfHAAAAAADgOCSmAAAAAAAABGIKJx27VAAAAAAA6ISYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQHFFMeeSRR6rRaFRfX18tWrSoXnjhhbh+06ZNdd5551VfX19ddNFF9fTTT0/4+/j4eK1evbpmzZpV06ZNq4GBgXr11Vc/cZ1Wq1WLFi2qadOm1ZlnnlnDw8NHMj4AAAAAAMBh6zimbNy4sVauXFlr1qypl156qebNm1eDg4P1xhtvTLr++eefr+uuu65uuOGG2rlzZw0PD9fw8HC98sor7TX33HNPPfTQQ7Vhw4bavn17nX766TU4OFjvvPNOe83f/M3f1De+8Y1atmxZfe9736v/+I//qD/4gz84gq8MH2s0W+0XAAAAAABMpuOY8sADD9SNN95Yy5YtqwsuuKA2bNhQp512Wj322GOTrn/wwQfrqquuqltvvbXOP//8uuuuu+qSSy6phx9+uKo+3JWyfv36WrVqVV199dV18cUX1+OPP167d++uzZs3V1XV+++/XytWrKh77723br755vqlX/qluuCCC+r3fu/3DjnngQMHat++fRNeAAAAAAAAneooprz77ru1Y8eOGhgY+PgCU6bUwMBAbdu2bdJztm3bNmF9VdXg4GB7/WuvvVZjY2MT1syYMaMWLVrUXvPSSy/V//zP/9SUKVPqV3/1V2vWrFn1W7/1WxN2t/ykdevW1YwZM9qv2bNnd/JVAQAAAAAAqqrDmPLWW2/VBx98UDNnzpzw/syZM2tsbGzSc8bGxuL6j36mNf/93/9dVVXf+c53atWqVfXUU0/VmWeeWb/xG79RP/jBDyb93Ntvv7327t3bfr3++uudfFUAAAAAAICqOsIH0B9tBw8erKqqb3/723XNNdfUggUL6i//8i+rp6enNm3aNOk5U6dOrenTp094AQAAAAAAdKqjmHL22WfXKaecUnv27Jnw/p49e6q/v3/Sc/r7++P6j36mNbNmzaqqqgsuuKD996lTp9bP//zP165duzr5CgAAAAAAAB3pKKaceuqptWDBgtq6dWv7vYMHD9bWrVtr8eLFk56zePHiCeurqp555pn2+jlz5lR/f/+ENfv27avt27e31yxYsKCmTp1a3//+99tr3nvvvRodHa2vfvWrnXwFAAAAAACAjvR2esLKlStr6dKltXDhwrr00ktr/fr1tX///lq2bFlVVV1//fV17rnn1rp166qqasWKFXXllVfW/fffX0NDQ/Xkk0/Wiy++WI8++mhVVfX09NQtt9xSd999d82dO7fmzJlTd955Z51zzjk1PDxcVVXTp0+vm2++udasWVOzZ8+ur371q3XvvfdWVdWSJUs+i/8DAAAAAADApDqOKddee229+eabtXr16hobG6v58+fXli1b2g+Q37VrV02Z8vGGl8svv7yeeOKJWrVqVd1xxx01d+7c2rx5c1144YXtNbfddlvt37+/brrppnr77bfriiuuqC1btlRfX197zb333lu9vb31jW98o/7v//6vFi1aVM8++2ydeeaZn+b7AwAAAAAARB3HlKqq5cuX1/Llyyf923PPPfeJ95YsWRJ3kPT09NTatWtr7dq1h1zzhS98oe6777667777Op4XAAAAAADgSHX0zBQAAAAAAICTjZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQ9HZ7ADhWNJqt9vHoyFAXJwEAAAAA4FhiZwoAAAAAAEAgpsAhNJqtCbtVAAAAAAA4OYkpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEPR2ewA4HjSarfbx6MhQFycBAAAAAOBoszMFAAAAAAAgEFMAAAAAAAACMQUAAAAAACAQUwAAAAAAAAIxBQAAAAAAIBBTAAAAAAAAgt5uDwDHm0az1T4eHRnq4iQAAAAAABwNdqYAAAAAAAAEYgp8So1ma8JuFQAAAAAATixiCgAAAAAAQCCmAAAAAAAABGIKAAAAAABAIKYAAAAAAAAEYgoAAAAAAEAgpgAAAAAAAARiCgAAAAAAQCCmAAAAAAAABGIKfIYazVY1mq1ujwEAAAAAwGdITAEAAAAAAAjEFAAAAAAAgKC32wPAierHb/c1OjLUxUkAAAAAAPg07EwBAAAAAAAIxBQAAAAAAIDAbb7gKHDLLwAAAACA45edKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCXdBotiY8RwUAAAAAgGOXmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAABBb7cHgJNdo9lqH4+ODHVxEgAAAAAAJmNnCgAAAAAAQCCmAAAAAAAABG7zBceQn7zl10e/u/0XAAAAAED32JkCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpcJxoNFvVaLa6PQYAAAAAwElHTAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAh6uz0A0LlGs9U+Hh0Z6uIkAAAAAAAnPjtTAAAAAAAAAjEFAAAAAAAgEFMAAAAAAAACz0yB45znpwAAAAAAfL7sTAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACHq7PQDw2Wo0W1VVNToy1D7+6HcAAAAAADpnZwoAAAAAAEAgpgAAAAAAAARiCgAAAAAAQCCmAAAAAAAABGIKAAAAAABAIKYAAAAAAAAEYgoAAAAAAEDQ2+0BgKOj0Wy1j0dHhro4CQAAAADA8cXOFAAAAAAAgEBMgZNUo9masFsFAAAAAIDJuc0X0I4qoyNDbgcGAAAAAPAT7EwBAAAAAAAIxBQAAAAAAIDAbb6AQ3LLLwAAAAAAO1OADnhoPQAAAABwMhJTAAAAAAAAAjEFAAAAAAAgEFMAAAAAAAACMQUAAAAAACAQUwAAAAAAAILebg8AHJ8azVb7eHRkqIuTAAAAAAB8vuxMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAh6uz0AcPxrNFvt49GRoS5OAgAAAADw2bMzBfjMNZqtCYEFAAAAAOB4JqYAAAAAAAAEYgoAAAAAAEAgpgAAAAAAAARiCgAAAAAAQCCmAAAAAAAABGIK8LlqNFvVaLa6PQYAAAAAwBETUwAAAAAAAAIxBQAAAAAAIBBTAAAAAAAAAjEFAAAAAAAgEFMAAAAAAACC3m4PAJw8Gs1W+3h0ZKiLkwAAAAAAHD47UwAAAAAAAAIxBQAAAAAAIBBTAAAAAAAAAjEFAAAAAAAgEFMAAAAAAACC3m4PAJycGs1W+3h0ZKiLkwAAAAAAZHamAAAAAAAABHamAMeEj3aqjI4M2bUCAAAAABxT7EwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAoLfbAwAkjWarfTw6MtTFSQAAAACAk5WdKQAAAAAAAIGYAhxXGs1We7fKjx8DAAAAAHxexBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAh6uz0AwGeh0Wy1j0dHhro4CQAAAABworEzBQAAAAAAIBBTAAAAAAAAAjEFAAAAAAAgEFMAAAAAAAACMQUAAAAAACAQUwAAAAAAAAIxBQAAAAAAIOjt9gAAn7VGs9U+Hh0Z6uIkAAAAAMCJwM4UAAAAAACAQEwBAAAAAAAIxBTghNdotibc+gsAAAAAoBNiCgAAAAAAQOAB9MBJxcPpAQAAAIBO2ZkCAAAAAAAQiCkAAAAAAACBmAIAAAAAABCIKQAAAAAAAIGYAgAAAAAAEIgpAAAAAAAAgZgCAAAAAAAQiCkAAAAAAACBmAIAAAAAABD0dnsAgG5pNFvt49GRofbvoyND3RoJAAAAADgG2ZkCMIlGszUhtgAAAAAAJy8xBQAAAAAAIBBTAAAAAAAAAjEFAAAAAAAgEFMAAAAAAACC3m4PAHCs+/EH0Y+ODHVxEgAAAACgG+xMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIDAA+gBOuBh9AAAAABw8rEzBQAAAAAAIBBTAAAAAAAAAjEFAAAAAAAgEFMAAAAAAAACMQUAAAAAACAQUwA+hUazVY1mq9tjAAAAAACfIzEFAAAAAAAg6O32AAAnikPtUBkdGTrKkwAAAAAAnyU7UwCOArcDAwAAAIDjl5gCcJQJKwAAAABwfBFTAAAAAAAAAjEFAAAAAAAgEFMAAAAAAAACMQUAAAAAACAQUwAAAAAAAAIxBQAAAAAAIBBTAAAAAAAAgt5uDwBwMms0W5O+PzoydJQnAQAAAAAOxc4UAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFIBjVKPZOuQD6gEAAACAo0dMAQAAAAAACMQUAAAAAACAQEwBAAAAAAAIxBQAAAAAAIBATAEAAAAAAAjEFAAAAAAAgKC32wMA8NM1mq328ejIUBcnAQAAAICTj50pAAAAAAAAgZ0pAMcZu1QAAAAA4OiyMwUAAAAAACAQUwAAAAAAAAIxBQAAAAAAIBBTAAAAAAAAAjEFAAAAAAAgEFMAAAAAAACCI4opjzzySDUajerr66tFixbVCy+8ENdv2rSpzjvvvOrr66uLLrqonn766Ql/Hx8fr9WrV9esWbNq2rRpNTAwUK+++uqk1zpw4EDNnz+/enp66uWXXz6S8QEAAAAAAA5bxzFl48aNtXLlylqzZk299NJLNW/evBocHKw33nhj0vXPP/98XXfddXXDDTfUzp07a3h4uIaHh+uVV15pr7nnnnvqoYceqg0bNtT27dvr9NNPr8HBwXrnnXc+cb3bbrutzjnnnE7HBgAAAAAAOCIdx5QHHnigbrzxxlq2bFldcMEFtWHDhjrttNPqsccem3T9gw8+WFdddVXdeuutdf7559ddd91Vl1xyST388MNV9eGulPXr19eqVavq6quvrosvvrgef/zx2r17d23evHnCtf7xH/+x/vmf/7nuu+++zr8pAAAAAADAEegoprz77ru1Y8eOGhgY+PgCU6bUwMBAbdu2bdJztm3bNmF9VdXg4GB7/WuvvVZjY2MT1syYMaMWLVo04Zp79uypG2+8sf76r/+6TjvttJ8664EDB2rfvn0TXgAAAAAAAJ3qKKa89dZb9cEHH9TMmTMnvD9z5swaGxub9JyxsbG4/qOfac34+Hj94R/+Yd188821cOHCw5p13bp1NWPGjPZr9uzZh3UeAAAAAADAjzuiB9AfbX/2Z39WP/zhD+v2228/7HNuv/322rt3b/v1+uuvf44TAgAAAAAAJ6qOYsrZZ59dp5xySu3Zs2fC+3v27Kn+/v5Jz+nv74/rP/qZ1jz77LO1bdu2mjp1avX29tYv/uIvVlXVwoULa+nSpZN+7tSpU2v69OkTXgAnokazVY1mq9tjAAAAAMAJq6OYcuqpp9aCBQtq69at7fcOHjxYW7durcWLF096zuLFiyesr6p65pln2uvnzJlT/f39E9bs27evtm/f3l7z0EMP1fe+9716+eWX6+WXX66nn366qqo2btxYf/zHf9zJVwAAAAAAAOhIb6cnrFy5spYuXVoLFy6sSy+9tNavX1/79++vZcuWVVXV9ddfX+eee26tW7euqqpWrFhRV155Zd1///01NDRUTz75ZL344ov16KOPVlVVT09P3XLLLXX33XfX3Llza86cOXXnnXfWOeecU8PDw1VV9ZWvfGXCDF/84herquoXfuEX6stf/vIRf3kAAAAAAICfpuOYcu2119abb75Zq1evrrGxsZo/f35t2bKl/QD5Xbt21ZQpH294ufzyy+uJJ56oVatW1R133FFz586tzZs314UXXthec9ttt9X+/fvrpptuqrfffruuuOKK2rJlS/X19X0GXxEAAAAAAODIdRxTqqqWL19ey5cvn/Rvzz333CfeW7JkSS1ZsuSQ1+vp6am1a9fW2rVrD+vzG41GjY+PH9ZaAAAAAACAT6OjZ6YAAAAAAACcbMQUgBNIo9mqRrPV7TEAAAAA4IRyRLf5AuDY9+NRZXRkqIuTAAAAAMDxzc4UAAAAAACAQEwBAAAAAAAI3OYL4CTgll8AAAAAcOTsTAEAAAAAAAjEFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBOAk1mq0JD6UHAAAAAA6tt9sDANBdPx5VRkeGujgJAAAAAByb7EwBAAAAAAAI7EwBoM0uFQAAAAD4JDtTAAAAAAAAAjEFAAAAAAAgEFMAAAAAAAACMQUAAAAAACAQUwAAAAAAAAIxBQAAAAAAIBBTAAAAAAAAAjEFgENqNFvVaLa6PQYAAAAAdJWYAgAAAAAAEIgpAAAAAAAAgZgCwGFxyy8AAAAATlZiCgAAAAAAQCCmAAAAAAAABGIKAAAAAABAIKYAAAAAAAAEYgoAAAAAAEAgpgAAAAAAAARiCgAAAAAAQCCmAAAAAAAABGIKAAAAAABAIKYAAAAAAAAEYgoAAAAAAEAgpgAAAAAAAARiCgAAAAAAQCCmAAAAAAAABGIKAAAAAABAIKYAAAAAAAAEvd0eAIDjT6PZah+Pjgx1cRIAAAAA+PzZmQIAAAAAABDYmQLAp2KXCgAAAAAnOjtTAAAAAAAAAjEFAAAAAAAgEFMAAAAAAAACMQUAAAAAACAQUwAAAAAAAAIxBQAAAAAAIOjt9gAAnFgazVZVVY2ODLWPP/odAAAAAI5HdqYAAAAAAAAEdqYAcFTYpQIAAADA8crOFAAAAAAAgEBMAQAAAAAACMQUAAAAAACAQEwBoCsazVb7OSo/fgwAAAAAxxoxBQAAAAAAIBBTAAAAAAAAAjEFAAAAAID/b+/+Y+ssz7uBX0nc/GjAzgIiJgV2si0toJKgJiNzhwZdM5z1aCUqQqWKRoiiME3JRmaN6lCFRAKkWOkPQgrFRVthlcZAmQpTOTSVFUrQRBYggAQMKpiwQDAnoCgx+H3zg/h5/+DNqU+w79iJ7cfH5/ORHuU5z3OfO9fpH3ejfnvdN5DQkHcBANDfYGendLUXx7gSAAAAAPiUzhQAAAAAAIAEYQoANaNQKg/auQIAAAAAo8U2XwDUpP6hii3AAAAAABhNOlMAAAAAAAAShCkAAAAAAAAJwhQAAAAAAIAEZ6YAUPOcnwIAAADAaNKZAgAAAAAAkCBMAQAAAAAASBCmAAAAAAAAJAhTAAAAAAAAEoQpAAAAAAAACcIUAAAAAACABGEKABNOoVSOQqmcdxkAAAAATBDCFAAmNMEKAAAAAGdKmAIAAAAAAJAgTAEAAAAAAEgQpgAAAAAAACQIUwAAAAAAABKEKQAAAAAAAAkNeRcAAGOlUCpX7rvaizlWAgAAAEAt0ZkCAAAAAACQIEwBAAAAAABIEKYAAAAAAAAkCFMAAAAAAAAShCkAAAAAAAAJDXkXAAB5KJTKlfuu9mLlc1d7Ma+SAAAAABinhCkAcJKTgxYAAAAA6pttvgAAAAAAABKEKQAAAAAAAAm2+QKABFt+AQAAAKAzBQCGoVAqVwUsAAAAAEx8whQAAAAAAIAEYQoAAAAAAECCMAUAAAAAACBBmAIAp8n5KQAAAAD1QZgCAAAAAACQIEwBAAAAAABIEKYAAAAAAAAkCFMAAAAAAAAShCkAAAAAAAAJwhQAAAAAAIAEYQoAAAAAAECCMAUAAAAAACBBmAIAAAAAAJAgTAEAAAAAAEgQpgAAAAAAACQ05F0AAEwEhVK5ct/VXsyxEgAAAABGms4UAAAAAACABGEKAAAAAABAgjAFAAAAAAAgQZgCAAAAAACQIEwBAAAAAABIEKYAAAAAAAAkNORdAABMNIVSuXLf1V7MsRIAAAAARoLOFAAAAAAAgARhCgAAAAAAQIIwBQBGWaFUrtr6CwAAAIDaIkwBAAAAAABIEKYAAAAAAAAkCFMAAAAAAAAShCkAAAAAAAAJDXkXAAD1ZLCD6Lvai2NcCQAAAABDpTMFAMaJQqk8aNgCAAAAQH6EKQAAAAAAAAnCFAAAAAAAgARhCgAAAAAAQIIwBQDGIeenAAAAAIwfDXkXAACk9Q9VutqLOVYCAAAAUJ+EKQBQQwQrAAAAAGPPNl8AAAAAAAAJwhQAAAAAAIAEYQoA1DAH1QMAAACMPmEKAAAAAABAgjAFAAAAAAAgQZgCAAAAAACQIEwBAAAAAABIaMi7AABgZPQ/iL6rvZhjJQAAAAATi84UAAAAAACABGEKAAAAAABAgm2+AGACsuUXAAAAwMjRmQIAdaBQKlcClv73AAAAAJyaMAUAAAAAACBBmAIAAAAAAJAgTAEAAAAAAEgQpgAAAAAAACQIUwAAAAAAABIa8i4AAMhPoVSu3He1F3OsBAAAAGD80pkCAAAAAACQoDMFAIgIXSoAAAAAg9GZAgAAAAAAkCBMAQAGVCiVq7pVAAAAAOqVbb4AgFOyBRgAAABQz3SmAAAAAAAAJAhTAAAAAAAAEmzzBQAMiy2/AAAAgHqjMwUAOCMOqgcAAAAmOp0pAMCIORGqdLUXdbAAAAAAE4bOFAAAAAAAgARhCgAAAAAAQIIwBQAAAAAAIEGYAgAAAAAAkCBMAQAAAAAASBCmAAAAAAAAJAhTAAAAAAAAEoQpAAAAAAAACcIUAAAAAACABGEKAAAAAABAQkPeBQAAE1+hVK7cd7UXc6wEAAAAYPh0pgAAAAAAACQIUwAAAAAAABKEKQAAAAAAAAnCFAAAAAAAgARhCgAAAAAAQIIwBQAAAAAAIEGYAgCMuUKpHIVSOe8yAAAAAIakIe8CAID6Nlio0tVeHONKAAAAAAamMwUAAAAAACBBmAIAjFu2AwMAAADGA9t8AQA1oX+oYgswAAAAYCwJUwCAmiNYAQAAAMaSMAUAqGmCFQAAAGC0OTMFAJhQnLMCAAAAjLT660zp7Y2YMiXvKsadGUcPf3rT2/u7+5P1fzfY/VC/Y25zm9vc5jb3SI1LfAcAAABgUMP43w4mZVmWjWIp40ZPT080NTXFoYhozLsYAAAAAAAgVz0R0RQRhw4disbGdHJgmy8AAAAAAICE+tvm6/33I06RMNWjS27fERERr9+5rHJ/sv7vBrsf6nfMbW5zm9vc5h6pcUP9zut3Ljvl9wEAAIA60tMTMXfukIbWX5gyc+anF1X+79Tpn97MnPm7+5P1fzfY/VC/Y25zm9vc5jb3SI0b4ncKdz5due9qL556LgAAAGBiO358yENt8wUAAAAAAJAgTAEA6lKhVI5CqZx3GQAAAEANEKYAAAAAAAAkCFMAAAAAAAAShCkAAAAAAAAJwhQAAAAAAICEhrwLAADI22AH0Xe1F8e4EgAAAGA8EqYAAAyif8giWAEAAID6ZZsvAAAAAACABGEKAAAAAABAgjAFAAAAAAAgQZgCAAAAAACQIEwBAAAAAABIEKYAAAAAAAAkNORdAABArSiUyhER0dVerNyf+AwAAABMXMIUAIAzJFgBAACAiU2YAgAwwnSwAAAAwMTizBQAAAAAAIAEYQoAAAAAAECCMAUAAAAAACDBmSkAAGPE+SkAAABQm4QpAAA5EKwAAABA7bDNFwAAAAAAQIIwBQAAAAAAIEGYAgAAAAAAkCBMAQAAAAAASBCmAAAAAAAAJAhTAAAAAAAAEoQpAAAAAAAACcIUAAAAAACABGEKAAAAAABAgjAFAAAAAAAgQZgCAAAAAACQIEwBAAAAAABIEKYAAAAAAAAkCFMAAAAAAAASGvIuAACAiEKpHBERXe3Fyv2JzwAAAEC+dKYAAAAAAAAkCFMAAAAAAAAShCkAAAAAAAAJzkwBABjHTj4/pf/ZKgAAAMDY0JkCAAAAAACQoDMFAKBGndy1AgAAAIwOnSkAAAAAAAAJwhQAAAAAAIAEYQoAAAAAAECCM1MAACaA/uen9NfVXqy8c64KAAAAnB6dKQAAAAAAAAk6UwAA6kj/DhadKgAAADA0whQAgDolWAEAAIChsc0XAAAR8Wm4MtjZKwAAAFDPhCkAAAAAAAAJtvkCAOAzbAEGAAAAvyNMAQAgSbACAABAvbPNFwAAAAAAQIIwBQAAAAAAIME2XwAADJktvwAAAKhHp9WZct9990WhUIjp06fHkiVL4rnnnkuO3759e1x88cUxffr0uOyyy+LJJ5+sep9lWWzcuDHOP//8mDFjRixdujTefPPNyvuurq5YvXp1zJs3L2bMmBF/+Id/GJs2bYqjR4+eTvkAAAAAAABDNuww5dFHH422trbYtGlTvPjii7Fw4cJobW2N/fv3Dzj+2Wefje985zuxevXqeOmll2L58uWxfPnyePXVVytjtmzZEtu2bYuOjo7Ys2dPzJw5M1pbW+Pw4cMREfHGG29EX19f/PSnP43XXnst7r777ujo6Ijvfe97p/mzAQAYCYVSuapbBQAAACaiYYcpP/rRj2LNmjWxatWquPTSS6OjoyM+//nPx89+9rMBx99zzz2xbNmyuPXWW+OSSy6JO++8M77yla/EvffeGxGfdqVs3bo1NmzYENdee20sWLAgfv7zn8f7778fjz/+eERELFu2LB588MG45ppr4g/+4A/im9/8ZvzjP/5j/OIXvzj9Xw4AAAAAADAEwwpTjh49Gnv37o2lS5f+boLJk2Pp0qWxe/fuAb+ze/fuqvEREa2trZXxb7/9dnR3d1eNaWpqiiVLlgw6Z0TEoUOHYvbs2YO+P3LkSPT09FRdAAAAAAAAwzWsMOXDDz+M48ePx5w5c6qez5kzJ7q7uwf8Tnd3d3L8iT+HM+dbb70VP/7xj+Nv/uZvBq118+bN0dTUVLkuvPDC9I8DAAAAAAAYwGkdQJ+n9957L5YtWxbXX399rFmzZtBxt912Wxw6dKhyvfvuu2NYJQAAAAAAMFEMK0w599xzY8qUKbFv376q5/v27Yvm5uYBv9Pc3Jwcf+LPocz5/vvvx9e+9rX46le/Gg888ECy1mnTpkVjY2PVBQAAAAAAMFzDClOmTp0aixYtip07d1ae9fX1xc6dO6OlpWXA77S0tFSNj4jo7OysjJ83b140NzdXjenp6Yk9e/ZUzfnee+/F1VdfHYsWLYoHH3wwJk+uuaYaAAAAAACgBjUM9wttbW2xcuXKWLx4cVxxxRWxdevW6O3tjVWrVkVExI033hhf+MIXYvPmzRERccstt8RVV10VP/zhD6NYLMYjjzwSL7zwQqWzZNKkSbF+/fq46667Yv78+TFv3ry4/fbbY+7cubF8+fKI+F2Q8vu///vxgx/8ID744INKPYN1xAAAAAAAAIyEYYcp3/72t+ODDz6IjRs3Rnd3d1x++eWxY8eOygHy77zzTlXXyFe/+tV4+OGHY8OGDfG9730v5s+fH48//nh8+ctfroz57ne/G729vXHzzTfHwYMH48orr4wdO3bE9OnTI+LTTpa33nor3nrrrbjggguq6smy7LR+OAAAI6tQKlfuu9qLOVYCAAAAI2vYYUpExLp162LdunUDvnv66ac/8+z666+P66+/ftD5Jk2aFHfccUfccccdA76/6aab4qabbjqdUgEAyIFgBQAAgInEwSMAAAAAAAAJwhQAAAAAAIAEYQoAAAAAAECCMAUAgFFXKJWrzlEBAACAWiJMAQAAAAAASGjIuwAAAOpL/w6VrvZijpUAAADA0OhMAQAAAAAASNCZAgBAbgY7R0XHCgAAAOOJzhQAAAAAAIAEYQoAAAAAAECCMAUAgHGpUCoPug0YAAAAjCVhCgAAAAAAQIIwBQAAAAAAIKEh7wIAAOBUBtvuq6u9OMaVAAAAUI90pgAAUNOcrQIAAMBo05kCAMCE0T9U0bUCAADASBGmAAAwIQlWAAAAGCm2+QIAAAAAAEgQpgAAAAAAACQIUwAAAAAAABKcmQIAwITn/BQAAADOhM4UAAAAAACABGEKAAAAAABAgjAFAIC6UyiVq7b+AgAAgBRnpgAAUNecpwIAAMCpCFMAAOD/OzlYOfFZyAIAAFDfbPMFAAAAAACQIEwBAAAAAABIEKYAAAAAAAAkODMFAACGoP95Kv05TwUAAGDiE6YAAMAZOPnQegAAACYe23wBAAAAAAAkCFMAAAAAAAAShCkAADCCCqXyoOerAAAAUJuEKQAAAAAAAAkOoAcAgFHicHoAAICJQZgCAABjQLACAABQu2zzBQAAAAAAkCBMAQAAAAAASBCmAAAAAAAAJAhTAAAgB4VSueocFQAAAMYvYQoAAAAAAEBCQ94FAABAvevfodLVXsyxEgAAAAYiTAEAgHFksK2/hCwAAAD5sc0XAAAAAABAgjAFAAAAAAAgQZgCAAAAAACQIEwBAAAAAABIcAA9AADUiBOH03e1Fx1UDwAAMIZ0pgAAwARTKJUHDVsAAAAYPp0pAAAwgelgAQAAOHM6UwAAAAAAABJ0pgAAQB3q37GiSwUAACBNZwoAAAAAAECCMAUAAAAAACBBmAIAAEShVB70sHoAAIB6J0wBAAAAAABIEKYAAAAAAAAkCFMAAAAAAAAShCkAAAAAAAAJDXkXAAAAjC/9D6Lvai/mWAkAAMD4oDMFAAAAAAAgQWcKAAAwqJO7VE581rECAADUE2EKAABwWmwHBgAA1AthCgAAcMYEKwAAwETmzBQAAAAAAIAEYQoAAAAAAECCMAUAAAAAACBBmAIAAAAAAJAgTAEAAAAAAEhoyLsAAABgYimUypX7rvZi5XP/+5OdPA4AAGA80ZkCAAAAAACQIEwBAAAAAABIEKYAAAAAAAAkODMFAAAYd04+dwUAACBPOlMAAAAAAAASdKYAAADjmi4VAAAgbzpTAAAAAAAAEoQpAAAAAAAACbb5AgAAaoYtvwAAgDzoTAEAAAAAAEgQpgAAAAAAACQIUwAAAAAAABKcmQIAANSsE2eodLUXq85T6c/ZKgAAwJnSmQIAAEx4hVJ50LAFAADgVIQpAAAAAAAACcIUAAAAAACABGEKAAAAAABAggPoAQCAutL/7BSH0wMAAEOhMwUAAAAAACBBmAIAAAAAAJAgTAEAAAAAAEhwZgoAAFC3nJ8CAAAMhc4UAAAAAACABGEKAAAAAABAgjAFAAAAAAAgQZgCAAAAAACQIEwBAAAAAABIEKYAAAAAAAAkCFMAAAAAAAAShCkAAAAAAAAJwhQAAAAAAICEhrwLAAAAGA8KpXLlvqu9WPnc1V7MqyQAAGCcEKYAAACcQv+gpT9BCwAA1AfbfAEAAJyBQqk8aNgCAABMDMIUAAAAAACABNt8AQAAjJChdKjYGgwAAGqPMAUAAGCM9T/c/uSD7wEAgPHHNl8AAAAAAAAJOlMAAADGCV0qAAAwPulMAQAAAAAASBCmAAAAAAAAJAhTAAAAAAAAEoQpAAAAAAAACcIUAAAAAACABGEKAAAAAABAgjAFAABgnCqUylEolfMuAwAA6p4wBQAAAAAAIKEh7wIAAAA4tf4dKl3txRwrAQCA+qMzBQAAAAAAIEFnCgAAQI3RpQIAAGNLZwoAAAAAAECCzhQAAIAapksFAABGn84UAAAAAACABGEKAADABFIolau6VQAAgDMnTAEAAAAAAEgQpgAAAAAAACQIUwAAAAAAABIa8i4AAACA0dH/7JSu9mKOlQAAQG0TpgAAANQBwQoAAJw+23wBAADUoUKpXBWwAAAAg9OZAgAAUOeGEqroZgEAoJ7pTAEAAAAAAEgQpgAAAAAAACQIUwAAAAAAABKEKQAAAAAAAAnCFAAAAIakUCoP6bB6AACYaIQpAAAAAAAACcIUAAAAAACABGEKAAAAAABAgjAFAAAAAAAgoSHvAgAAAKg9/Q+i72ov5lgJAACMPp0pAAAAAAAACTpTAAAAOCMnd6mc+Nz//sRnAACoRcIUAAAAxoRgBQCAWmWbLwAAAAAAgASdKQAAAIw5XSoAANQSnSkAAADkrlAqVwUsAAAwnghTAAAAAAAAEoQpAAAAAAAACcIUAAAAAACABAfQAwAAMK44nB4AgPFGmAIAAMC4JVgBAGA8sM0XAAAAAABAgjAFAAAAAAAgQZgCAAAAAACQIEwBAAAAAABIEKYAAAAAAAAkCFMAAAAAAAAShCkAAAAAAAAJwhQAAABqRqFUjkKpnHcZAADUmYa8CwAAAIDT0T9U6Wov5lgJAAATnc4UAAAAAACABJ0pAAAA1DxdKgAAjCadKQAAAAAAAAnCFAAAAAAAgATbfAEAADCh2PILAICRpjMFAAAAAAAgQZgCAAAAAACQIEwBAAAAAABIEKYAAAAwoRVK5apzVAAAYLgcQA8AAEDdcDg9AACnQ2cKAAAAAABAgjAFAAAAAAAgQZgCAAAAAACQ4MwUAAAA6pLzUwAAGCqdKQAAAAAAAAnCFAAAAAAAgATbfAEAAED8btuvrvaiLcAAAKiiMwUAAAAAACBBmAIAAAAAAJAgTAEAAAAAAEgQpgAAAAAAACQIUwAAAAAAABKEKQAAAAAAAAnCFAAAAAAAgARhCgAAAAAAQIIwBQAAAAAAIEGYAgAAAAAAkCBMAQAAAAAASGjIuwAAAAAYzwqlcuW+q72YYyUAAORFmAIAAABDJFgBAKhPtvkCAAAAAABI0JkCAAAAp+lEp0pXe1HXCgDABCZMAQAAgBEmWAEAmFhs8wUAAACjrFAqVwUsAADUFmEKAAAAAABAgjAFAAAAAAAgQZgCAAAAAACQ4AB6AAAAGEMOpwcAqD3CFAAAAMiJYAUAoDbY5gsAAAAAACBBmAIAAAAAAJAgTAEAAAAAAEgQpgAAAAAAACQIUwAAAAAAABKEKQAAAAAAAAnCFAAAAAAAgARhCgAAAIwThVI5CqXyZ+4BAMhXQ94FAAAAAGn9Q5Wu9mKOlQAA1CedKQAAAAAAAAnCFAAAAAAAgATbfAEAAEANseUXAMDY05kCAAAANcxB9QAAo0+YAgAAAAAAkCBMAQAAAAAASHBmCgAAAEwQg2331dVerLxzzgoAwPDpTAEAAAAAAEgQpgAAAECdcWg9AMDw2OYLAAAA6lj/UMUWYAAAA9OZAgAAAAAAkCBMAQAAAAAASBCmAAAAAAAAJAhTAAAAAAAAEhxADwAAAESEw+gBAAajMwUAAAAYUKFUrgpYAADqlTAFAAAAAAAgQZgCAAAAAACQIEwBAAAAAABIEKYAAAAAAAAkCFMAAAAAAAAShCkAAAAAAAAJDXkXAAAAAIx/hVK5ct/VXsyxEgCAsaczBQAAAAAAIEFnCgAAADAsulQAgHqjMwUAAAAAACBBmAIAAAAAAJAgTAEAAAAAAEgQpgAAAAAAACQIUwAAAIAzUiiVqw6lBwCYaIQpAAAAwIgRrAAAE5EwBQAAAAAAIEGYAgAAAAAAkNCQdwEAAADAxNR/u6+u9mKOlQAAnBlhCgAAADDqBCsAQC2zzRcAAAAAAECCMAUAAAAAACDhtMKU++67LwqFQkyfPj2WLFkSzz33XHL89u3b4+KLL47p06fHZZddFk8++WTV+yzLYuPGjXH++efHjBkzYunSpfHmm29WjTlw4ECsWLEiGhsbY9asWbF69er4+OOPT6d8AAAAAACAIRt2mPLoo49GW1tbbNq0KV588cVYuHBhtLa2xv79+wcc/+yzz8Z3vvOdWL16dbz00kuxfPnyWL58ebz66quVMVu2bIlt27ZFR0dH7NmzJ2bOnBmtra1x+PDhypgVK1bEa6+9Fp2dnfHEE0/EM888EzfffPNp/GQAAAAgb4VSuXKOyon7ky8AgPFi2AfQ/+hHP4o1a9bEqlWrIiKio6MjyuVy/OxnP4tSqfSZ8ffcc08sW7Ysbr311oiIuPPOO6OzszPuvffe6OjoiCzLYuvWrbFhw4a49tprIyLi5z//ecyZMycef/zxuOGGG+L111+PHTt2xPPPPx+LFy+OiIgf//jH8Y1vfCN+8IMfxNy5cz/z9x45ciSOHDlS+Xzo0KGIiOjp6RnuT64LfUf+T0R8+p/PifuT9X832P1Qv2Nuc5vb3OY290iNM7e5zW1uc5t7osw90f47e6TmBgAYLSf+rZFl2akHZ8Nw5MiRbMqUKdljjz1W9fzGG2/MvvnNbw74nQsvvDC7++67q55t3LgxW7BgQZZlWfY///M/WURkL730UtWYP/uzP8v+/u//PsuyLPvnf/7nbNasWVXvjx07lk2ZMiX7xS9+MeDfu2nTpiwiXC6Xy+VyuVwul8vlcrlcLpfL5XK5Br3efffdU+Yjw+pM+fDDD+P48eMxZ86cqudz5syJN954Y8DvdHd3Dzi+u7u78v7Es9SY8847r+p9Q0NDzJ49uzLmZLfddlu0tbVVPvf19cWBAwfinHPOiUmTJp3qp9adnp6euPDCC+Pdd9+NxsbGvMsBGFeskQADsz4CDM4aCTAw6yPjSZZl8dFHHw24+9XJhr3NV62YNm1aTJs2rerZrFmz8immhjQ2NlrEAAZhjQQYmPURYHDWSICBWR8ZL5qamoY0blgH0J977rkxZcqU2LdvX9Xzffv2RXNz84DfaW5uTo4/8eepxpx8wP0nn3wSBw4cGPTvBQAAAAAAGAnDClOmTp0aixYtip07d1ae9fX1xc6dO6OlpWXA77S0tFSNj4jo7OysjJ83b140NzdXjenp6Yk9e/ZUxrS0tMTBgwdj7969lTFPPfVU9PX1xZIlS4bzEwAAAAAAAIZl2Nt8tbW1xcqVK2Px4sVxxRVXxNatW6O3tzdWrVoVERE33nhjfOELX4jNmzdHRMQtt9wSV111Vfzwhz+MYrEYjzzySLzwwgvxwAMPRETEpEmTYv369XHXXXfF/PnzY968eXH77bfH3LlzY/ny5RERcckll8SyZctizZo10dHREceOHYt169bFDTfcMKS9zDi1adOmxaZNmz6zNRoA1kiAwVgfAQZnjQQYmPWRWjUpy7JsuF+699574/vf/350d3fH5ZdfHtu2bat0iFx99dVRKBTioYceqozfvn17bNiwIbq6umL+/PmxZcuW+MY3vlF5n2VZbNq0KR544IE4ePBgXHnllfGTn/wkvvjFL1bGHDhwINatWxe//OUvY/LkyXHdddfFtm3b4qyzzjqDnw8AAAAAAJB2WmEKAAAAAABAvRjWmSkAAAAAAAD1RpgCAAAAAACQIEwBAAAAAABIEKYAAAAAAAAkCFOI++67LwqFQkyfPj2WLFkSzz33XN4lAYy6Z555Jv7qr/4q5s6dG5MmTYrHH3+86n2WZbFx48Y4//zzY8aMGbF06dJ48803q8YcOHAgVqxYEY2NjTFr1qxYvXp1fPzxx2P4KwBG3ubNm+OP//iP4+yzz47zzjsvli9fHr/97W+rxhw+fDjWrl0b55xzTpx11llx3XXXxb59+6rGvPPOO1EsFuPzn/98nHfeeXHrrbfGJ598MpY/BWDE3X///bFgwYJobGyMxsbGaGlpiV/96leV99ZHgE+1t7fHpEmTYv369ZVn1khqnTClzj366KPR1tYWmzZtihdffDEWLlwYra2tsX///rxLAxhVvb29sXDhwrjvvvsGfL9ly5bYtm1bdHR0xJ49e2LmzJnR2toahw8froxZsWJFvPbaa9HZ2RlPPPFEPPPMM3HzzTeP1U8AGBW7du2KtWvXxn/9139FZ2dnHDt2LK655pro7e2tjPmHf/iH+OUvfxnbt2+PXbt2xfvvvx/f+ta3Ku+PHz8exWIxjh49Gs8++2z8y7/8Szz00EOxcePGPH4SwIi54IILor29Pfbu3RsvvPBC/Pmf/3lce+218dprr0WE9REgIuL555+Pn/70p7FgwYKq59ZIal5GXbviiiuytWvXVj4fP348mzt3brZ58+YcqwIYWxGRPfbYY5XPfX19WXNzc/b973+/8uzgwYPZtGnTsn/7t3/LsizL/vu//zuLiOz555+vjPnVr36VTZo0KXvvvffGrHaA0bZ///4sIrJdu3ZlWfbpevi5z30u2759e2XM66+/nkVEtnv37izLsuzJJ5/MJk+enHV3d1fG3H///VljY2N25MiRsf0BAKPs937v97J/+qd/sj4CZFn20UcfZfPnz886Ozuzq666KrvllluyLPNvSCYGnSl17OjRo7F3795YunRp5dnkyZNj6dKlsXv37hwrA8jX22+/Hd3d3VXrY1NTUyxZsqSyPu7evTtmzZoVixcvroxZunRpTJ48Ofbs2TPmNQOMlkOHDkVExOzZsyMiYu/evXHs2LGqNfLiiy+Oiy66qGqNvOyyy2LOnDmVMa2trdHT01P5f28D1Lrjx4/HI488Er29vdHS0mJ9BIiItWvXRrFYrFoLI/wbkomhIe8CyM+HH34Yx48fr1qgIiLmzJkTb7zxRk5VAeSvu7s7ImLA9fHEu+7u7jjvvPOq3jc0NMTs2bMrYwBqXV9fX6xfvz7+9E//NL785S9HxKfr39SpU2PWrFlVY09eIwdaQ0+8A6hlr7zySrS0tMThw4fjrLPOisceeywuvfTSePnll62PQF175JFH4sUXX4znn3/+M+/8G5KJQJgCAAAMaO3atfHqq6/Gf/7nf+ZdCsC48aUvfSlefvnlOHToUPz7v/97rFy5Mnbt2pV3WQC5evfdd+OWW26Jzs7OmD59et7lwKiwzVcdO/fcc2PKlCmxb9++quf79u2L5ubmnKoCyN+JNTC1PjY3N8f+/fur3n/yySdx4MABaygwIaxbty6eeOKJ+M1vfhMXXHBB5Xlzc3McPXo0Dh48WDX+5DVyoDX0xDuAWjZ16tT4oz/6o1i0aFFs3rw5Fi5cGPfcc4/1Eahre/fujf3798dXvvKVaGhoiIaGhti1a1ds27YtGhoaYs6cOdZIap4wpY5NnTo1Fi1aFDt37qw86+vri507d0ZLS0uOlQHka968edHc3Fy1Pvb09MSePXsq62NLS0scPHgw9u7dWxnz1FNPRV9fXyxZsmTMawYYKVmWxbp16+Kxxx6Lp556KubNm1f1ftGiRfG5z32uao387W9/G++8807VGvnKK69Uhc6dnZ3R2NgYl1566dj8EIAx0tfXF0eOHLE+AnXt61//erzyyivx8ssvV67FixfHihUrKvfWSGqdbb7qXFtbW6xcuTIWL14cV1xxRWzdujV6e3tj1apVeZcGMKo+/vjjeOuttyqf33777Xj55Zdj9uzZcdFFF8X69evjrrvuivnz58e8efPi9ttvj7lz58by5csjIuKSSy6JZcuWxZo1a6KjoyOOHTsW69atixtuuCHmzp2b068COHNr166Nhx9+OP7jP/4jzj777Mr+1E1NTTFjxoxoamqK1atXR1tbW8yePTsaGxvj7/7u76KlpSX+5E/+JCIirrnmmrj00kvjr//6r2PLli3R3d0dGzZsiLVr18a0adPy/HkAZ+S2226Lv/zLv4yLLrooPvroo3j44Yfj6aefjl//+tfWR6CunX322ZUz9k6YOXNmnHPOOZXn1khqnTClzn3729+ODz74IDZu3Bjd3d1x+eWXx44dOz5z2BPARPPCCy/E1772tcrntra2iIhYuXJlPPTQQ/Hd7343ent74+abb46DBw/GlVdeGTt27Kja+/Vf//VfY926dfH1r389Jk+eHNddd11s27ZtzH8LwEi6//77IyLi6quvrnr+4IMPxk033RQREXfffXdl3Tty5Ei0trbGT37yk8rYKVOmxBNPPBF/+7d/Gy0tLTFz5sxYuXJl3HHHHWP1MwBGxf79++PGG2+M//3f/42mpqZYsGBB/PrXv46/+Iu/iAjrI0CKNZJaNynLsizvIgAAAAAAAMYrZ6YAAAAAAAAkCFMAAAAAAAAShCkAAAAAAAAJwhQAAAAAAIAEYQoAAAAAAECCMAUAAAAAACBBmAIAAAAAAJAgTAEAAAAAAEgQpgAAAAAAACQIUwAAAAAAABKEKQAAAAAAAAn/D8tnvhJmiHMGAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 2000x2000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features with scores above the threshold_mic: 134\n"
     ]
    }
   ],
   "source": [
    "# sort the scores in descending order\n",
    "scores.sort(reverse=True)\n",
    "\n",
    "threshold_mic = 0.0025\n",
    "\n",
    "# plot the scores\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.bar([i for i in range(len(scores))], scores)\n",
    "# draw a vertical line at the threshold_mic\n",
    "plt.axhline(y=threshold_mic, color='r', linestyle='-')\n",
    "plt.savefig('outputs/00_feature_select_29/feat_imp_mutual_info_sorted.png')\n",
    "plt.show()\n",
    "\n",
    "# get the number of features with scores above the threshold_mic\n",
    "\n",
    "num_features = len([i for i in scores if i > threshold_mic])\n",
    "print(f\"number of features with scores above the threshold_mic: {num_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test, mutual_info_classif, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest 1/1 trained with \n",
      "F1 score: 0.4723849866542789 \n",
      "test accuracy: 0.8380 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6802747976661021 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.84      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.84      0.51      0.47      5752\n",
      "weighted avg       0.84      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/1: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8379694019471489\n"
     ]
    }
   ],
   "source": [
    "models, test_accuracies = train_random_forests(X_train_fs, y_train, X_test_fs, y_test)\n",
    "print(f\"average test accuracy: {np.mean(test_accuracies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range: 0.00890041760974042\n"
     ]
    }
   ],
   "source": [
    "# difference between the max and threshold scores\n",
    "range_mic =  max_mic_imp - threshold_mic\n",
    "print(f\"Range: {range_mic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\n",
      "\n",
      "Threshold: 0.0025\n",
      "number of features with scores above the threshold: 134\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4724538500360015 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6686519768899631 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.89      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.86      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4723161491956597 \n",
      "test accuracy: 0.8378 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6775232988047633 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.80      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.82      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "1:\n",
      "\n",
      "Threshold: 0.0034000000000000002\n",
      "number of features with scores above the threshold: 94\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47506274241387175 \n",
      "test accuracy: 0.8373 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6547736270848399 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.66      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.75      0.51      0.48      5752\n",
      "weighted avg       0.81      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4761844032206798 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6467847264185936 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.69      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.76      0.51      0.48      5752\n",
      "weighted avg       0.81      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "2:\n",
      "\n",
      "Threshold: 0.0043\n",
      "number of features with scores above the threshold: 63\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4909166834954882 \n",
      "test accuracy: 0.8315 \n",
      "train accuracy: 0.9960 \n",
      "ROAUC: 0.6362315538516912 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.38      0.04      0.07       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.61      0.51      0.49      5752\n",
      "weighted avg       0.76      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4905631172610291 \n",
      "test accuracy: 0.8326 \n",
      "train accuracy: 0.9963 \n",
      "ROAUC: 0.64088713219148 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.40      0.04      0.07       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.62      0.51      0.49      5752\n",
      "weighted avg       0.77      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "3:\n",
      "\n",
      "Threshold: 0.0052\n",
      "number of features with scores above the threshold: 34\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5192471341571047 \n",
      "test accuracy: 0.8152 \n",
      "train accuracy: 0.9706 \n",
      "ROAUC: 0.6042053971115755 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90      4807\n",
      "           1       0.30      0.09      0.14       945\n",
      "\n",
      "    accuracy                           0.82      5752\n",
      "   macro avg       0.57      0.53      0.52      5752\n",
      "weighted avg       0.75      0.82      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5184530896568091 \n",
      "test accuracy: 0.8150 \n",
      "train accuracy: 0.9718 \n",
      "ROAUC: 0.6036412947168096 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90      4807\n",
      "           1       0.30      0.09      0.14       945\n",
      "\n",
      "    accuracy                           0.82      5752\n",
      "   macro avg       0.57      0.52      0.52      5752\n",
      "weighted avg       0.75      0.82      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "4:\n",
      "\n",
      "Threshold: 0.0060999999999999995\n",
      "number of features with scores above the threshold: 19\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5222404627892433 \n",
      "test accuracy: 0.6335 \n",
      "train accuracy: 0.6931 \n",
      "ROAUC: 0.5759791441713639 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.67      0.75      4807\n",
      "           1       0.21      0.46      0.29       945\n",
      "\n",
      "    accuracy                           0.63      5752\n",
      "   macro avg       0.54      0.56      0.52      5752\n",
      "weighted avg       0.76      0.63      0.68      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5264021332144262 \n",
      "test accuracy: 0.6394 \n",
      "train accuracy: 0.6967 \n",
      "ROAUC: 0.5783994461339999 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.67      0.76      4807\n",
      "           1       0.22      0.46      0.30       945\n",
      "\n",
      "    accuracy                           0.64      5752\n",
      "   macro avg       0.54      0.57      0.53      5752\n",
      "weighted avg       0.76      0.64      0.68      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "5:\n",
      "\n",
      "Threshold: 0.006999999999999999\n",
      "number of features with scores above the threshold: 12\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.514262201909399 \n",
      "test accuracy: 0.6094 \n",
      "train accuracy: 0.6252 \n",
      "ROAUC: 0.5958580024941581 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.63      0.73      4807\n",
      "           1       0.21      0.51      0.30       945\n",
      "\n",
      "    accuracy                           0.61      5752\n",
      "   macro avg       0.54      0.57      0.51      5752\n",
      "weighted avg       0.76      0.61      0.66      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5151156729020683 \n",
      "test accuracy: 0.6080 \n",
      "train accuracy: 0.6221 \n",
      "ROAUC: 0.5979992801503098 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.63      0.73      4807\n",
      "           1       0.21      0.52      0.30       945\n",
      "\n",
      "    accuracy                           0.61      5752\n",
      "   macro avg       0.54      0.57      0.52      5752\n",
      "weighted avg       0.76      0.61      0.66      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "6:\n",
      "\n",
      "Threshold: 0.0078\n",
      "number of features with scores above the threshold: 6\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.463420638079587 \n",
      "test accuracy: 0.5177 \n",
      "train accuracy: 0.5291 \n",
      "ROAUC: 0.584563516828963 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.50      0.63      4807\n",
      "           1       0.19      0.61      0.29       945\n",
      "\n",
      "    accuracy                           0.52      5752\n",
      "   macro avg       0.53      0.55      0.46      5752\n",
      "weighted avg       0.76      0.52      0.58      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 0 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4632932465997358 \n",
      "test accuracy: 0.5176 \n",
      "train accuracy: 0.5290 \n",
      "ROAUC: 0.5823751297435508 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.50      0.63      4807\n",
      "           1       0.19      0.61      0.29       945\n",
      "\n",
      "    accuracy                           0.52      5752\n",
      "   macro avg       0.53      0.55      0.46      5752\n",
      "weighted avg       0.76      0.52      0.58      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 0 seconds\n",
      "7:\n",
      "\n",
      "Threshold: 0.0087\n",
      "number of features with scores above the threshold: 5\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4887849285623973 \n",
      "test accuracy: 0.5607 \n",
      "train accuracy: 0.5672 \n",
      "ROAUC: 0.5902657390071577 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.56      0.68      4807\n",
      "           1       0.20      0.57      0.30       945\n",
      "\n",
      "    accuracy                           0.56      5752\n",
      "   macro avg       0.53      0.56      0.49      5752\n",
      "weighted avg       0.76      0.56      0.62      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.47907320917227214 \n",
      "test accuracy: 0.5436 \n",
      "train accuracy: 0.5516 \n",
      "ROAUC: 0.5902166483402181 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.54      0.66      4807\n",
      "           1       0.20      0.58      0.30       945\n",
      "\n",
      "    accuracy                           0.54      5752\n",
      "   macro avg       0.53      0.56      0.48      5752\n",
      "weighted avg       0.76      0.54      0.60      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "8:\n",
      "\n",
      "Threshold: 0.009600000000000001\n",
      "number of features with scores above the threshold: 4\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.45031731612514314 \n",
      "test accuracy: 0.4920 \n",
      "train accuracy: 0.5043 \n",
      "ROAUC: 0.5816582519099681 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.46      0.60      4807\n",
      "           1       0.19      0.66      0.30       945\n",
      "\n",
      "    accuracy                           0.49      5752\n",
      "   macro avg       0.53      0.56      0.45      5752\n",
      "weighted avg       0.76      0.49      0.55      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 0 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.45031731612514314 \n",
      "test accuracy: 0.4920 \n",
      "train accuracy: 0.5043 \n",
      "ROAUC: 0.5816582519099681 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.46      0.60      4807\n",
      "           1       0.19      0.66      0.30       945\n",
      "\n",
      "    accuracy                           0.49      5752\n",
      "   macro avg       0.53      0.56      0.45      5752\n",
      "weighted avg       0.76      0.49      0.55      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 0 seconds\n",
      "9:\n",
      "\n",
      "Threshold: 0.0105\n",
      "number of features with scores above the threshold: 2\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.31352327030329424 \n",
      "test accuracy: 0.3140 \n",
      "train accuracy: 0.3120 \n",
      "ROAUC: 0.5664120776248923 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.20      0.33      4807\n",
      "           1       0.18      0.88      0.30       945\n",
      "\n",
      "    accuracy                           0.31      5752\n",
      "   macro avg       0.54      0.54      0.31      5752\n",
      "weighted avg       0.78      0.31      0.33      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 0 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.31352327030329424 \n",
      "test accuracy: 0.3140 \n",
      "train accuracy: 0.3120 \n",
      "ROAUC: 0.5664120776248923 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.20      0.33      4807\n",
      "           1       0.18      0.88      0.30       945\n",
      "\n",
      "    accuracy                           0.31      5752\n",
      "   macro avg       0.54      0.54      0.31      5752\n",
      "weighted avg       0.78      0.31      0.33      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 0 seconds\n",
      "10:\n",
      "\n",
      "Threshold: 0.0114\n",
      "number of features with scores above the threshold: 1\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5212132835825627 \n",
      "test accuracy: 0.6667 \n",
      "train accuracy: 0.6590 \n",
      "ROAUC: 0.5400258441448372 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.73      0.79      4807\n",
      "           1       0.20      0.35      0.26       945\n",
      "\n",
      "    accuracy                           0.67      5752\n",
      "   macro avg       0.53      0.54      0.52      5752\n",
      "weighted avg       0.74      0.67      0.70      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 0 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5212132835825627 \n",
      "test accuracy: 0.6667 \n",
      "train accuracy: 0.6590 \n",
      "ROAUC: 0.5400258441448372 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.73      0.79      4807\n",
      "           1       0.20      0.35      0.26       945\n",
      "\n",
      "    accuracy                           0.67      5752\n",
      "   macro avg       0.53      0.54      0.52      5752\n",
      "weighted avg       0.74      0.67      0.70      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 0 seconds\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "prev_num_feat = 0\n",
    "for i in range(11):\n",
    "    print(f\"{i}:\\n\")\n",
    "    threshold_itr = threshold_mic + round((range_mic * i / 10), 4)\n",
    "    print(f\"Threshold: {threshold_itr}\")\n",
    "    num_features_itr = len([sc for sc in scores if sc > threshold_itr])\n",
    "    print(f\"number of features with scores above the threshold: {num_features_itr}\")\n",
    "    if prev_num_feat != num_features_itr:\n",
    "        prev_num_feat = num_features_itr\n",
    "    else:\n",
    "        continue\n",
    "    if num_features_itr == 0:\n",
    "        break\n",
    "    X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test, mutual_info_classif, num_features_itr)\n",
    "    models, test_accuracies = train_random_forests(X_train_fs, y_train, X_test_fs, y_test, 2)\n",
    "    accuracy_scores.append((threshold_itr,np.mean(test_accuracies),num_features_itr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_th_mic = [i[0] for i in accuracy_scores]\n",
    "list_ac_mic = [i[1] for i in accuracy_scores]\n",
    "list_num_feat_mic = [i[2] for i in accuracy_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the min of accuracy or number of features\n",
    "min_ac_mic = min(list_ac_mic)\n",
    "min_num_feat_mic = min(list_num_feat_mic)\n",
    "min_pt = min(min_ac_mic, min_num_feat_mic)\n",
    "# the max of accuracy or number of features\n",
    "max_ac_mic = max(list_ac_mic)\n",
    "max_num_feat_mic = max(list_num_feat_mic)\n",
    "max_pt = max(max_ac_mic, max_num_feat_mic)\n",
    "\n",
    "# min and max of the thresholds RECORDER not corrosponding to the min and max of the accuracy\n",
    "min_th_mic = min(list_th_mic)\n",
    "max_th_mic = max(list_th_mic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAANXCAYAAAACeQ/SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAChF0lEQVR4nOzdd3hUZf7+8fvMpHdS6b1LryIIklB0XaxrwQJiXSuKZXUtqN9dsaygrvrDQrGgIq5rWZUWOtIRpIQACb2kUBJISJs5vz+SDMRQEkhyJjPv13XlcnOm3Yl+/XL7POfzGKZpmgIAAAAAnJHN6gAAAAAA4O4oTgAAAABwDhQnAAAAADgHihMAAAAAnAPFCQAAAADOgeIEAAAAAOdAcQIAAACAc6A4AQAAAMA5UJwAAAAA4BwoTgBQyyxYsECGYeibb76xOoqk6snz4osvyjCMCj3XMAy9+OKLVfbZAACcDsUJANyAYRgV+lqwYIHVUXEOP//8swzDUP369eV0Oq2OAwCoIj5WBwAASJ999lmZ7z/99FPNmTOn3PV27dopKSmpJqOhkqZNm6amTZtq586dmjdvngYNGmR1JABAFaA4AYAbuO2228p8v3z5cs2ZM6fcdUkXXJxyc3MVFBR0Qe+B08vJydH333+vcePGacqUKZo2bZrbFqecnBwFBwdbHQMAag226gFALeV0OvXPf/5TDRs2VEBAgBISErR9+/Yyz7nsssvUoUMHrVmzRv3791dQUJD+/ve/S5Ly8/M1duxYtWzZUv7+/mrUqJGeeuop5efnl3mPOXPmqF+/foqIiFBISIjatGnjeo/K5pGkGTNmqHv37goMDFR0dLRuu+027du375w/b35+vh577DHFxMQoNDRUV111lfbu3XvO16WlpcnHx0cvvfRSuceSk5NlGIbeffddSVJhYaFeeukltWrVSgEBAYqKilK/fv00Z86cc36OJP33v//ViRMndMMNN+jmm2/Wt99+q7y8vHLPy8vL04svvqjWrVsrICBA9erV03XXXaeUlBTXc5xOp95++2117NhRAQEBiomJ0eWXX67Vq1dLknbu3CnDMDR16tRy7//H+75K7xnbvHmzbrnlFtWpU0f9+vWTJP3++++644471Lx5cwUEBKhu3bq68847dejQoXLvu2/fPt11112qX7++/P391axZM91///0qKChQamqqDMPQhAkTyr3u119/lWEY+vLLLyv0ewQAd8SKEwDUUq+++qpsNpueeOIJZWVl6fXXX9ett96qFStWlHneoUOHdMUVV+jmm2/Wbbfdpri4ODmdTl111VVasmSJ7r33XrVr104bNmzQhAkTtHXrVn333XeSpE2bNunPf/6zOnXqpJdffln+/v7avn27li5del55pk6dqlGjRqlnz54aN26c0tLS9Pbbb2vp0qX67bffFBERccaf9+6779bnn3+uW265RZdcconmzZunK6+88py/p7i4OA0YMEBff/21xo4dW+ax6dOny26364YbbpBUXDDGjRunu+++W7169VJ2drZWr16ttWvXavDgwef8rGnTpmngwIGqW7eubr75Zj399NP68ccfXe8vSQ6HQ3/+85+VmJiom2++WaNHj9axY8c0Z84cbdy4US1atJAk3XXXXZo6daquuOIK3X333SoqKtLixYu1fPly9ejR45xZTueGG25Qq1at9Morr8g0TUnFxTg1NVWjRo1S3bp1tWnTJn344YfatGmTli9f7hrSsX//fvXq1UtHjx7Vvffeq7Zt22rfvn365ptvlJubq+bNm6tv376aNm2aHnvssXK/l9DQUF199dXnlRsA3IIJAHA7Dz74oHmmf0XPnz/flGS2a9fOzM/Pd11/++23TUnmhg0bXNcGDBhgSjInTpxY5j0+++wz02azmYsXLy5zfeLEiaYkc+nSpaZpmuaECRNMSWZGRsYZs1Y0T0FBgRkbG2t26NDBPHHihOt5//vf/0xJ5gsvvOC6Nnbs2DI//7p160xJ5gMPPFDms2+55RZTkjl27Ngz5jNN0/zggw/K/W5M0zTbt29vxsfHu77v3LmzeeWVV571vc4kLS3N9PHxMT/66CPXtUsuucS8+uqryzxv8uTJpiRz/Pjx5d7D6XSapmma8+bNMyWZjzzyyBmfs2PHDlOSOWXKlHLP+ePvpPT3OXz48HLPzc3NLXftyy+/NCWZixYtcl0bMWKEabPZzFWrVp0xU+nvOSkpyfVYQUGBGR0dbY4cObLc6wCgNmGrHgDUUqNGjZKfn5/r+0svvVSSlJqaWuZ5/v7+GjVqVJlrM2bMULt27dS2bVtlZma6vuLj4yVJ8+fPlyTXCtD3339/zglx58qzevVqpaen64EHHlBAQIDreVdeeaXatm2rn3766Yzv/fPPP0uSHnnkkTLXH3300bNmKnXdddfJx8dH06dPd13buHGjNm/erJtuusl1LSIiQps2bdK2bdsq9L6n+uqrr2Sz2XT99de7rg0fPly//PKLjhw54rr2n//8R9HR0Xr44YfLvUfp6s5//vMfGYZRboXs1Oecj7/+9a/lrgUGBrr+d15enjIzM3XxxRdLktauXSupeNvgd999p2HDhp12tas004033qiAgABNmzbN9disWbOUmZl52vv1AKA2oTgBQC3VuHHjMt/XqVNHksr8IV2SGjRoUKbQSNK2bdu0adMmxcTElPlq3bq1JCk9PV2SdNNNN6lv3766++67FRcXp5tvvllff/31aUvUufLs2rVLktSmTZtyr23btq3r8dPZtWuXbDabaxtbqdO91+lER0crISFBX3/9teva9OnT5ePjo+uuu8517eWXX9bRo0fVunVrdezYUU8++aR+//33Cn3G559/rl69eunQoUPavn27tm/frq5du6qgoEAzZsxwPS8lJUVt2rSRj8+Zd8unpKSofv36ioyMrNBnV1SzZs3KXTt8+LBGjx6tuLg4BQYGKiYmxvW8rKwsSVJGRoays7PVoUOHs75/RESEhg0bpi+++MJ1bdq0aWrQoIGrlANAbcU9TgBQS9nt9tNeN0vuXSl16opCKafTqY4dO2r8+PGnfY9GjRq5Xrto0SLNnz9fP/30k2bOnKnp06crPj5es2fPLpOhonmscvPNN2vUqFFat26dunTpoq+//loJCQmKjo52Pad///5KSUnR999/r9mzZ+vjjz/WhAkTNHHiRN19991nfO9t27Zp1apVkqRWrVqVe3zatGm69957q/TnOdPKk8PhOONrTvfPwo033qhff/1VTz75pLp06aKQkBA5nU5dfvnl53UO1YgRIzRjxgz9+uuv6tixo3744Qc98MADstn4b7UAajeKEwB4oRYtWmj9+vVKSEg459Yvm82mhIQEJSQkaPz48XrllVf07LPPav78+ZUatd2kSRNJxZPs/rj6kJyc7Hr8TK91Op2u1ZpTX1dR11xzje677z7Xdr2tW7fqmWeeKfe8yMhIjRo1SqNGjdLx48fVv39/vfjii2ctTtOmTZOvr68+++yzcgVyyZIleuedd7R79241btxYLVq00IoVK1RYWChfX9/Tvl+LFi00a9YsHT58+IyrTqUrekePHi1z/Wwrd3905MgRJSYm6qWXXtILL7zguv7HrYoxMTEKCwvTxo0bz/mel19+uWJiYjRt2jT17t1bubm5uv322yucCQDcFf/5BwC80I033qh9+/bpo48+KvfYiRMnlJOTI6l4G9cfdenSRZLKjS0/lx49eig2NlYTJ04s89pffvlFSUlJZ52Qd8UVV0iS3nnnnTLX33rrrQp/fkREhIYOHaqvv/5aX331lfz8/HTNNdeUec4fR3CHhISoZcuW5/xZp02bpksvvVQ33XST/vKXv5T5evLJJyXJNYr7+uuvV2ZmpmsE+qlKV+euv/56maZ52hHqpc8JCwtTdHS0Fi1aVObx999//6xZT1Va8v64KvjH36vNZtM111yjH3/80TUO/XSZJMnHx0fDhw/X119/ralTp6pjx47q1KlThTMBgLtixQkAvNDtt9+ur7/+Wn/96181f/589e3bVw6HQ1u2bNHXX3+tWbNmqUePHnr55Ze1aNEiXXnllWrSpInS09P1/vvvq2HDhq5zgCrK19dXr732mkaNGqUBAwZo+PDhrnHkTZs2LTfC+lRdunTR8OHD9f777ysrK0uXXHKJEhMTT3tO1NncdNNNuu222/T+++9r6NCh5caft2/fXpdddpm6d++uyMhIrV69Wt98840eeuihM77nihUrtH379jM+p0GDBurWrZumTZumv/3tbxoxYoQ+/fRTjRkzRitXrtSll16qnJwczZ07Vw888ICuvvpqDRw4ULfffrveeecdbdu2zbVtbvHixRo4cKDrs+6++269+uqruvvuu9WjRw8tWrRIW7durfDvIywsTP3799frr7+uwsJCNWjQQLNnz9aOHTvKPfeVV17R7NmzNWDAANcI+wMHDmjGjBlasmRJmd/liBEj9M4772j+/Pl67bXXKpwHANwZxQkAvJDNZtN3332nCRMm6NNPP9V///tfBQUFqXnz5ho9erRrSMRVV12lnTt3avLkycrMzFR0dLQGDBigl156SeHh4ZX+3DvuuENBQUF69dVX9be//U3BwcG69tpr9dprr531DCdJmjx5smsL2Hfffaf4+Hj99NNPrvuxKuKqq65SYGCgjh07VmaaXqlHHnlEP/zwg2bPnq38/Hw1adJE//jHP1yrRqdTOkFu2LBhZ3zOsGHD9OKLL+r3339Xp06d9PPPP+uf//ynvvjiC/3nP/9xHbTbsWNH12umTJmiTp06adKkSXryyScVHh6uHj166JJLLnE954UXXlBGRoa++eYbff3117riiiv0yy+/KDY2tsK/ky+++EIPP/yw3nvvPZmmqSFDhuiXX35R/fr1yzyvQYMGWrFihZ5//nlNmzZN2dnZatCgga644goFBQWVeW737t110UUXKSkpSbfeemuFswCAOzNMd7lrFwAAeIyuXbsqMjJSiYmJVkcBgCrBPU4AAKBKrV69WuvWrdOIESOsjgIAVYYVJwAAUCU2btyoNWvW6M0331RmZqZSU1PLHHYMALUZK04AAKBKfPPNNxo1apQKCwv15ZdfUpoAeBRWnAAAAADgHFhxAgAAAIBzoDgBAAAAwDl43TlOTqdT+/fvV2hoqAzDsDoOAAAAAIuYpqljx46pfv36stnOvqbkdcVp//79lTosEQAAAIBn27Nnjxo2bHjW53hdcQoNDZVU/MsJCwuzOA0AAAAAq2RnZ6tRo0aujnA2XlecSrfnhYWFUZwAAAAAVOgWHoZDAAAAAMA5UJwAAAAA4BwoTgAAAABwDhQnAAAAADgHihMAAAAAnAPFCQAAAADOgeLkRg4dOqTY2Fjt3Lmzwq+57LLL9Oijj1ZbpjNp2rSp3nrrrQt6jzvuuEPXXHPNWZ9j1c8HAAAAnIri5Eb++c9/6uqrr1bTpk314osvyjCMs37h9EzT1AsvvKB69eopMDBQgwYN0rZt2875uvfee09NmzZVQECAevfurZUrV5Z5PC8vTw8++KCioqIUEhKi66+/Xmlpaa7H169fr+HDh6tRo0YKDAxUu3bt9Pbbb5d5jwULFpz27+XBgwer5ocHAABAtaA4uYnc3FxNmjRJd911lyTpiSee0IEDB1xfDRs21Msvv1zm2vkqLCysqthu6fXXX9c777yjiRMnasWKFQoODtbQoUOVl5d3xtdMnz5dY8aM0dixY7V27Vp17txZQ4cOVXp6uus5jz32mH788UfNmDFDCxcu1P79+3Xddde5Hl+zZo1iY2P1+eefa9OmTXr22Wf1zDPP6N133y33ecnJyWX+XsbGxlbtLwEAAABViuLkJn7++Wf5+/vr4osvliSFhISobt26ri+73a7Q0NAy10o5nU499dRTioyMVN26dfXiiy+WeW/DMPT//t//01VXXaXg4GD985//lCR9//336tatmwICAtS8eXO99NJLKioqklS8avPiiy+qcePG8vf3V/369fXII4+Ued/c3FzdeeedCg0NVePGjfXhhx+WeXzDhg2Kj49XYGCgoqKidO+99+r48eNn/B3k5ORoxIgRCgkJUb169fTmm29W+vdomqbeeustPffcc7r66qvVqVMnffrpp9q/f7++++67M75u/PjxuueeezRq1Ci1b99eEydOVFBQkCZPnixJysrK0qRJkzR+/HjFx8ere/fumjJlin799VctX75cknTnnXfq7bff1oABA9S8eXPddtttGjVqlL799ttynxcbG1vm76XNxv8pAgAAuDP+tOYmFi9erO7du5/Xaz/55BMFBwdrxYoVev311/Xyyy9rzpw5ZZ7z4osv6tprr9WGDRt05513avHixRoxYoRGjx6tzZs364MPPtDUqVNdpeo///mPJkyYoA8++EDbtm3Td999p44dO5Z5zzfffFM9evTQb7/9pgceeED333+/kpOTJRWXoKFDh6pOnTpatWqVZsyYoblz5+qhhx4648/x5JNPauHChfr+++81e/ZsLViwQGvXri33czRt2vSM77Fjxw4dPHhQgwYNcl0LDw9X7969tWzZstO+pqCgQGvWrCnzGpvNpkGDBrles2bNGhUWFpZ5Ttu2bdW4ceMzvq9UXLgiIyPLXe/SpYvq1aunwYMHa+nSpWd8PQAAANyDj9UBUGzXrl2qX7/+eb22U6dOGjt2rCSpVatWevfdd5WYmKjBgwe7nnPLLbdo1KhRru/vvPNOPf300xo5cqQkqXnz5vq///s/PfXUUxo7dqx2796tunXratCgQfL19VXjxo3Vq1evMp/7pz/9SQ888IAk6W9/+5smTJig+fPnq02bNvriiy+Ul5enTz/9VMHBwZKkd999V8OGDdNrr72muLi4Mu91/PhxTZo0SZ9//rkSEhIkFRfChg0blnledHS0WrRoccbfRem9Qn98/7i4uDPeR5SZmSmHw3Ha12zZssX1vn5+foqIiKjw+/7666+aPn26fvrpJ9e1evXqaeLEierRo4fy8/P18ccf67LLLtOKFSvUrVu3M/5cAAAAsJblK07nuiH/j9566y21adNGgYGBatSokR577LGz3rtSW5w4cUIBAQHn9dpOnTqV+b5evXpl7s2RpB49epT5fv369Xr55ZcVEhLi+rrnnnt04MAB5ebm6oYbbtCJEyfUvHlz3XPPPfrvf//r2sZ3us81DEN169Z1fW5SUpI6d+7sKk2S1LdvXzmdTteq1KlSUlJUUFCg3r17u65FRkaqTZs2ZZ730EMPKTExsSK/Fktt3LhRV199tcaOHashQ4a4rrdp00b33XefunfvrksuuUSTJ0/WJZdcogkTJliYFgAAAOdiaXGqyA35p/riiy/09NNPa+zYsUpKStKkSZM0ffp0/f3vf6/h5FUvOjpaR44cOa/X+vr6lvneMAw5nc4y104tMFLxCs9LL72kdevWub42bNigbdu2KSAgQI0aNVJycrLef/99BQYG6oEHHlD//v3LDJaoyOfWtNJ7v06ddlf6/an3hZ0qOjpadrv9rK+pW7euCgoKdPTo0XO+7+bNm5WQkKB7771Xzz333Dkz9+rVS9u3bz/n8wAAAGAdS4vTuW7I/6Nff/1Vffv21S233KKmTZtqyJAhGj58+DlXqWqDrl27avPmzTX2ed26dVNycrJatmxZ7qt0UEFgYKCGDRumd955RwsWLNCyZcu0YcOGCr1/u3bttH79euXk5LiuLV26VDabrdwqkiS1aNFCvr6+WrFihevakSNHtHXr1kr9XM2aNVPdunXLrEplZ2drxYoV6tOnz2lf4+fnp+7du5d5jdPpVGJious13bt3l6+vb5nnJCcna/fu3WXed9OmTRo4cKBGjhzpul/sXNatW6d69epV6ucEAABAzbKsOFXkhvw/uuSSS7RmzRpXUUpNTdXPP/+sP/3pT2f8nPz8fGVnZ5f5ckdDhw7Vpk2bznvVqbJeeOEFffrpp3rppZe0adMmJSUl6auvvnKtkEydOlWTJk3Sxo0blZqaqs8//1yBgYFq0qRJhd7/1ltvVUBAgEaOHKmNGzdq/vz5evjhh3X77beXu5dIKp4ieNddd+nJJ5/UvHnztHHjRt1xxx3lps29++67rnugTscwDD366KP6xz/+oR9++EEbNmzQiBEjVL9+/TKH7SYkJJQZEz5mzBh99NFH+uSTT5SUlKT7779fOTk5rvvCwsPDddddd2nMmDGaP3++1qxZo1GjRqlPnz6uSYgbN27UwIEDNWTIEI0ZM0YHDx7UwYMHlZGR4fqct956S99//722b9+ujRs36tFHH9W8efP04IMPVuj3CgAAAGtYNhyiIjfk/9Ett9yizMxM9evXT6ZpqqioSH/961/PulVv3Lhxeumll6o0e3Xo2LGjunXrpq+//lr33XdftX/e0KFD9b///U8vv/yyXnvtNfn6+qpt27a6++67JUkRERF69dVXNWbMGDkcDnXs2FE//vijoqKiKvT+QUFBmjVrlkaPHq2ePXsqKChI119/vcaPH3/G17zxxhs6fvy4hg0bptDQUD3++OPKysoq85zMzEylpKSc9bOfeuop5eTk6N5779XRo0fVr18/zZw5s8w9ZCkpKcrMzHR9f9NNNykjI0MvvPCCDh48qC5dumjmzJll/vmcMGGCbDabrr/+euXn52vo0KF6//33XY9/8803ysjI0Oeff67PP//cdb1JkybauXOnpOL/YPD4449r3759CgoKUqdOnTR37lwNHDjw7L9QAAAAWMowTdO04oP379+vBg0a6Ndffy2z1empp57SwoULy2zZKrVgwQLdfPPN+sc//qHevXtr+/btGj16tO655x49//zzp/2c/Px85efnu77Pzs5Wo0aNlJWVpbCwsKr/wS7ATz/9pCeffFIbN27kXB8AAACgmmVnZys8PLxC3cCyFaeK3JD/R88//7xuv/1216pIx44dXSsLzz777GnLhr+/v/z9/av+B6gGV155pbZt26Z9+/apUaNGVscBAAAAUMKyZY2K3JD/R7m5ueXKkd1ulyRZtHBW5R599FFKEwAAAOBmLD0Ad8yYMRo5cqR69OihXr166a233ipzQ/6IESPUoEEDjRs3TpI0bNgwjR8/Xl27dnVt1Xv++ec1bNgwV4ECAAAAgKpmaXE61w35u3fvLrPC9Nxzz8kwDD333HPat2+fYmJiNGzYsAqPfQZqs5kzZ+rpp5/W2rVruQcOAACghln+p6+HHnpIu3btUn5+vlasWKHevXu7HluwYIGmTp3q+t7Hx0djx47V9u3bdeLECe3evVvvvfeeIiIiaj64hcaNGye73a433njD6ihuZcGCBerWrZv8/f3VsmXLMv/snMmsWbN08cUXKzQ0VDExMbr++utdE/AkacmSJerbt6+ioqIUGBiotm3basKECWXeo2nTpjIMo9zXqSPGU1JSdO211yomJkZhYWG68cYby9zft2DBgtO+h2EYWrVqlSTp8ssvl6+vr6ZNm3ZhvygAAABUmuXFCZU3efJkPfXUU2c8KLgmFRQUWB1BkrRjxw5deeWVGjhwoNatW6dHH31Ud999t2bNmnXW11x99dWKj4/XunXrNGvWLGVmZuq6665zPSc4OFgPPfSQFi1apKSkJD333HN67rnn9OGHH7qes2rVKh04cMD1NWfOHEnSDTfcIEnKycnRkCFDZBiG5s2bp6VLl6qgoEDDhg2T0+mUVHxG2anvceDAAd19991q1qyZevTo4fqsO+64Q++8806V/u4AAABQAaaXycrKMiWZWVlZVkc5LwsWLDAbNGhgFhQUmPXr1zeXLl1a5nGHw2G+9tprZosWLUw/Pz+zUaNG5j/+8Q/X43v27DFvvvlms06dOmZQUJDZvXt3c/ny5aZpmubIkSPNq6++usz7jR492hwwYIDr+wEDBpgPPvigOXr0aDMqKsq87LLLTNM0zTfffNPs0KGDGRQUZDZs2NC8//77zWPHjpV5ryVLlpgDBgwwAwMDzYiICHPIkCHm4cOHzU8++cSMjIw08/Lyyjz/6quvNm+77bYK/V6eeuop86KLLipz7aabbjKHDh16xtfMmDHD9PHxMR0Oh+vaDz/8YBqGYRYUFJzxdddee+1Zc40ePdps0aKF6XQ6TdM0zVmzZpk2m63MP3NHjx41DcMw58yZc9r3KCgoMGNiYsyXX365zPVdu3aZkszt27ef8fMBAABQMZXpBqw41TKTJk3S8OHD5evrq+HDh2vSpEllHn/mmWf06quv6vnnn9fmzZv1xRdfuO4ZO378uAYMGKB9+/bphx9+0Pr16/XUU0+5Vj0q6pNPPpGfn5+WLl2qiRMnSpJsNpveeecdbdq0SZ988onmzZunp556yvWadevWKSEhQe3bt9eyZcu0ZMkSDRs2TA6HQzfccIMcDod++OEH1/PT09P1008/6c4779TOnTtlGIYWLFhwxkzLli3ToEGDylwbOnSoli1bdsbXdO/eXTabTVOmTJHD4VBWVpY+++wzDRo0SL6+vqd9zW+//aZff/1VAwYMOO3jBQUF+vzzz3XnnXfKMAxJxWeJGYZRZix+QECAbDablixZctr3+eGHH3To0CHXoJRSjRs3VlxcnBYvXnzGnwsAAADVoAaKnFupzStOWVlZZmBgoLlu3TrTNE3zt99+M0NCQlwrO9nZ2aa/v7/50Ucfnfb1H3zwgRkaGmoeOnTotI9XdMWpa9eu58w6Y8YMMyoqyvX98OHDzb59+57x+ffff795xRVXuL5/8803zebNm5tOp9Pcu3ev2aZNG3PFihVnfH2rVq3MV155pcy1n376yZRk5ubmnvF1CxYsMGNjY0273W5KMvv06WMeOXKk3PMaNGhg+vn5mTabrdwq0KmmT59u2u12c9++fa5r6enpZlhYmDl69GgzJyfHPH78uPnQQw+Zksx77733tO9zxRVXlPl9nKpr167miy++eMYMAAAAqBhWnGoLh0NasED68svivzocZ336l19+qRYtWqhz586SpC5duqhJkyaaPn26JCkpKUn5+flKSEg47evXrVunrl27KjIy8oJid+/evdy1uXPnKiEhQQ0aNFBoaKhuv/12HTp0SLm5ua7PPlMuSbrnnns0e/Zs7du3T5I0depU3XHHHTIMQw0aNNCWLVvUq1evC8r9RwcPHtQ999yjkSNHatWqVVq4cKH8/Pz0l7/8pdy5YIsXL9bq1as1ceJEvfXWW/ryyy9P+56TJk3SFVdcofr167uuxcTEaMaMGfrxxx8VEhKi8PBwHT16VN26dTvtdLy9e/dq1qxZuuuuu077GYGBga7fKwAAAGqGpePIvdq330qjR0t795681rCh9Pbb0inDCU41adIkbdq0ST4+J/+2OZ1OTZ48WXfddZcCAwPP+pHnetxms5UrDIWFheWeFxwcXOb7nTt36s9//rPuv/9+/fOf/1RkZKSWLFmiu+66SwUFBQoKCjrnZ3ft2lWdO3fWp59+qiFDhmjTpk366aefzvqaU9WtW7fMlDpJSktLU1hY2Bk/+7333lN4eLhef/1117XPP/9cjRo10ooVK3TxxRe7rjdr1kyS1LFjR6WlpenFF1/U8OHDy7zfrl27NHfuXH377bflPmvIkCFKSUlRZmamfHx8FBERobp166p58+blnjtlyhRFRUXpqquuOm3uw4cPKyYm5gy/CQAAAFQHVpys8O230l/+UrY0SdK+fcXXT/MH7w0bNmj16tVasGCB1q1b5/pasGCBli1bpi1btqhVq1YKDAxUYmLiaT+2U6dOWrdunQ4fPnzax2NiYnTgwIEy19atW3fOH2fNmjVyOp168803dfHFF6t169bav39/uc8+U65Sd999t6ZOnaopU6Zo0KBBatSo0Tk/u1SfPn3Kvf+cOXPUp0+fM74mNze33IpP6UHKZ7vvy+l0Kj8/v9z1KVOmKDY2VldeeeUZXxsdHa2IiAjNmzdP6enp5cqRaZqaMmWKRowYcdr7rPLy8pSSkqKuXbue8TMAAABQDap736C7sfwep6Ii02zY0DSl0345DcM8Ube+uWTLQXPp9gxzeUqmuXLHIXP4qPvMDl27m+v3HDE37D1qbtqXZSYdyDK3Hsw2O3XtYd7z4GhzZ+Zx87G/PWuGR9Qx3/5/H5srfttk/pK40Hz7vYnm0ZwCMyPruNmqVWuzb79+5rwFC80tW7eZX389wzWZb+bMmaZhGOYnn3xibt261XzhhRfMsLCwcvc4jR49usyPtG7dOlOS+dZbb5kpKSnmp59+ajZo0MCU5LpfKDk52fTz8zPvv/9+c/369WZSUpL5/vvvmxkZGa73OXr0qBkUFGT6+fmZX331let6Re5xSk1NNYOCgswnn3zSTEpKMt977z3TbrebM2fOdD3n3//+txkfH+/6PjEx0TQMw3zppZfMrVu3mmvWrDGHDh1qNmnSxHVf1Lvvvmv+8MMP5tatW82tW7eaH3/8sRkaGmo+++yzZT7f4XCYjRs3Nv/2t7+dNt/kyZPNZcuWmdu3bzc/++wzMzIy0hwzZky5582dO9eUZCYlJZ32febPn2+GhISYOTk5Z/xdAAAAoGIq0w3YqlfTFi8uv9IkaaqkUSpecQg4uF//fmmyljfuJEkyHYXa+9WXCut9va56d2m512aFd9DGKZ9oVuBAydZbRsfdGvO3v8tx/LDsIXUU2uUKjd/dUJJUlPC0fpv3sRKGXCGZDvlGNVbk4L8q8McjshmG6vQdrjsfeFRmUYHqdBki37aXafWunerxjzkyDEPJu48ouXCPVr82T3abIZthyGZIra56UH974f805sm/KapFZzWIv0P7Pvunbvt4uQJDwmQYhvo9PEEzvpuoDz6aJB8/f8U0v0i/mm0UGBImm2HIbjPUqNtA7Vq3REsKm2nl1+sVEeQre06GkpOTtWrbAUU3O67YsACF+Jf9R7dZs2b66aef9Nhjj+ntt99Ww4YN9fHHH2vo0KGu52RmZiolJcX1fXx8vL744gu9/vrrev311xUUFKQ+ffpo5syZru19TqdTzzzzjHbs2CEfHx+1aNFCr732mu67774ynz937lzt3r1bd95552n/ticnJ+uZZ57R4cOH1bRpUz377LN67LHHyj1v0qRJuuSSS9S2bdvTvs+XX36pW2+9VUFBQad9HAAAANXDMM0/3NTi4bKzsxUeHq6srCyFhYXVfIAvv5RuuaXc5bGSFkpaUPL9q7c/r8QuCXKappym5DRNOZymTFNyOM2S68WPub53lnxvmjJLnu+sZX930776u3yjmyhy0H1nfV6wn11xYQGKDfNXXFhA8f8O9S/z17iwAAX62WsoefXLzMxUmzZttHr1atc9VwAAADh/lekGrDjVtHr1Tnv5F0nvnvL903fG6+nLTn9WUGWYZknZKi1azpISZpoynadeP1m6nM6ypcwseX7pa52nlLLS1zrM05Q656klTqeUvVO+L3mf7Kyj2rx2md7ds1HPvTJesQ2bqchp6mhugdKy85SWna+0Y3lKz87X8fwi5RQ4lJqZo9TMnLP+/KEBPiUlyl9xoQGKLVOsiv8aE+qvAF/3L1g7d+7U+++/T2kCAACwACtONc3hkJo2LR4EcbpfvWEUT9fbsUOyu/8f5qtK06ZNdeTIET3//PN64oknzvrc4/lFSi8pU+klZSotO09px4r/WvrYicKzj3c/VUSQb0mx8lds6MlSFRfmr9iS1auYEH/5+TBPBQAAwFOw4uTO7PbikeN/+UtxSTq1PBlG8V/fesurSpNUvJpSUSH+PgqJCVHzmJAzPsc0TR3PLyouV9l5SjtWsmqVfbJopZcUrfwip47mFupobqGS046d9bMjg/3KrVjFhgUoLrS0YPkrOsRfvnYKFgAAgCdhxckqpzvHqVGj4tJ0hnOcUPVM01T2iaKSYnVquTpZrEpXtgodFfs/FcOQooL9y65alaxmxYUGuK5FhfjLbjOq+ScEAADAmVSmG1CcrORwFE/ZO3Cg+N6nSy/1upWm2sI0TR3JLSwpUsWlKv2UopVW8n36sXw5KjiRw2ZIMa6BFqcWK/8ygy8ig/xko2ABAABUOYrTWbhVcYLHcTpNHcopKHvvlWuwxcnVq4xj+RWeeOhjMxRTuhXwlG2CreJCdWmraAX5seMWAADgfHCPE2ARW0nJiQn110X1z/w8h9PUoeP5p6xY5bnuxzp1i+ChnHwVOU0dyMrTgay8cu8T4GtT/1YxurxDXSW0jVN4kG81/nQAAADeixUnwI0VOpzKPKVglW4RPJCVp+Wph7T3yAnXc31shi5uHqWhHepqaPs4xYYFWJgcAADA/bFV7ywoTvAUpmlq84Fszdp4ULM2pZWbCNitcYSGXlRXQy+qq6bRwRalBAAAcF8Up7OgOMFT7cjM0axNBzVr00H9tvtomcfa1g3VkIvqauhFcWpfL0yGwbAJAAAAitNZUJzgDQ5m5WnO5uKVqGWph8pM+msUGaih7etqaIe66ta4DiPRAQCA16I4nQXFCd7maG6BEpPSNWvTQS3cmqH8IqfrsegQfw1uH6fLO9RVn+ZR8vPh4F4AAOA9KE5nQXGCN8stKNKirRmaufGgErek61hekeux0AAfxbeN1eUX1dWANjGMOQcAAB6P4nQWFCegWEGRU8tTD2nmpoOavSlNmcfzXY/5+9h0acmY80HtYhUR5GdhUgAAgOpBcToLihNQnsNp6rfdR0qGS6Rp9+Fc12N2m6HezSJ1eYe6GtK+ruqGM+YcAAB4BorTWVCcgLMzTVNJB465JvRtOVh2zHnnRhG6vGRCX/OYEItSAgAAXDiK01lQnIDK2XUox7UStWbXkTKPtY4LcZ0VdVF9xpwDAIDaheJ0FhQn4PylZ+dp9uY0zdp0UMtSDqnolDHnDSICS0pUnHo0jWTMOQAAcHsUp7OgOAFVIyu3UPOS0zRzY/GY87zCk2POo4L9NLh9nIZ2qKtLWkTJ38duYVIAAIDTozidBcUJqHonChxauDVDszcd1NykNGWfMuY8xN9HA0vGnF/WJkbB/ow5BwAA7oHidBYUJ6B6FTqcWpF6WDM3HdDsTWlKP3ZyzLmfj02XtozW0A51NahdnCKDGXMOAACsQ3E6C4oTUHOcTlO/7Tmq2SUT+nYeOjnm3GZIvZtFaehFcRpyUV3Vjwi0MCkAAPBGFKezoDgB1jBNU8lpxzRrY/Fwic0Hsss83rlhuIaUTOhrGcuYcwAAUP0oTmdBcQLcw+5DuZq9uXglavWuIzr130QtY0M09KI4Db2orjo2CGfMOQAAqBYUp7OgOAHuJ/1YnuZuTtfMTQe1LCVThY6yY84Ht4/T5R3qqidjzgEAQBWiOJ0FxQlwb1knCrUgOV0zNx7UguQMnSh0uB6LDPbToHaxurxDXV3SIloBvow5BwAA54/idBYUJ6D2yCt0aNHWDM3alKbELWk6mlvoeizYz67LSsacD2wbqxDGnAMAgEqiOJ0FxQmonQodTq3ccVizNh3U7E1pOpid53rMz25Tv1bRGnpRnAa1i1NUiL+FSQEAQG1BcToLihNQ+zmdptbvPapZm4on9O3IzHE9ZjOkvi2j9e4t3RQe6GthSgAA4O4oTmdBcQI8i2ma2pZ+XLM2HtTMTQe1aX/xmPN/XttBt/ZuYnE6AADgzirTDWw1lAkAqoVhGGodF6qHE1rpp0cu1ZjBrSVJ85LSLU4GAAA8CcUJgEcZ3D5OkrRke6ZOFDjO8WwAAICKoTgB8Cht64aqfniA8ouc+jUl0+o4AADAQ1CcAHgUwzCU0K541SlxC9v1AABA1aA4AfA48e1iJRXf5+Rl828AAEA1oTgB8Dh9mkcp0Neug9l5ril7AAAAF4LiBMDjBPja1a9VtCQpkel6AACgClCcAHikQaXb9bakWZwEAAB4AooTAI80sE1xcVq/N0vpx/IsTgMAAGo7ihMAjxQbFqDODcMlSfOZrgcAAC4QxQmAx4pvWzKWnPucAADABaI4AfBYCSX3OS3elqm8QofFaQAAQG1GcQLgsS6qH6a4MH+dKHRoeeohq+MAAIBajOIEwGMZhsF2PQAAUCUoTgA82smx5OkyTdPiNAAAoLaiOAHwaJe0iJa/j037jp7QloPHrI4DAABqKYoTAI8W6GdXv5bRkopXnQAAAM4HxQmAx4sv2a6XmJRmcRIAAFBbUZwAeLz4tsXF6bc9R5V5PN/iNAAAoDaiOAHwePXCA3VR/TCZprQgOcPqOAAAoBaiOAHwCglt2a4HAADOH8UJgFdIaFd8ntOirRkqKHJanAYAANQ2FCcAXqFjg3DFhPorp8ChFTsOWR0HAADUMhQnAF7BZjMU36Z0ux5jyQEAQOVQnAB4DddY8i1pMk3T4jQAAKA2oTgB8Br9WkbLz27TnsMntD39uNVxAABALUJxAuA1gv191KdFlCQpcQvb9QAAQMVRnAB4lYR2jCUHAACVR3EC4FXiS85zWrPriI7kFFicBgAA1BYUJwBepWGdILWtGyqnKS3YynY9AABQMRQnAF7n5HY9ihMAAKgYihMArxPfNk6StHBrhgodTovTAACA2oDiBMDrdGkUochgPx3LK9KqnYetjgMAAGoBihMAr2O3GRrYpni73jy26wEAgAqgOAHwSq77nDjPCQAAVADFCYBXurRVtHzthnZk5ig147jVcQAAgJujOAHwSqEBvurdLEoS0/UAAMC5UZwAeK2T2/XSLE4CAADcHcUJgNeKb1tcnFbtPKKsE4UWpwEAAO6M4gTAazWJClbL2BA5nKYWbs2wOg4AAHBjFCcAXq10u968JLbrAQCAM6M4AfBqCW3jJEnzkzNU5HBanAYAALgrihMAr9atcYQignyVdaJQa3cftToOAABwUxQnAF7Nx27TZa1jJEmJbNcDAABnQHEC4PUS2hVv10vcwnlOAADg9ChOALxe/9YxstsMbU8/rl2HcqyOAwAA3BDFCYDXCw/0Vc+mdSRJiUmsOgEAgPIoTgAgaVDJdr15bNcDAACnQXECAEnxbYvPc1qx45CO5RVanAYAALgbihMASGoeE6Lm0cEqdJhavC3T6jgAAMDNUJwAoETpqtNcxpIDAIA/oDgBQInSseQLkjPkcJoWpwEAAO6E4gQAJXo0raPQAB8dzinQuj1HrY4DAADcCMUJAEr42m0a0DpGkpTIdj0AAHAKihMAnIKx5AAA4HQoTgBwigGtY2QzpC0Hj2nvkVyr4wAAADdBcQKAU9QJ9lOPJpGSWHUCAAAnUZwA4A/i25WOJac4AQCAYhQnAPiDQSXFaXnKIeXkF1mcBgAAuAOKEwD8QYuYEDWODFKBw6kl2zOtjgMAANwAxQkA/sAwDCWUrDoxlhwAAEgUJwA4rYS2pWPJM+R0mhanAQAAVqM4AcBp9GoWqRB/H2Uez9fv+7KsjgMAACxGcQKA0/Dzsal/62hJ0jy26wEA4PUoTgBwBvEl2/UYSw4AAChOAHAGA9vEyDCkzQeydSDrhNVxAACAhShOAHAGUSH+6tooQpI0bwurTgAAeDOKEwCcRUK74u16iWzXAwDAq1GcAOAsSs9zWro9UycKHBanAQAAVqE4AcBZtIkLVYOIQOUXObV0e6bVcQAAgEUoTgBwFoZhuFadErnPCQAAr0VxAoBziG9bXJzmbUmTaZoWpwEAAFagOAHAOVzcPEpBfnalZedr0/5sq+MAAAALUJwA4BwCfO3q1zJakjQ3Kc3iNAAAwAoUJwCogEElY8k5zwkAAO9EcQKACrisbYwk6fe9WUrPzrM4DQAAqGkUJwCogNjQAHVuGC6JVScAALwRxQkAKiihZLseY8kBAPA+FCcAqKDSseRLtmUqr9BhcRoAAFCTKE4AUEEX1Q9T3bAAnSh0aFnqIavjAACAGkRxAoAKMgxD8e2KV50SGUsOAIBXoTgBQCUMKilO85LSZZqmxWkAAEBNoTgBQCVc0iJaAb427c/K05aDx6yOAwAAagjFCQAqIcDXrr4toiWxXQ8AAG9CcQKASmIsOQAA3ofiBACVVDqWfN2eo8o8nm9xGgAAUBMoTgBQSXXDA9ShQZhMU5rPqhMAAF6B4gQA5yG+bcl2vSSKEwAA3oDiBADnoXQs+eJtGcovclicBgAAVDeKEwCchw71wxUT6q+cAodW7jhsdRwAAFDNKE4AcB5sNkPxbYpXndiuBwCA56M4AcB5SijZrpe4JU2maVqcBgAAVCeKEwCcp36touXnY9Oewye0Lf241XEAAEA1ojgBwHkK8vPRJS2iJLFdDwAAT0dxAoALkNC29D6nNIuTAACA6kRxAoALEN+u+DyntbuP6HBOgcVpAABAdaE4AcAFaBARqLZ1Q+U0pYVb2a4HAICnojgBwAUqna43l/ucAADwWBQnALhACSXb9RYlZ6jQ4bQ4DQAAqA4UJwC4QJ0bRigq2E/H8ou0asdhq+MAAIBqQHECgAtktxkaWDpdbwvb9QAA8EQUJwCoAqeOJTdN0+I0AACgqlGcAKAKXNo6Rr52QzsP5So1M8fqOAAAoIpRnACgCoT4++ji5lGSpHlM1wMAwONQnACgisS3LR1LnmZxEgAAUNUoTgBQRRLaFo8lX73riLJyCy1OAwAAqhLFCQCqSOOoILWKDZHDaWrBVrbrAQDgSShOAFCFSg/DncdYcgAAPArFCQCqUEK74vucFiRnqMjhtDgNAACoKhQnAKhC3RrXUUSQr7JOFGrNriNWxwEAAFWE4gQAVchuMzSwTfGqE9v1AADwHBQnAKhipdv1GEsOAIDnoDgBQBW7tFWMfGyGUjJytDMzx+o4AACgClCcAKCKhQf6qmfTSElSItv1AADwCBQnAKgGpdv15m1hux4AAJ6A4gQA1aD0PKcVqYeVnVdocRoAAHChKE4AUA2aRQereUywipymFm/NtDoOAAC4QBQnAKgmCW2Lt+slsl0PAIBaj+IEANWkdLveguQMOZymxWkAAMCFoDgBQDXp3qSOwgJ8dDinQOv2HLE6DgAAuAAUJwCoJr52mwa0KT0Ml7HkAADUZhQnAKhGg0rHklOcAACo1ShOAFCNBrSOkd1mKDntmPYczrU6DgAAOE8UJwCoRhFBfurepI4kad4WVp0AAKitKE4AUM1OjiWnOAEAUFtRnACgmpWOJV+eckjH84ssTgMAAM4HxQkAqlmLmGA1iQpSgcOpJdsyrY4DAADOA8UJAKqZYRiKL92ul5RmcRoAAHA+3KI4vffee2ratKkCAgLUu3dvrVy58ozPveyyy2QYRrmvK6+8sgYTA0DlDCrZrjc/OV1Op2lxGgAAUFmWF6fp06drzJgxGjt2rNauXavOnTtr6NChSk8//U3U3377rQ4cOOD62rhxo+x2u2644YYaTg4AFdezaaRC/X2UebxA6/cetToOAACoJMuL0/jx43XPPfdo1KhRat++vSZOnKigoCBNnjz5tM+PjIxU3bp1XV9z5sxRUFAQxQmAW/Pzsal/6xhJjCUHAKA2srQ4FRQUaM2aNRo0aJDrms1m06BBg7Rs2bIKvcekSZN08803Kzg4+LSP5+fnKzs7u8wXAFih9D6nuUkUJwAAahtLi1NmZqYcDofi4uLKXI+Li9PBgwfP+fqVK1dq48aNuvvuu8/4nHHjxik8PNz11ahRowvODQDnY2DbWBmGlHQgW/uPnrA6DgAAqATLt+pdiEmTJqljx47q1avXGZ/zzDPPKCsry/W1Z8+eGkwIACdFBvupW+M6ktiuBwBAbWNpcYqOjpbdbldaWtnxvGlpaapbt+5ZX5uTk6OvvvpKd91111mf5+/vr7CwsDJfAGAVxpIDAFA7WVqc/Pz81L17dyUmJrquOZ1OJSYmqk+fPmd97YwZM5Sfn6/bbrutumMCQJUpHUu+NOWQcguKLE4DAAAqyvKtemPGjNFHH32kTz75RElJSbr//vuVk5OjUaNGSZJGjBihZ555ptzrJk2apGuuuUZRUVE1HRkAzlvruBA1iAhUQZFTS7cfsjoOAACoIB+rA9x0003KyMjQCy+8oIMHD6pLly6aOXOma2DE7t27ZbOV7XfJyclasmSJZs+ebUVkADhvhmFoULtYfbJsl+ZtSdPg9nHnfhEAALCcYZqmVx1hn52drfDwcGVlZXG/EwBLLNyaoZGTVyo21F/Ln0mQzWZYHQkAAK9UmW5g+VY9APA2FzePVJCfXenH8rVpP2fLAQBQG1CcAKCG+fvYdWmraElS4ham6wEAUBtQnADAAglti+9tSkziPCcAAGoDihMAWGBgyXlOG/ZlKS07z+I0AADgXChOAGCBmFB/dW4UIUmat4VVJwAA3B3FCQAsMqhk1YntegAAuD+KEwBYJL5dcXFasj1DeYUOi9MAAICzoTgBgEXa1wtTvfAA5RU6tSzlkNVxAADAWVCcAMAihmEovnS7HmPJAQBwaxQnALBQQsl2vXlJ6TJN0+I0AADgTChOAGChS1pEK8DXpv1ZeUo6cMzqOAAA4AwoTgBgoQBfu/q1jJYkJSaxXQ8AAHdFcQIAiyW0i5MkJXKeEwAAboviBAAWKx0QsX7vUWUcy7c4DQAAOB2KEwBYLC4sQB0bhMs0pfnJrDoBAOCOKE4A4AZKV53mJVGcAABwRxQnAHADpWPJF2/LUH6Rw+I0AADgjyhOAOAGOtQPV2yov3IKHFqRetjqOAAA4A8oTgDgBmw2w7Vdj7HkAAC4H4oTALiJU8eSm6ZpcRoAAHAqihMAuIm+LaPk52PT3iMntDXtuNVxAADAKShOAOAmgvx81LdFlCQpcQvb9QAAcCcUJwBwI/El2/UYSw4AgHuhOAGAGykdELF29xEdzimwOA0AAChFcQIAN9IgIlDt6oXJaUoLkll1AgDAXVCcAMDNJLjGklOcAABwFxQnAHAzCe2Ki9OirRkqKHJanAYAAEgUJwBwO50bRig6xE/H8ou0audhq+MAAABRnADA7dhshga2YbseAADuhOIEAG6odLte4pY0maZpcRoAAEBxAgA31K9VjPzsNu06lKuUjByr4wAA4PUoTgDghkL8fdS7eaQkad6WNIvTAAAAihMAuKnSseRzuc8JAADLUZwAwE0ltIuTJK3ZdURHcwssTgMAgHejOAGAm2oUGaTWcSFyOE0t3JphdRwAALwaxQkA3FjpqhNjyQEAsBbFCQDcWOl9TguS01XkcFqcBgAA70VxAgA31rVxHdUJ8lV2XpFW7zpidRwAALwWxQkA3JjdZmhgm+JVp3lb2K4HAIBVKE4A4Obi25WOJec8JwAArEJxAgA31791jHxshlIzcrQjM8fqOAAAeCWKEwC4ubAAX/VqFilJSmTVCQAAS1CcAKAWKB1Lzn1OAABYg+IEALVA6VjylTsOKzuv0OI0AAB4H4oTANQCTaOD1SImWEVOU4u2ZlgdBwAAr0NxAoBawrVdL4ntegAA1DSKEwDUEvEl2/XmJ6fL4TQtTgMAgHehOAFALdGjSR2FBfjoSG6hftt9xOo4AAB4FYoTANQSPnabLmtTehgu2/UAAKhJFCcAqEUS2hUXp3lbOM8JAICaRHECgFrkstaxstsMbU07rj2Hc62OAwCA16A4AUAtEh7kqx5N6kiSEpNYdQIAoKZQnACglindrpe4hfucAACoKRQnAKhl4tsWn+e0IvWwjucXWZwGAADvQHECgFqmRUywmkYFqcDh1JJtGVbHAQDAK1CcAKCWMQzDterEWHIAAGoGxQkAaqFBJfc5zd+SLqfTtDgNAACej+IEALVQj6aRCvX30aGcAq3be9TqOAAAVNiLP2zShDlblXk83+oolUJxAoBayM/Hpv5tYiRJ89iuBwCoJQqKnPp02U69nbhNjlq2Y4LiBAC1VEJbxpIDAGqX3Ydz5DSlYD+7YkP9rY5TKRQnAKilLmsTK5shJR3I1r6jJ6yOAwDAOaVk5EiSmseEyDAMi9NUDsUJAGqpyGA/dWtcR5I0j1UnAEAtsCOztDgFW5yk8ihOAFCLxZdM10tMSrM4CQAA55aacVyS1Cya4gQAqEGD2hWf5/RryiHlFhRZnAYAgLNLPWWrXm1DcQKAWqxVbIga1glUQZFTS7ZlWh0HAICzcm3VY8UJAFCTDMNwrTpxnxMAwJ1l5RbqUE6BJLbqAQAsEF8ylnzelnQ5a9mZGAAA75GSWXx/U92wAAX7+1icpvIoTgBQy/VuHqlgP7vSj+Vr4/4sq+MAAHBaJ+9vqn2rTRLFCQBqPX8fuy5tFSNJSkxiux4AwD3tyKy9E/UkihMAeATXWPItjCUHALin2jxRT6I4AYBHGNgmVoYhbdyXrYNZeVbHAQCgHLbqAQAsFxPqr84NIyQxXQ8A4H6cTlM7DhUXpxbRrDgBACw0qF3pdD226wEA3Mu+oydUUOSUn92mBnUCrY5zXihOAOAh4tsWn+e0ZHum8godFqcBAOCk1JKDb5tEBcluMyxOc34oTgDgIdrVC1X98ADlFTr1a0qm1XEAAHBJzSieqFdb72+SKE4A4DEMwzg5XY+x5AAAN7KjZMWpWS29v0miOAGAR0ko2a43b0u6TNO0OA0AAMVq+0Q9ieIEAB6lT4soBfradSArT5sPZFsdBwAASSe36rWgOAEA3EGAr119W0ZLYrseAMA9nChwaH/JGYPN2aoHAHAXpWPJEznPCQDgBkrvb4oI8lWdYD+L05w/ihMAeJj4tsXFaf2eo8o4lm9xGgCAt0vNLJmoF117t+lJFCcA8DixYQHq1DBckjSfVScAgMV2uAZD1N5tehLFCQA8UumqU+KWNIuTAAC8XaprFDkrTgAAN1M6lnzxtkzlFTosTgMA8GaeMFFPojgBgEfq0CBMcWH+yi1waMWOw1bHAQB4KdM0TznDia16AAA3YxjGye16SWzXAwBYI/N4gY7lF8kwpMaRQVbHuSAUJwDwUKXb9RKT0mWapsVpAADeqHSbXsM6gQrwtVuc5sJQnADAQ/VtGS1/H5v2HT2hrWnHrY4DAPBCpYMhavPBt6UoTgDgoQL97OrbMlqSNJftegAAC5Qeftu8lg+GkChOAODRSu9zmsd5TgAAC5Ru1avth99KFCcA8GilxWnt7iM6dDzf4jQAAG/jKRP1JIoTAHi0+hGBal8vTKYpLUjOsDoOAMCLFDqc2n04VxJb9QAAtUBCu5Kx5Fu4zwkAUHP2HM5VkdNUoK9dcaEBVse5YBQnAPBwCe2Kx5Iv2pqpgiKnxWkAAN6idJtes+hg2WyGxWkuHMUJADxcpwbhig7x1/H8Iq3aedjqOAAAL5GaWTIYwgO26UkUJwDweDabofi2MZIYSw4AqDmuUeQeMFFPojgBgFeIb1u8XS8xKV2maVqcBgDgDVI8aKKeRHECAK9waato+dlt2n04VyklZ2oAAFCdTo4iZ8UJAFBLBPv76OIWUZKkJ7/5Xau51wkAUI2y8wqVWXJ+YDO26gEAapN7L20uP7tNv+0+qr9MXKZRU1Zq474sq2MBADzQjpLVpphQf4UG+FqcpmpQnADAS/RrFa0FT16m4b0ayW4zND85Q3/+9xI9OG2ttqezfQ8AUHVcE/U8ZLVJojgBgFepHxGocdd10twxA3R1l/oyDOmnDQc0ZMJCPTFjvfaUnPAOAMCFSPWwwRASxQkAvFKz6GC9fXNX/fzIpRrULk5OU/pmzV7Fv7lAL3y/UenZeVZHBADUYqkeNopcojgBgFdrVy9MH4/sof8+cIn6tYxWocPUp8t2qf8b8zXulyQdySmwOiIAoBbytIl6EsUJACCpa+M6+vzu3vrint7q1jhCeYVOfbAwVf1fn6+3527T8fwiqyMCAGoJp9PUjtJ7nNiqBwDwRJe0iNZ/7r9Ek0b2ULt6YTqWX6QJc7eq/+vz9dGiVOUVOqyOCABwcwez85RX6JSPzVDDOoFWx6kyFCcAQBmGYSihXZx+erif/j28q5pHB+twToH++XOSBrwxX58v36WCIqfVMQEAbqp0m17jqCD52j2nbnjOTwIAqFI2m6Fhnetr9mP99fr1ndQgIlBp2fl67ruNGjR+ob5du1cOp2l1TACAmzk5itxztulJFCcAwDn42G26sWcjzXtigF4c1l7RIX7afThXY75er8vfWqSZGw/INClQAIBipStOLTxoMIREcQIAVJC/j1139G2mRU8N1FOXt1FYgI+2pR/XXz9fq6vfW6qFWzMoUAAA1yjyZh40ilyiOAEAKinIz0cPXNZSi/8Wr4fjWyrIz67f92Zp5OSVuunD5Vq187DVEQEAFkrN8LyJehLFCQBwnsIDffX4kDZa9NRA3dWvmfx8bFq547BumLhMd0xZqY37sqyOCACoYXmFDu07ekKSZ53hJFGcAAAXKDrEX8//ub0WPnmZhvdqLLvN0ILkDP3530v0wLQ12p5+zOqIAIAasutQrkxTCg3wUVSwn9VxqhTFCQBQJeqFB2rcdR2VOGaArulSX4Yh/bzhoIZMWKTHv16vPYdzrY4IAKhmp27TMwzD4jRVi+IEAKhSTaOD9dbNXTVzdH8NaR8npyn9Z+1exb+5QM9/t1Hp2XlWRwQAVJPSwRAtPGwwhERxAgBUkzZ1Q/XhiB767sG+urRVtAodpj5bvkv935ivcT8n6UhOgdURAQBVrHQUuafd3yRRnAAA1axLowh9dldvfXnPxerepI7yCp36YFGqLn19vt6au1XH8gqtjggAqCKlh98287DDbyWKEwCghvRpEaVv/tpHk+/oofb1wnQ8v0hvzd2m/q/P14eLUpRX6LA6IgDgApimyYoTAABVwTAMxbeN0/8e7qd3b+mq5jHBOpJbqFd+3qIBb8zXZ8t3qaDIaXVMAMB5OJxToKwTxbsIPO3wW4niBACwgM1m6M+d6mv2o/31+l86qUFEoNKy8/X8dxuVMH6B/rNmrxxO0+qYAIBK2FEyGKJBRKACfO0Wp6l6FCcAgGV87Dbd2KOR5j0xQC9ddZGiQ/y15/AJPT5jvS5/a5F+2XBApkmBAoDawJO36UkUJwCAG/D3sWvkJU216KnL9LfL2yo80Ffb0o/r/mlrddW7S7UgOZ0CBQBuLqVkMERzD9ymJ1GcAABuJMjPR/df1kKLnhqoR+JbKtjPrg37snTHlFW66YPlWrnjsNURAQBnsKNkxckT72+SKE4AADcUHuirMUPaaNFTA3V3v2by87Fp5c7DuvGDZRo5eaU27M2yOiIA4A9KD79tHuN5o8glihMAwI1FhfjruT+318InL9MtvRvLx2Zo4dYMDXt3ie7/fI22pR2zOiIAQFKRw6ldh7jHCQAAS9ULD9Qr13ZU4uMDdG3XBjIM6ZeNBzX0rUUa8/U67Tmca3VEAPBq+46eUKHDlL+PTfXDA62OUy0oTgCAWqNJVLAm3NRFM0f319CL4uQ0pW/X7lP8mwv03HcblJadZ3VEAPBKqafc32SzGRanqR4UJwBArdOmbqg+uL2Hvn+wry5tFa1Ch6nPl+9W/9fn65Wfk3Q4p8DqiADgVVIySibqeeg2PYniBACoxTo3itBnd/XWV/derB5N6ii/yKkPF6Wq/+vzNWHOVh3LK7Q6IgB4BddgiGjPHAwhUZwAAB7g4uZRmvHXPppyR09dVD9Mx/OL9HbiNl36+nx9sDBFJwocVkcEAI/m6aPIJYoTAMBDGIahgW1j9eND/fTeLd3UIiZYR3MLNe6XLRrwxnx9tmynCoqcVscEAI+UmslWPQAAahWbzdCVnepp1qP99cZfOqlBRKDSj+Xr+e83Kf7NBfpmzV45nKbVMQHAYxzPL1Jadr4ktuoBAFDr+NhtuqFHI817YoBevvoixYT6a++RE3pixnoNfWuRft5wQE4KFABcsJ0l9zdFBfspPMjX4jTVh+IEAPBo/j52jejTVIueHKinr2iriCBfbU8/rgemrdVV7y3R/OR0mSYFCgDOlzdM1JMoTgAALxHoZ9dfB7TQoqcG6pGEVgr2s2vjvmyNmrJKN36wTCt3HLY6IgDUSqVnOHnyNj2J4gQA8DJhAb4aM7i1Fj01UPdc2kz+Pjat2nlEN36wTK/+ssXqeABQ67hGkbPiBACA54kK8dezV7bXwicH6pbejSVJHy5K0fb04xYnA4DaZUfJRD1PHkUuUZwAAF6ubniAXrm2owa1i5PTlCbM3Wp1JACoNUzTdJ3h1DyGrXoAAHi8x4e0lmFIP/1+QJv2Z1kdBwBqhbTsfOUUOGS3GWocGWR1nGpFcQIAQFK7emEa1qm+JOnN2aw6AUBFlB5826hOoPx8PLtaePZPBwBAJTw2uLXsNkPztqRrza4jVscBALeX6iXb9CSKEwAALs2ig3VD94aSpDdmbeF8JwA4h5OjyD17MIREcQIAoIyHE1rJz27T8tTDWrr9kNVxAMCtlU7UY8UJAAAv0yAi0DWe/I3Zyaw6AcBZlJ7h5OmjyCWKEwAA5Tw4sKUCfe1av+eo5mxOszoOALil/CKH9hzOlSS18PDDbyWKEwAA5cSE+mtU36aSpPFztsrpZNUJAP5o96FcOU0pxN9HMaH+VsepdhQnAABO477+LRQa4KMtB4/px9/3Wx0HANzOqdv0DMOwOE31ozgBAHAa4UG+uq9/c0nShDlbVehwWpwIANzLyVHknr9NT6I4AQBwRqP6NlNUsJ92HsrVf9bstToOALiV1IySiXrRnj9RT6I4AQBwRsH+Prr/shaSpHcStymv0GFxIgBwHztKt+qx4gQAAG67uInqhQdof1aevlix2+o4AOA2Su9x8obDb6XzKE5NmzbVyy+/rN27+X8eAADPF+Br18PxrSRJ7y/YrtyCIosTAYD1juYW6HBOgSTucTqjRx99VN9++62aN2+uwYMH66uvvlJ+fn51ZAMAwC3c0KOhmkQFKfN4gaYs3Wl1HACwXOlqU73wAAX5+VicpmacV3Fat26dVq5cqXbt2unhhx9WvXr19NBDD2nt2rXVkREAAEv52m16bFBrSdIHC1OUdaLQ4kQAYK3SiXrNvGSbnnQB9zh169ZN77zzjvbv36+xY8fq448/Vs+ePdWlSxdNnjxZpslhgQAAzzGsc321jgtRdl6RPlqUanUcALCUa6Kel2zTky6gOBUWFurrr7/WVVddpccff1w9evTQxx9/rOuvv15///vfdeutt1ZlTgAALGW3GRozuI0kafLSHco8zjZ1AN7LdYaTl4wil6RKb0hcu3atpkyZoi+//FI2m00jRozQhAkT1LZtW9dzrr32WvXs2bNKgwIAYLWhF8WpU8Nw/b43S+/PT9ELw9pbHQkALOFto8il81hx6tmzp7Zt26b/9//+n/bt26d//etfZUqTJDVr1kw333xzlYUEAMAdGIahJ4YUrzp9vmKXDmSdsDgRANQ8h9PUjkPFxakFK05nlpqaqiZNmpz1OcHBwZoyZcp5hwIAwF1d2ipavZpFauWOw3oncbvGXdfR6kgAUKP2Hz2hgiKn/Ow2NagTaHWcGlPpFaf09HStWLGi3PUVK1Zo9erVVRIKAAB3ZRiGnhxavOr09eo92lmyXQUAvEXpKPImUUGy2wyL09ScShenBx98UHv27Cl3fd++fXrwwQerJBQAAO6sZ9NIXdYmRg6nqbfmbrU6DgDUKG+cqCedR3HavHmzunXrVu56165dtXnz5ioJBQCAuyu91+n79fuVfPCYxWkAoOa4JurFeM/9TdJ5FCd/f3+lpaWVu37gwAH5+HjHqcEAAHRoEK4/dawr05TenJ1sdRwAqDGpmSUrTl50+K10HsVpyJAheuaZZ5SVleW6dvToUf3973/X4MGDqzQcAADubMzg1rIZ0uzNaVq/56jVcQCgRuxwrThRnM7qX//6l/bs2aMmTZpo4MCBGjhwoJo1a6aDBw/qzTffrI6MAAC4pZaxobqmawNJ0r9YdQLgBXILirQ/K0+Sdx1+K51HcWrQoIF+//13vf7662rfvr26d++ut99+Wxs2bFCjRo2qIyMAAG7rsUGt5Ws3tHhbppanHrI6DgBUq9KDb+sE+apOsJ/FaWrWed2UFBwcrHvvvbeqswAAUOs0igzSTT0b6fPlu/WvWcma8dc+MgzvGc8LwLuUFqdmXnZ/k3SexUkqnq63e/duFRQUlLl+1VVXXXAoAABqk4fjW2nG6r1aveuIFmzN0MA2sVZHAoBq4a0T9aTz2KqXmpqqzp07q0OHDrryyit1zTXX6JprrtG1116ra6+9ttIB3nvvPTVt2lQBAQHq3bu3Vq5cedbnHz16VA8++KDq1asnf39/tW7dWj///HOlPxcAgKoSFxagkZc0lST9a1aynE7T2kAAUE289Qwn6TyK0+jRo9WsWTOlp6crKChImzZt0qJFi9SjRw8tWLCgUu81ffp0jRkzRmPHjtXatWvVuXNnDR06VOnp6ad9fkFBgQYPHqydO3fqm2++UXJysj766CM1aNCgsj8GAABV6q8DWijE30eb9mdr5qaDVscBgGpRulXP20aRS+dRnJYtW6aXX35Z0dHRstlsstls6tevn8aNG6dHHnmkUu81fvx43XPPPRo1apTat2+viRMnKigoSJMnTz7t8ydPnqzDhw/ru+++U9++fdW0aVMNGDBAnTt3ruyPAQBAlYoM9tOd/ZpJKj7XycGqEwAPY5omW/Uqw+FwKDQ0VJIUHR2t/fv3S5KaNGmi5OSKj2ItKCjQmjVrNGjQoJNhbDYNGjRIy5YtO+1rfvjhB/Xp00cPPvig4uLi1KFDB73yyityOBxn/Jz8/HxlZ2eX+QIAoDrcfWkzRQT5KiUjR//9bZ/VcQCgSmUcz9ex/CLZDKlJVJDVcWpcpYtThw4dtH79eklS79699frrr2vp0qV6+eWX1bx58wq/T2ZmphwOh+Li4spcj4uL08GDp9/ikJqaqm+++UYOh0M///yznn/+eb355pv6xz/+ccbPGTdunMLDw11fjEwHAFSXsABf/XVAC0nSW3O3qqDIaXEiAKg6patNDesEyd/HbnGamlfp4vTcc8/J6Sz+fwQvv/yyduzYoUsvvVQ///yz3nnnnSoPeCqn06nY2Fh9+OGH6t69u2666SY9++yzmjhx4hlf88wzzygrK8v1tWfPnmrNCADwbiP7NFVMqL/2Hjmh6at2Wx0HAKqMN48il85jHPnQoUNd/7tly5basmWLDh8+rDp16lTq3Iro6GjZ7XalpaWVuZ6Wlqa6deue9jX16tWTr6+v7PaTDbddu3Y6ePCgCgoK5OdX/hAuf39/+fv7VzgXAAAXItDProfjW+qF7zfp3/O26y/dGynQz/v+yywAz+PNE/WkSq44FRYWysfHRxs3bixzPTIystKH/fn5+al79+5KTEx0XXM6nUpMTFSfPn1O+5q+fftq+/btrhUvSdq6davq1at32tIEAIAVbu7ZWA0iApV+LF+fLd9pdRwAqBLePBhCqmRx8vX1VePGjc86jKEyxowZo48++kiffPKJkpKSdP/99ysnJ0ejRo2SJI0YMULPPPOM6/n333+/Dh8+rNGjR2vr1q366aef9Morr+jBBx+skjwAAFQFPx+bRg9qJUl6f0GKjuUVWpwIAC6cN48il87jHqdnn31Wf//733X48OEL/vCbbrpJ//rXv/TCCy+oS5cuWrdunWbOnOkaGLF7924dOHDA9fxGjRpp1qxZWrVqlTp16qRHHnlEo0eP1tNPP33BWQAAqErXdW2g5jHBOppbqElLdlgdBwAuSKHDqd2HcyV571Y9wzTNSh000bVrV23fvl2FhYVq0qSJgoPL/uLWrl1bpQGrWnZ2tsLDw5WVlaWwsDCr4wAAPNj/ft+vh774TSH+Plr81EDVCWZbOYDaKSXjuBLeXKggP7s2vTS00rfpuKvKdINKD4e45pprzjcXAABe5U8d6qldvRQlHcjWxIUpeuZP7ayOBADnpfT+pmbRwR5Tmiqr0sVp7Nix1ZEDAACPY7MZenJoa905dbU+WbZTd/VrptiwAKtjAUCl7cgsnqjnraPIpfO4xwkAAFTcwDax6tY4QnmFTr07f7vVcQDgvHj7RD3pPIqTzWaT3W4/4xcAADjJMAw9MbSNJOnLlbu1p+TmagCoTUqLUwsvHQwhncdWvf/+979lvi8sLNRvv/2mTz75RC+99FKVBQMAwFNc0iJa/VpGa8n2TL2duE3/uqGz1ZEAoFJSM0/e4+StKl2crr766nLX/vKXv+iiiy7S9OnTddddd1VJMAAAPMkTQ9toyfZMfbt2r/46oIVaxnrvdhcAtUt2XqEyj+dL8u7iVGX3OF188cVKTEysqrcDAMCjdGkUoUHt4uQ0pQlztlodBwAqrHSbXmyov0IDfC1OY50qKU4nTpzQO++8owYNGlTF2wEA4JEeH9JahiH9tOGANu7LsjoOAFQIE/WKVXqrXp06dcrMbjdNU8eOHVNQUJA+//zzKg0HAIAnaVcvTMM61dcP6/dr/JytmnxHT6sjAcA5MVGvWKWL04QJE8oUJ5vNppiYGPXu3Vt16tSp0nAAAHiaxwa31k8bDmjelnSt2XVY3ZtEWh0JAM6KiXrFKl2c7rjjjmqIAQCAd2gWHawbujfUV6v26I1ZyfrynovL/AdJAHA3KRnFW/Wae3lxqvQ9TlOmTNGMGTPKXZ8xY4Y++eSTKgkFAIAnezihlfzsNi1PPayl2w9ZHQcAzsjpNLXzUOkocu/eqlfp4jRu3DhFR0eXux4bG6tXXnmlSkIBAODJGkQE6taLG0uS3pi1RaZpWpwIAE7vQHae8gqd8rUbalQn0Oo4lqp0cdq9e7eaNWtW7nqTJk20e/fuKgkFAICne+Cylgr0tWv93izN2ZxmdRwAOK3Ukm16jSOD5GOvspOMaqVK//SxsbH6/fffy11fv369oqKiqiQUAACeLibUX6P6NpUkvTl7q5xOVp0AuJ8dmWzTK1Xp4jR8+HA98sgjmj9/vhwOhxwOh+bNm6fRo0fr5ptvro6MAAB4pPv6t1BogI+S047px9/3Wx0HAMphot5JlS5O//d//6fevXsrISFBgYGBCgwM1JAhQxQfH889TgAAVEJ4kK/u699ckjRhzlYVOpwWJwKAspiod1Kli5Ofn5+mT5+u5ORkTZs2Td9++61SUlI0efJk+fn5VUdGAAA81qi+zRQV7Kedh3L1nzV7rY4DAGWwVe+kSp/jVKpVq1Zq1apVVWYBAMDrBPv76IGBLfV//9ustxO36ZquDRTga7c6FgAor9ChfUdPSGLFSTqPFafrr79er732Wrnrr7/+um644YYqCQUAgDe5tXdj1QsP0IGsPH2xggm1ANzDzkM5Mk0pLMBHUcHsLKt0cVq0aJH+9Kc/lbt+xRVXaNGiRVUSCgAAbxLga9fD8cW7ON6bv105+UUWJwKAk4MhmseEyDAMi9NYr9LF6fjx46e9l8nX11fZ2dlVEgoAAG9zQ4+GahIVpEM5BZr6606r4wCA6/6m5tFs05POozh17NhR06dPL3f9q6++Uvv27askFAAA3sbXbtNjg1pLkj5YmKKs3EKLEwHwdkzUK6vSwyGef/55XXfddUpJSVF8fLwkKTExUV988YW++eabKg8IAIC3GNa5vt5fsF1b047rw8UpenJoW6sjAfBip27Vw3msOA0bNkzfffedtm/frgceeECPP/649u3bp3nz5qlly5bVkREAAK9gtxl6fEgbSdKUpTuVeTzf4kQAvJVpmkotWXFqxlY9SedRnCTpyiuv1NKlS5WTk6PU1FTdeOONeuKJJ9S5c+eqzgcAgFcZ0j5OnRuGK7fAoffnp1gdB4CXOpxToOy8IhkGxanUeRUnqXi63siRI1W/fn29+eabio+P1/Lly6syGwAAXscwTq46fb58l/aXnKECADUptWQwRP3wQM6WK1Gp4nTw4EG9+uqratWqlW644QaFhYUpPz9f3333nV599VX17NmzunICAOA1Lm0Vrd7NIlXgcOrf87ZZHQeAF0plMEQ5FS5Ow4YNU5s2bfT777/rrbfe0v79+/Xvf/+7OrMBAOCVDMPQk0OLV52+Xr1XO0v+yy8A1JRURpGXU+Hi9Msvv+iuu+7SSy+9pCuvvFJ2O0t2AABUlx5NI3VZmxg5nKYmzN1qdRwAXoaJeuVVuDgtWbJEx44dU/fu3dW7d2+9++67yszMrM5sAAB4tSdK7nX6Yf1+JR88ZnEaAN6ErXrlVbg4XXzxxfroo4904MAB3Xffffrqq69Uv359OZ1OzZkzR8eO8S90AACqUocG4fpTx7oyTenN2clWx/FKm/dn68uVu5Vf5LA6ClBjihxO7T6cK4mJeqeq9FS94OBg3XnnnVqyZIk2bNigxx9/XK+++qpiY2N11VVXVUdGAAC81pjBrWUzpNmb07Ruz1Gr43iNvEKHxv2SpGHvLtEz327QmK/Xy+k0rY4F1Ii9R06o0GEqwNem+uGBVsdxG+c9jlyS2rRpo9dff1179+7Vl19+WVWZAABAiZaxobq2a0NJrDrVlOWph3TF24v1wcJUOZymDEP66fcD+ufPSVZHA2pEambxNr2mUcGy2QyL07iPCypOpex2u6655hr98MMPVfF2AADgFI8OaiVfu6HF2zK1LOWQ1XE8VnZeof7+3w26+cPl2pGZo7gwf300oofeuqmLJGnSkh36eHGqtSGBGnByMATb9E5VJcUJAABUn0aRQbqpZyNJ0r9mJ8s02TJW1eZuTtOQ8Yv0xYrdkqThvRprzpgBGtw+Tld3aaCnr2grSfrHT0n63+/7rYwKVLuTo8iZqHcqihMAALXAw/Gt5O9j05pdR7QgOcPqOB4j83i+Hv7yN9396WodzM5Tk6ggfXFPb427rqPCAnxdz7uvf3ON7NNEkjRm+notT2XlD56LiXqnR3ECAKAWiAsL0MhLmkoqXnViUMGFMU1T3/22T4PHL9SP6/fLZhSXo5mj++uSFtHlnm8Yhl4YdpGGXhSnAodT9366WlvTmCgMz8QZTqdHcQIAoJb464AWCvH30ab92fpl40Gr49Ra+46e0Kipq/To9HU6kluotnVD9d2DffXMn9op0M9+xtfZbYbevrmrejSpo+y8Io2cvFIHs/JqMDlQ/Y7nFyn9WL4kRpH/EcUJAIBaIjLYT3f1ayZJGj8nWQ5WnSrF6TT12bKdGjJ+oRYkZ8jPbtMTQ1rrx4f7qVPDiAq9R4CvXR+N6KHmMcE6kJWnO6asVHZeYfUGB2rQjpLVpugQP4UH+p7j2d6F4gQAQC1y96XNFBHkq5SMHP33t31Wx6k1UjKO66YPl+n57zcpp8Ch7k3q6OfR/fRQfCv52iv3x6E6wX76ZFQvxYT6a8vBY/rrZ2tUUOSspuRAzSodRc5giPIoTgAA1CKhAb7664AWkqS35m7lD+znUOhw6r3523XF24u1aucRBfnZ9dJVF2nGfX3UMjb0vN+3UWSQptzRU8F+dv2ackhPfsMBufAMpfc3sU2vPIoTAAC1zMg+TRUT6q+9R05o+qrdVsdxWxv3Zemqd5fqjVnJKihyakDrGM1+rL9GXtK0Sg717NAgXO/f1l0+NkPfr9uv12ZtqYLUgLVco8iZqFcOxQkAgFom0M+uh+NbSpL+PW+7ThQ4LE7kXvIKHRr3S5Kufm+pkg5kKyLIV+Nv7Kypo3qqYZ2gKv2sAa1jNO66jpKkDxam6pNfd1bp+wM17eQocrbq/RHFCQCAWujmno3VICJQ6cfy9emynVbHcRvLUw/pircX64OFqXI4Tf25Uz3NeWyAruvWUIZx4atMp3NDj0Z6fHBrSdKLP27SzI0HquVzgOpmmqZ2ZLJV70woTgAA1EJ+PjY9OqiVJOn/LUzRMS+f7HYsr1DP/neDbv5wuXZk5iguzF8fjeihd2/ppphQ/2r//IfiW2p4r8YyTWn0V+u0eufhav9MoKqlZecrt8Ahu81Q48iqXZ31BBQnAABqqWu7NlDzmGAdzS3Ux4t3WB3HMnM3p2nw+EWatqL4fq/hvRprzpgBGtw+rsYyGIah/7v6Ig1qF6v8Iqfu+mS1tqcfr7HPB6pC6Ta9xpFB8vOhJvwRvxEAAGopH7tNY0q2iE1askNHcgosTlSzDh3P1yNf/qa7P12tg9l5ahIVpC/u6a1x13VUWEDNnz/jY7fpneFd1blRhLJOFGrk5JVKz+aAXNQeKaWDIdimd1oUJwAAarE/dain9vXCdDy/SBMXplgdp0aYpqnvftunQeMX6of1+2UzpPv6N9fM0f11SYtoS7MF+flo8sgeahoVpH1HT2jU1FU6nl9kaSagonYwivysKE4AANRiNpuhJ4YWrzpN/XWn0jx8haO0jDw6fZ2O5Baqbd1QffdgXz3zp3YK9LNbHU+SFBXir0/u7KWoYD9t2p+t+z9fo0IH523B/bkOv2Wi3mlRnAAAqOUGtolVt8YRyi9y6t15262OUy2cTlOfLdupIeMXakFyhvzsNj0xpLV+fLifOjWMsDpeOU2igjX5jp4K9LVr8bZMPf2fDTJNDsiFeys9/JYznE6P4gQAQC1nGIaeHNpWkvTVqt3aczjX4kRVKyXjuG76cJme/36Tcgoc6t6kjn4e3U8PxbeSr919/yjTuVGE3ru1q+w2Q/9Zu1fj52y1OhJwRvlFDu09UvzvDu5xOj33/bcNAACosD4totSvZbQKHabemrvN6jhVotDh1Hvzt+uKtxdr1c4jCvKz66WrLtKM+/qoZWyo1fEqJL5tnP55TQdJxYcVT1uxy+JEwOntPpQrpymF+PvUyAj/2ojiBACAh3hiaBtJ0n9/26vt6ccsTnNhNu7L0tXvLtUbs5JVUOTUgNYxmv1Yf428pKlstuo5yLa63NyrsR5JKD5z6/nvNmru5jSLEwHlpZyyTa+6Douu7ShOAAB4iC6NIjS4fZycpjRhTu1cdcordGjcL0m6+r2l2nwgWxFBvhp/Y2dNHdVTDevU3gM5HxvUSjf2aCinKT305Vr9tvuI1ZGAMkoHQzBR78woTgAAeJDHh7SWYUg/bTigjfuyrI5TKctTD+mKtxfrg4WpcjhN/blTPc15bICu69aw1v8XcMMw9M9rO2pA6xjlFRYfkLuj5MwcwB2UjiJvHs1EvTOhOAEA4EHa1g3TsE71JUlvzk62OE3FHMsr1LP/3aCbP1yuHZk5igvz10cjeujdW7p51L0Wvnab3r+1mzo2CNfhnALdMWWlMo/nWx0LkCSlZjJR71woTgAAeJjHBreW3WZofnKGVu88bHWcs5q7OU2Dxy/StBW7JUnDezXWnDEDNLh9nMXJqkewv48m39FTjSIDtetQru6aukq5BRyQC+ulZpSe4URxOhOKEwAAHqZZdLBu6N5QkvTGrGS3PD/o0PF8PfLlb7r709U6mJ2nJlFB+uKe3hp3XUeFBfhaHa9axYT665NRvVQnyFfr92bpwWlrVcQBubDQkZwCHcktlMQ9TmdDcQIAwAM9nNBKfnabVuw4rCXbM62O42Kapr77bZ8GjV+oH9bvl82Q7uvfXDNH99clLaKtjldjmseE6OORPeXvY9P85Aw9991Gtyy48A6l2/TqhQcoyM/H4jTui+IEAIAHahARqFsvbixJ+pebrDrtP3pCd05dpUenr9OR3EK1rRuq7x7sq2f+1E6Bfnar49W47k3q6N/Du8pmSF+t2qN3ErdbHQleim16FUNxAgDAQz1wWUsF+tq1fm+WZlt4dpDTaeqzZTs1ePxCzU/OkJ/dpieGtNaPD/dTp4YRluVyB0MuqquXri4+IHfC3K36etUeixPBG5VOeGSb3tlRnAAA8FAxof4a1bepJGn87K1yOGt+1Skl47hu+nCZnv9+k3IKHOrepI5+Ht1PD8W3kq+dP4ZI0u0XN9EDl7WQJD3z3w2an5xucSJ4m1RGkVcI/8YCAMCD3de/hUIDfJScdkz/+31/jX1uocOp9+Zv1xVvL9aqnUcU5GfXS1ddpBn39VHL2NAay1FbPDm0ja7r2kAOp6kHp63V73uPWh0JXqT08Fu26p0dxQkAAA8WHuSr+/o3lySNn7NVhTUwvW3jvixd/e5SvTErWQVFTg1oHaPZj/XXyEuaymar3QfZVhfDMPTq9Z3Ur2W0cgscunPqKu0+lGt1LHgBh9PUzpJ/1lhxOjuKEwAAHm5U32aKCvbTrkO5+mbN3mr7nLxCh179ZYuufm+pNh/IVkSQr8bf2FlTR/VUwzpB1fa5nsLPx6b/d1s3ta8XpszjBRo5ZaUO5xRYHQsebv/REyoocsrPx6YGdQKtjuPWKE4AAHi4YH8fPTCwpSTpncRtyit0VPlnrEg9pCveXqyJC1PkcJr6c6d6mvPYAF3XraEMg1WmigoN8NWUUT3VICJQOzJzdNcnq3SioOr/fgGlUkom6jWNCpKdFeGzojgBAOAFbu3dWPXCA3QgK0/TVuyusvc9lleoZ/+7QTd9uFw7MnMUF+avj0b00Lu3dFNMqH+VfY43iQsL0Cd39lR4oK9+231Uj3z1myWDPeAdGAxRcRQnAAC8QICvXQ/Ht5IkvT9/u3Lyiy74PROT0jR4/CJXERveq7HmjBmgwe3jLvi9vV3L2FB9PLKH/HxsmrM5TWN/4IBcVA/XKHIGQ5wTxQkAAC9xQ4+GahIVpEM5BZr6687zfp9Dx/P1yJe/6a5PVutgdp6aRAXpi3t6a9x1HRUW4Ft1gb1cz6aRevumLjIM6fPlu/X+ghSrI8EDuSbqcYbTOVGcAADwEr52mx4b1FqSNHFhirJyCyv1etM09d1v+zRo/EL9sH6/bIZ0X//mmjm6vy5pEV0dkb3eFR3r6YU/t5ckvTErWd+urb7hHvBOrq16MWzVOxeKEwAAXmRY5/pqHReiY3lF+nBxxVcw9h89oTunrtKj09fpSG6h2tYN1XcP9tUzf2qnQD97NSbGqL7NdG/JSPmnvvldi7dlWJwIniK3oEgHsvIkseJUERQnAAC8iN1m6PEhbSRJU5buVMax/LM+3+k09dmynRo8fqHmJ2fIz27TE0Na68eH+6lTw4gaSAxJevrythrWub6KnKbu/3ytNu3PsjoSPEDp/U11gnxVJ9jP4jTuj+IEAICXGdI+Tp0bhiu3wKH3F2w/4/NSMo7rpg+X6fnvNymnwKHuTero59H99FB8K/na+SNETbLZDP3rhk7q0zxKx/OLdMeUVdp7hANycWHYplc5/FsPAAAvYxgnV52mLd+tfUdPlHm80OHUe/O364q3F2vVziMK8rPrpasu0oz7+qhlbKgVkSHJ38euibd3V5u4UGUcy9fIySt1NJcDcnH+To4iZ5teRVCcAADwQpe2ilbvZpEqcDj178Rtrusb92Xp6neX6o1ZySoocmpA6xjNfqy/Rl7SVDYOx7RceKCvpt7ZU/XCA5SSkaN7Pl1dLQcawzvsKJmoxyjyiqE4AQDghQzD0JNDi1edZqzZqy0Hs/XqL1t09XtLtflAtiKCfDX+xs6aOqqnGtYJsjgtTlUvPFBTR/VSaICPVu08osemr+OAXJyX1EwOv60MihMAAF6qR9NIXdYmRg6nqT+/s0QTF6YU/+9O9TTnsQG6rltDGQarTO6oTd1QfXh7D/nZbfpl40H93/82c0AuKsU0TddWvRasOFUIxQkAAC/2RMm9TkVOU3Fh/vpoRA+9e0s3xYT6W5wM59KnRZT+dWNnSdLUX3fqo8WpFidCbZJxPF/H84tkM6TGUawqV4SP1QEAAIB1OjQI12vXd9S+o3m6+9JmCgvwtToSKuGqzvWVlpWnf/6cpFd+3qK4sABd3aWB1bFQC5SuNjWsEyR/H85iqwiKEwAAXu6mno2tjoALcPelzbTv6AlN/XWnnpixXjGh/rqkRbTVseDmTo4iZ5teRbFVDwAAoBYzDEPP/7m9ruhQV4UOU/d9ukZbDmZbHQtuLjWjZKIeo8grjOIEAABQy9lthibc1EU9m9bRsfwi3TF5lQ5knTj3C+G1dmRy+G1lUZwAAAA8QICvXR+N6KGWsSE6mJ2nOyavUtaJQqtjwU2VjiJvwYpThVGcAAAAPEREkJ+mjuqp2FB/Jacd032frVZ+EQfkoqyCIqd2H86VxIpTZVCcAAAAPEjDOkGaMqqnQvx9tDz1sJ6Y8bucHJCLU+w5kiuH01SQn11xYRw9UFEUJwAAAA9zUf1w/b/busnHZujH9fv16swtVkeCGymdqNcsOphDriuB4gQAAOCBLm0Vo9f/0kmS9OGiVE1ZusPiRHAXpRP12KZXORQnAAAAD3Vdt4Z6cmgbSdLL/9usXzYcsDgR3MGpK06oOIoTAACAB3vgsha67eLGMk1p9PR1WrnjsNWRYLHSUeQtOPy2UihOAAAAHswwDL10VQcNbh+ngiKn7vl0tbanH7M6FiyUmlmyVS+arXqVQXECAADwcHaboXdu7qqujSOUdaJQIyevUlp2ntWxYIGsE4XKPF4gSWoaHWRxmtqF4gQAAOAFAv3smjSyp5pFB2vf0RO6Y8oqHcvjgFxvU7pNLzbUX6EBvhanqV0oTgAAAF4iMthPn4zqpegQPyUdyNb9n69VQZHT6lioQScn6nF/U2VRnAAAALxI46ggTbmjl4L87FqyPVNP/+d3mSYH5HqL0ol6jCKvPIoTAACAl+nYMFzv3dpNdpuhb3/bpzdmJVsdCTWkdKtec0aRVxrFCQAAwAsNbBOrcdd1lCS9vyBFny3fZXEi1IQUtuqdN4oTAACAl7qxRyM9Nqi1JGns9xs1e9NBixOhOjmdpnYeKl1xYqteZVGcAAAAvNgjCS01vFcjOU3p4S9/05pdR6yOhGqyP+uE8gqd8rUbalgn0Oo4tQ7FCQAAwIsZhqH/u7qD4tvGKr/Iqbs/WeWavAbPUnp/U+PIIPnYqQGVxW8MAADAy/nYbXr3lq7q3DBcR3ILNXLKSqUf44BcT8NEvQtDcQIAAICC/Hw06Y6eahIVpD2HT+iuqauVk19kdSxUIdcZTkzUOy8UJwAAAEiSokP89cmoXooM9tOGfVl6YNpaFTo4INdTpJaOImei3nmhOAEAAMClaXSwJo3soQBfmxZuzdDfv93AAbkegq16F4biBAAAgDK6Nq6j927pJpshzVizVxPmbrM6Ei5QXqFD+7NOSGKr3vmiOAEAAKCchHZx+sc1xQfkvpO4TV+u3G1xIlyInYdyZJpSWICPIoP9rI5TK1GcAAAAcFq39G6sh+NbSpKe+26j5m1JszgRztep2/QMw7A4Te1EcQIAAMAZjRncWn/p3lAOp6kHp/2m9XuOWh0J58E1UY/BEOeN4gQAAIAzMgxD467rqP6tY3Si0KE7p67SzpLpbKg9XCtO3N903ihOAAAAOCtfu03v39pNHRqE6VBOge6YslKHjudbHQuVcHIUORP1zhfFCQAAAOcU4u+jyXf0VMM6gdp5KFd3frJauQUckFsbmKbJVr0qQHECAABAhcSGBuiTO3spIshX6/cc1cNf/KYiDsh1e4dyCpSdVyTDkJpGUZzOF8UJAAAAFdYiJkSTRvaQv49NiVvS9cGiVKsj4Rx2lGzTqx8eqABfu8Vpai+KEwAAACqle5NIPf/n9pKkH9bttzgNzoVtelWD4gQAAIBK+3OnerLbDCWnHdOew7lWx8FZlE7Ua8FgiAtCcQIAAEClRQT5qXuTOpKkeVvSLU6Ds0kpKU7NGEV+QShOAAAAOC+D2sVKkuYmpVmcBGezI5OtelWB4gQAAIDzEt82TpK0IvWwjuczmtwdFTmc2l2ylZIznC4MxQkAAADnpUVMsJpGBanA4dSSbRlWx8Fp7DlyQoUOUwG+NtULC7A6Tq1GcQIAAMB5MQxDCe2KV53mJnGfkzsq3abXNCpYNpthcZrajeIEAACA85bQtvg+p/lb0uVwmhanwR8xUa/qUJwAAABw3no2i1RogI8O5RRo/d6jVsfBH5RO1GMwxIWjOAEAAOC8+dptGtA6RpKUyHQ9t1O6VY9R5BeO4gQAAIALklAyljyR+5zcTqprxYmteheK4gQAAIALclnrWNkMacvBY9p7JNfqOChxLK9Q6cfyJbHiVBUoTgAAALggdYL91KNJpCRp3hZWndzFjszi1aboED+FB/panKb2ozgBAADggsWXbNdjLLn7KC1OzaPZplcVKE4AAAC4YINKitPylEPKyS+yOA0kJupVNYoTAAAALliLmBA1iQpSgcOpxdsyrY4DSakZTNSrShQnAAAAXDDDMJTQNk4SY8ndhWurHhP1qgTFCQAAAFWidCz5/OR0OZ2mxWm8m2mapxQnVpyqAsUJAAAAVaJn00iF+vso83iB1u89anUcr3YwO0+5BQ7ZbYYaRwZZHccjUJwAAABQJfx8bOrfJkYSh+FarfTg28aRQfK180f+qsBvEQAAAFUmoW3pWHLuc7JSqmsUOdv0qgrFCQAAAFVmYJtY2Qxpy8Fj2nf0hNVxvFbpRD3ub6o6FCcAAABUmTrBfurepI4kaR6rTpYp3arXjMNvqwzFCQAAAFUqvmQs+Vzuc7IME/WqHsUJAAAAVWpQyVjyZSmHlJNfZHEa75Nf5NDeI7mSKE5VieIEAACAKtUyNkSNI4NU4HBqyfZMq+N4nV2HcuU0pRB/H8WE+Fsdx2NQnAAAAFClDMNQfMl0vUTuc6pxpfc3NY8JlmEYFqfxHBQnAAAAVLlB7Yrvc5q3JUNOp2lxGu+SmlkyUY9R5FWK4gQAAIAq16tZpEL8fZR5PF+/78uyOo5XObnixES9qkRxAgAAQJXz87Gpf+toSWzXq2mlZzg1Y8WpSlGcAAAAUC0SGEtuCUaRVw+KEwAAAKrFwLaxshlS0oFs7T96wuo4XuFIToGO5BZKYsWpqlGcAAAAUC0ig/3UrXEdSVLiFladakLpYIh64QEK8vOxOI1noTgBAACg2sS3Yyx5TTp1FDmqFsUJAAAA1aZ0LPmvKYeUW1BkcRrPl1p6f1M0E/WqGsUJAAAA1aZVbIgaRQaqoMipJdsyrY7j8Uon6rHiVPUoTgAAAKg2hmG4puslMl2v2pVO1GMwRNWjOAEAAKBaJZTc5zQvOV1Op2lxGs/lcJraeShXktSCw2+rHMUJAAAA1ap3sygF+9mVcSxfG/ZlWR3HY+07ckIFRU75+dhUPyLQ6jgeh+IEAACAauXnY1P/1jGSmK5XnVJKRpE3jQqS3WZYnMbzUJwAAABQ7RJKputxnlP12ZHBRL3qRHECAABAtRvYJkaGIW3an60DWSesjuORSg+/ZaJe9aA4AQAAoNpFhfira6MISUzXqy6lh98yUa96UJwAAABQI1zb9bjPqVqUjiJvzkS9akFxAgAAQI0YVFKclqYcUm5BkcVpPEtuQZEOZOVJklqwVa9aUJwAAABQI1rHhahhnUAVFDm1dPshq+N4lNJtepHBfooI8rM4jWeiOAEAAKBGGIahhLbFh+GyXa9qpWZyf1N1ozgBAACgxpTe5zRvS7qcTtPiNJ7j5ChyilN1oTgBAACgxvRuHqlgP7vSj+Vr4/4sq+N4jJOjyBkMUV0oTgAAAKgx/j52XdoqRpI0l7HkVYZR5NWP4gQAAIAaldCu+D6neVu4z6kqmKbpGkXORL3qQ3ECAABAjRrYNlaGIW3cl62DJSO0cf4yjuXreH6RbIbUOCrI6jgei+IEAACAGhUd4q8ujSIkSYmsOl2wlJJteg3rBMnfx25xGs9FcQIAAECNKz0Mdx73OV2w0m16zdmmV60oTgAAAKhxpfc5LdmeqRMFDovT1G6pGSUT9aKZqFed3KI4vffee2ratKkCAgLUu3dvrVy5skKv++qrr2QYhq655prqDQgAAIAq1SYuVA0iApVf5NTS7ZlWx6nVUllxqhGWF6fp06drzJgxGjt2rNauXavOnTtr6NChSk8/+7Ltzp079cQTT+jSSy+toaQAAACoKoZhuFaduM/pwpxccaI4VSfLi9P48eN1zz33aNSoUWrfvr0mTpyooKAgTZ48+YyvcTgcuvXWW/XSSy+pefPmNZgWAAAAVSWh5D6nxKR0maZpcZraqaDIqT1HTkji8NvqZmlxKigo0Jo1azRo0CDXNZvNpkGDBmnZsmVnfN3LL7+s2NhY3XXXXef8jPz8fGVnZ5f5AgAAgPUubh6pID+70o/la+M+/ox2PnYfzpXDaSrIz664MH+r43g0S4tTZmamHA6H4uLiylyPi4vTwYMHT/uaJUuWaNKkSfroo48q9Bnjxo1TeHi466tRo0YXnBsAAAAXzt/HrktbRUuS5iaxXe98lG7TaxYdLMMwLE7j2SzfqlcZx44d0+23366PPvpI0dHRFXrNM888o6ysLNfXnj17qjklAAAAKqp0u968LYwlPx8nR5GzTa+6+Vj54dHR0bLb7UpLK/tfGNLS0lS3bt1yz09JSdHOnTs1bNgw1zWn0ylJ8vHxUXJyslq0aFHmNf7+/vL3Z9kSAADAHQ1sEyvDkDbsy1Jadp7iwgKsjlSrpJYcfstgiOpn6YqTn5+funfvrsTERNc1p9OpxMRE9enTp9zz27Ztqw0bNmjdunWur6uuukoDBw7UunXr2IYHAABQy8SE+qtzwwhJxUMiUDmpmSUT9RhFXu0sXXGSpDFjxmjkyJHq0aOHevXqpbfeeks5OTkaNWqUJGnEiBFq0KCBxo0bp4CAAHXo0KHM6yMiIiSp3HUAAADUDoPaxWrdnqOatyVNt/RubHWcWuXkihNb9aqb5cXppptuUkZGhl544QUdPHhQXbp00cyZM10DI3bv3i2brVbdigUAAIBKSGgXp3/N3qol2zOVV+hQgK/d6ki1QlZuoQ7lFEiSmrHiVO0M08uG5mdnZys8PFxZWVkKCwuzOg4AAIDXM01TfV+dp/1ZeZo0sodrYATO7rfdR3Tt+78qLsxfK/4+6NwvQDmV6QYs5QAAAMBShmG4ytJc7nOqsNJtes0YDFEjKE4AAACwXEK7WEnSvC1p8rINUeeNUeQ1i+IEAAAAy13cPEpBfnalZedr0/5sq+PUCq6Jeqw41QiKEwAAACwX4GtXv5bRkqS5SWnneDakUybqMRiiRlCcAAAA4BYGldznNG8L9zmdi9NpntyqxyjyGkFxAgAAgFsY2Lb4Pqff92YpLTvP4jTubX/WCeUXOeVrN9SwTqDVcbwCxQkAAABuISbUX50bRUhi1elcSrfpNYkKlo+dP9LXBH7LAAAAcBuDSladEhlLflapGcWDIRhFXnMoTgAAAHAbpec5LdmeobxCh8Vp3NfJUeQUp5pCcQIAAIDbaFcvVPXDA5RX6NSvKZlWx3FbqSXFqQWDIWoMxQkAAABuwzAMxbdju965lN7j1IwVpxpDcQIAAIBbSThlLLlpmhancT95hQ7tO3pCEoff1iSKEwAAANxKn+ZRCvS160BWnjbtz7Y6jtspvb8pPNBXkcF+FqfxHhQnAAAAuJUAX7v6tYqWxHa903Ft04sOlmEYFqfxHhQnAAAAuJ1BJfc5zduSZnES97Mjs3gUORP1ahbFCQAAAG5nYJvi4rR+b5bSs/MsTuNeSlecWsQwUa8mUZwAAADgdmLDAtS5Ybik4iEROCml9AwnBkPUKIoTAAAA3FLpdL1EipOLaZpKzSjeqsco8ppFcQIAAIBbSii5z2nJtkzlFTosTuMeDuUU6FhekQxDahpFcapJFCcAAAC4pfb1wlQvPEAnCh1alnLI6jhuofT+pgYRgQrwtVucxrtQnAAAAOCWDMNQfNviVadEputJ0sltetzfVOMoTgAAAHBbg0ruc5qXlC7TNC1OY73Sw2+ZqFfzKE4AAABwW31aRCnA16b9WXnafCDb6jiWSynZqscZTjWP4gQAAAC3FeBr///t3XtwVPX9//HXbja7ud9DwiVAuCZaW0qQiFgFkmqt4w2ntdNOtbRqGbU6ok5xsIL2Z9EWO7ZWbadOtdJpoV7G9it4I4BYinKR4C0ESgLBS26EkJB7sp/fH9ldiAQ2IZucvTwfMxlg97PnvE84A3nN5/N5H100JVNS76xTpKuoZ6meVQhOAAAACGrFnu56GyK8LXlXj1tVR1olSZNYqjfiCE4AAAAIat4GEXsON6q2ud3iaqzz6dE2dbuNYqLtGp0UY3U5EYfgBAAAgKA2KilGXx2XLEnaFMGzTic66iXIbrdZXE3kITgBAAAg6BXl9XbXK4ngfU7eZzhNYn+TJQhOAAAACHpFnn1O7+yvV3tXj8XVWKOino56ViI4AQAAIOidOyZJ2Ukxauvq0baKI1aXYwnvUj2CkzUITgAAAAh6NptNCzyzTpHaltw745SbQUc9KxCcAAAAEBK8bclLympkjLG4mpHV3N6luuYOScw4WYXgBAAAgJBw4eQMxUTb9fmxdpV90Wx1OSOq0jPblJHgUlJMtMXVRCaCEwAAAEJCTHSULpqSIUnauLfG4mpGFh31rEdwAgAAQMgoyu9tS74hwvY50RjCegQnAAAAhIwFeb37nPZ82ujb8xMJaEVuPYITAAAAQkZWUozOG5ssY6RN5ZEz63RiqR4d9axCcAIAAEBIKTqpu14kcLuNrzlELjNOliE4AQAAIKQU5fXuc3pnf73au3osrmb41TS3q62rRw67TePT4qwuJ2IRnAAAABBSvjI2SVlJLrV29ujdiiNWlzPsvMv0xqfFKTqKH9+twnceAAAAIcVms2mBZ9Zp497w3+fk7aiXSytySxGcAAAAEHKK8rz7nGpljLG4muFFR73gQHACAABAyJk7JUMuh12fNbZpb3Wz1eUMK19HvUw66lmJ4AQAAICQE+uM0kVTMiSF/3K9inrPw29ZqmcpghMAAABCUlF+7z6nDWHclry9q0efHm2TRCtyqxGcAAAAEJIWePY5lR5uVP3xDourGR5VDa0yRkp0OZSZ4LK6nIhGcAIAAEBIyk6O0VfGJskYaVOYLtfzdtSblBkvm81mcTWRjeAEAACAkOV9GG5JWXgGpwOexhC0IrcewQkAAAAhqyi/d7neO/vr1NHdY3E1gVdZT0e9YEFwAgAAQMj6yphkjUp0qaWzR+9VNFhdTsCdvFQP1iI4AQAAIGTZ7TbfrFNJGHbX8z78lqV61iM4AQAAIKQtyPO2Ja+VMcbiagKnoaVTja1dkghOwYDgBAAAgJB20ZQMuRx2fdbYpvKaZqvLCZhKz4NvxyTHKM7psLgaEJwAAAAQ0mKdUZo7JUNSeHXX83bUozFEcCA4AQAAIOR5H4YbTvucKmhFHlQITgAAAAh53gYRuw83qv54h8XVBIZ3qR4d9YIDwQkAAAAhb3RyrM4dkyRjpM3ldVaXExAVLNULKgQnAAAAhIWiMFqu1+M2OnSkVZI0iaV6QYHgBAAAgLBQlN/blnzLvjp1dPdYXM3QfHa0TZ09bjkddo1JibW6HIjgBAAAgDBx3thkZSa61NLZo+2VDVaXMyQHPPubctPjFWW3WVwNJIITAAAAwoTdbjtpuV5otyWno17wITgBAAAgbHjbkm8oq5ExxuJqzl5FHR31gg3BCQAAAGHjoqkZcjrs+vRom/bXHre6nLNWWU9HvWBDcAIAAEDYiHM6NHdyuqTeWadQdaIVOTNOwYLgBAAAgLCywNNdL1T3ObV0dKu6qV0SrciDCcEJAAAAYcXbIOL9qqM6crzD4moGz7tMLy3eqZQ4p8XVwIvgBAAAgLAyJiVW54xOkjHS5vI6q8sZtArv/iZmm4IKwQkAAABhpyjf05Z8b+jtc/J21KMVeXAhOAEAACDsFHn2OW3ZV6/ObrfF1QzOicYQdNQLJgQnAAAAhJ2vjk1WRoJLxzu6tb2ywepyBuVEK3JmnIIJwQkAAABhx263aUFepqTQaktujPEt1ZtMcAoqBCcAAACEJe9yvZK9NTLGWFzNwNQ2d6ils0d2m5STFmd1OTgJwQkAAABh6RtTM+R02HW4oU3/qz1udTkD4t3flJMWJ5cjyuJqcDKCEwAAAMJSnNOhCyenS5I2hMjDcCvqewMerciDD8EJAAAAYcv7MNySENnn5J1xys2go16wITgBAAAgbC3w7HN6v+qoGlo6La7GPzrqBS+CEwAAAMLW2JRY5Y9OkttIm8uDf7met6MewSn4EJwAAAAQ1k4s1wvu4NTZ7dbho22SpEks1Qs6BCcAAACEtaL83uD09r46dXa7La7m9KoaWtTjNop3RikryWV1OfgSghMAAADC2tfGpSgjwanjHd3acbDB6nJOy9cYIjNeNpvN4mrwZQQnAAAAhDW73ab503tnnTYEcXe9Cm9jCJbpBSWCEwAAAMJekae7XklZrYwxFlfTP29jiFye4RSUCE4AAAAIe9+YmiFnlF1VDa064AkowYZW5MGN4AQAAICwF+9y6ILJ6ZKkDUHaXc+7x2lyJkv1ghHBCQAAABGhON/bljz49jkda+3SEc8DeieyVC8oEZwAAAAQERZ4nue069BRHfWElGBRUd+7fDAryaUEl8PiatAfghMAAAAiwrjUOOVlJ8ptpM37gmu5nneZHh31ghfBCQAAABHD+zDcYNvn5J1xyqUxRNAiOAEAACBieNuSbymvU2e32+JqTjgx40RwClYEJwAAAESMGeNSlB7vVHNHt3YebLC6HB9vK3I66gUvghMAAAAiht1u0/y84Fqu53YbnuEUAghOAAAAiCi+tuR7a2SMsbga6bPGNnV0uxUdZdPYlFiry8FpEJwAAAAQUS6amilnlF2HjrTqgGdvkZW8s00T0uPliOLH82DF3wwAAAAiSoLLocJJaZKC42G4FXW9HfVoDBHcCE4AAACIOMWe7nolQbDPqcIz40Qr8uBGcAIAAEDEWeBpELHzUIMaWzstrcXbinwyD78NagQnAAAARJyctDhNz0qU20iby+ssrYWOeqGB4AQAAICIVJTvbUtu3T6nts4efdbYJknKZY9TUCM4AQAAICIVefY5vb2vTl09bktq8M42JcdGKy3eaUkNGBiCEwAAACLSjJwUpcc71dzerR0HGyyp4eRlejabzZIaMDAEJwAAAESkKLtN86Z7HoZrUXe9E63IaQwR7AhOAAAAiFjF+d7gVCNjzIifv4LGECGD4AQAAICI9Y1pmYqOsungkVZfiBlJvuBEY4igR3ACAABAxEpwOXTBpHRJvbNOI8kYc2KpXiZL9YIdwQkAAAARrSjP25Z8ZPc51R/vVHN7t2w2aUJ63IieG4NHcAIAAEBE87Yl33XoqBpbO0fsvN7ZprEpsYqJjhqx8+LsEJwAAAAQ0XLS4jQtK0E9bqO399WN2HlPtCJnmV4oIDgBAAAg4nlnnUZyuR6NIUILwQkAAAARz9uW/O3yWnX1uEfknCcaQxCcQgHBCQAAABFvRk6q0uKdamrv1s6DR0fknCdmnFiqFwoITgAAAIh4UXab5k3PlDQybcm7etyqOtIqiRmnUEFwAgAAACQVe/Y5bdw7/PucDje0qtttFBNtV3ZSzLCfD0NHcAIAAAAkfWNqhqKjbKqob/HtPxouFXW9y/RyMxJkt9uG9VwIDIITAAAAICkxJlqFuemSpJJh7q53ohU5y/RCBcEJAAAA8CjydNfbMMz7nCrqPR31aEUeMghOAAAAgEdRXu8+p52HjupYa9ewnedAHTNOoYbgBAAAAHiMT4/T1FEJ6nEbbd43fMv1KmlFHnIITgAAAMBJijzd9YZrn1Nze5fqmjskSbnMOIUMghMAAABwkmLPPqfN5bXq7nEH/PjejnoZCS4lxUQH/PgYHgQnAAAA4CRfH5+q1LhoNbV3a+ehowE/Ph31QhPBCQAAADhJlN2m+dN7Z51KhqG7nvcZUZMJTiGF4AQAAAB8iW+f097A73M6UO99+C3BKZQQnAAAAIAv+ca0DDnsNlXUtfiW1gWKd48THfVCC8EJAAAA+JKkmGgVTkqTFNjlem630UH2OIUkghMAAADQD+/DcAPZlry6qV1tXT1y2G3KSYsL2HEx/AhOAAAAQD+KPG3Jdxxs0LG2roAc07tMb3xanKKj+FE8lPC3BQAAAPRjQnq8poxKULfb6O19dQE5ZmV9b0c9lumFHoITAAAAcBreWadA7XM64G0MkUljiFBDcAIAAABOo9jTlnxzeZ26e9xDPl4FrchDFsEJAAAAOI2v56QoJS5ax9q6tOvQ0SEfz7dUj+AUcghOAAAAwGk4ouyaP92zXG+ID8Nt7+rRp0fbJLFULxQRnAAAAIAzCNQ+p0NHWmWMlOhyKCPBGYjSMIIITgAAAMAZXDwtUw67TQfqWnwPrz0bFXUnOurZbLZAlYcRQnACAAAAziApJlqzc9MkSRuGMOvkbQzBMr3QRHACAAAA/CjydNfbOIR9Tt6H39JRLzQRnAAAAAA/ivJ69zltr2xQU3vXWR2jgoffhjSCEwAAAODHxIx4Tc6MV7fb6O3yurM6RqV3qV4GS/VCEcEJAAAAGIDiISzXa2jpVGNr70wVS/VCE8EJAAAAGIAFnuV6m8pr1d3jHtRnvR31xiTHKNYZFfDaMPwITgAAAMAAFExIVXJstBpbu/R+VeOgPuttDEFHvdBFcAIAAAAGwBFl1/zpmZIG/zDcE63IWaYXqghOAAAAwAB525KXDHKfk3epHvubQhfBCQAAABigi6dlymG36X+1x3XoSMuAP8fDb0MfwQkAAAAYoOTYaJ0/MU2StKFsYLNOPW7jC1mTmHEKWQQnAAAAYBCK8nu7623cO7B9Tp8ebVVXj5HTYdfYlNjhLA3DiOAEAAAADIJ3n9N7FQ1qau/yO97bUS83PV52u21Ya8PwITgBAAAAg5CbEa9JmfHqdhtt2Vfndzwd9cIDwQkAAAAYpGLPrNPGAexz8nbUIziFNoITAAAAMEgL8nr3OW0qr1WP25xxrG+pXgYd9UIZwQkAAAAYpFkTUpUcG62jrV16v+roGcdW1DPjFA4ITgAAAMAgOaLsmjc9U5K0oez03fVaOrpV09QhiVbkoY7gBAAAAJwF73K9M+1zqvQ0hkiLdyolzjkidWF4EJwAAACAszBv2ihF2W3aX3tcVUda+x1zwNsYgtmmkEdwAgAAAM5Ccly0zp+YKun0y/UqaUUeNghOAAAAwFnytSXf2/9yPW9HvUmZdNQLdQQnAAAA4Cx59zm9V3lEze1dp7zv7aiXy1K9kEdwAgAAAM7SpMwETcqIV1eP0ZZ99X3eM8ao0jPjNJmleiGP4AQAAAAMQVF+76xTyd6++5xqmzvU0tkju00an0ZwCnUEJwAAAGAIFuT17nPaXF6nHrfxve7tqJeTFiengx+7Qx1/gwAAAMAQzJqYqqQYhxpaOrW76qjvdV9jCPY3hQWCEwAAADAE0VF2zZvuXa53orveiVbkdNQLBwQnAAAAYIh8+5xOep5TRR0d9cIJwQkAAAAYonnTRinKbtO+muM63NAqSarg4bdhheAEAAAADFFyXLRmTUiVJG0oq1Fnt9sXoCazVC8sEJwAAACAAPAu19u4t1ZVDS1yGyneGaVRiS6LK0MgEJwAAACAACjK721L/m7FEX3w6TFJUm5mvGw2m5VlIUAITgAAAEAATM5MUG5GvLp6jP7634OSpEkZLNMLFwQnAAAAIECK8nqX6+3xzDjRGCJ8BEVwevLJJzVx4kTFxMSosLBQ27dvP+3Yl19+WbNmzVJKSori4+M1Y8YMrV69egSrBQAAAPq3wLPPyYtW5OHD8uC0du1aLVmyRMuXL9f777+vr33ta7rssstUW1vb7/i0tDQtW7ZM27Zt0wcffKBFixZp0aJFeuONN0a4cgAAAKCv8yemKTHG4fszHfXCh80YY6wsoLCwUOeff77+8Ic/SJLcbrdycnL0s5/9TEuXLh3QMWbOnKkrrrhCv/zlL/2ObWpqUnJyso4dO6akpKQh1Q4AAAB82c/+sVv/t+dzSdLHD16meJfDzydglcFkA0tnnDo7O7Vr1y4VFxf7XrPb7SouLta2bdv8ft4Yo5KSEpWXl+viiy/ud0xHR4eampr6fAEAAADDxbvPKTsphtAURiz9m6yvr1dPT4+ysrL6vJ6VlaW9e/ee9nPHjh3T2LFj1dHRoaioKD311FP65je/2e/YlStX6sEHHwxo3QAAAMDpXH5etnYeGq/C3HSrS0EAhWQETkxMVGlpqY4fP66SkhItWbJEkyZN0rx5804Ze99992nJkiW+Pzc1NSknJ2cEqwUAAEAkcTmi9P+uOc/qMhBglganjIwMRUVFqaamps/rNTU1ys7OPu3n7Ha7pkyZIkmaMWOGysrKtHLlyn6Dk8vlksvF05oBAAAAnD1L9zg5nU4VFBSopKTE95rb7VZJSYnmzJkz4OO43W51dHQMR4kAAAAAYP1SvSVLlujGG2/UrFmzNHv2bD3++ONqaWnRokWLJEk33HCDxo4dq5UrV0rq3bM0a9YsTZ48WR0dHVq/fr1Wr16tp59+2srLAAAAABDGLA9O119/verq6vTAAw+ourpaM2bM0Ouvv+5rGFFVVSW7/cTEWEtLi2699VZ9+umnio2NVV5env72t7/p+uuvt+oSAAAAAIQ5y5/jNNJ4jhMAAAAAKYSe4wQAAAAAoYDgBAAAAAB+EJwAAAAAwA+CEwAAAAD4QXACAAAAAD8ITgAAAADgB8EJAAAAAPwgOAEAAACAHwQnAAAAAPCD4AQAAAAAfhCcAAAAAMAPghMAAAAA+EFwAgAAAAA/CE4AAAAA4AfBCQAAAAD8IDgBAAAAgB8EJwAAAADwg+AEAAAAAH4QnAAAAADAD4ITAAAAAPhBcAIAAAAAPwhOAAAAAOAHwQkAAAAA/CA4AQAAAIAfBCcAAAAA8IPgBAAAAAB+EJwAAAAAwA+H1QWMNGOMJKmpqcniSgAAAABYyZsJvBnhTCIuODU3N0uScnJyLK4EAAAAQDBobm5WcnLyGcfYzEDiVRhxu936/PPPlZiYKJvNZnU5CFNNTU3KycnR4cOHlZSUZHU5iCDce7AC9x2swH2HQDDGqLm5WWPGjJHdfuZdTBE342S32zVu3Diry0CESEpK4h9zWIJ7D1bgvoMVuO8wVP5mmrxoDgEAAAAAfhCcAAAAAMAPghMwDFwul5YvXy6Xy2V1KYgw3HuwAvcdrMB9h5EWcc0hAAAAAGCwmHECAAAAAD8ITgAAAADgB8EJAAAAAPwgOAEAAACAHwQnoB9PPvmkJk6cqJiYGBUWFmr79u1nHP/CCy8oLy9PMTExOu+887R+/fo+7xtj9MADD2j06NGKjY1VcXGx9u/f3++xOjo6NGPGDNlsNpWWlgbqkhAirLr31q1bp8LCQsXGxio1NVXXXHNNIC8LQc6K+27fvn26+uqrlZGRoaSkJF100UXatGlTwK8NwSvQ993LL7+sSy+9VOnp6af9P7S9vV233Xab0tPTlZCQoOuuu041NTWBvCyEMwOgjzVr1hin02n+8pe/mI8//tjcfPPNJiUlxdTU1PQ7fuvWrSYqKsr8+te/Np988om5//77TXR0tPnwww99Yx555BGTnJxsXnnlFbNnzx5z1VVXmdzcXNPW1nbK8e644w5z+eWXG0lm9+7dw3WZCEJW3XsvvviiSU1NNU8//bQpLy83H3/8sVm7du2wXy+Cg1X33dSpU823v/1ts2fPHrNv3z5z6623mri4OPPFF18M+zXDesNx3z3//PPmwQcfNH/+859P+3/o4sWLTU5OjikpKTE7d+40F1xwgbnwwguH6zIRZghOwJfMnj3b3Hbbbb4/9/T0mDFjxpiVK1f2O/673/2uueKKK/q8VlhYaH76058aY4xxu90mOzvb/OY3v/G939jYaFwul/nHP/7R53Pr1683eXl55uOPPyY4RSAr7r2uri4zduxY88wzzwT6chAirLjv6urqjCSzZcsW35impiYjybz11lsBuzYEr0DfdyerrKzs9//QxsZGEx0dbV544QXfa2VlZUaS2bZt2xCuBpGCpXrASTo7O7Vr1y4VFxf7XrPb7SouLta2bdv6/cy2bdv6jJekyy67zDe+srJS1dXVfcYkJyersLCwzzFramp08803a/Xq1YqLiwvkZSEEWHXvvf/++/rss89kt9v19a9/XaNHj9bll1+ujz76KNCXiCBk1X2Xnp6u6dOn6/nnn1dLS4u6u7v1pz/9SaNGjVJBQUGgLxNBZjjuu4HYtWuXurq6+hwnLy9P48ePH9RxELkITsBJ6uvr1dPTo6ysrD6vZ2Vlqbq6ut/PVFdXn3G899czjTHG6Ec/+pEWL16sWbNmBeRaEFqsuvcqKiokSStWrND999+vV199VampqZo3b54aGhqGfmEIalbddzabTRs2bNDu3buVmJiomJgY/fa3v9Xrr7+u1NTUgFwbgtdw3HcDUV1dLafTqZSUlCEdB5GL4AQEgSeeeELNzc267777rC4FEcbtdkuSli1bpuuuu04FBQV69tlnZbPZ9MILL1hcHcKVMUa33XabRo0apXfeeUfbt2/XNddcoyuvvFJffPGF1eUBQL8ITsBJMjIyFBUVdUqHnZqaGmVnZ/f7mezs7DOO9/56pjEbN27Utm3b5HK55HA4NGXKFEnSrFmzdOONNw79whD0rLr3Ro8eLUk655xzfO+7XC5NmjRJVVVVQ7gihAIr/8179dVXtWbNGs2dO1czZ87UU089pdjYWP31r38NyLUheA3HfTcQ2dnZ6uzsVGNj45COg8hFcAJO4nQ6VVBQoJKSEt9rbrdbJSUlmjNnTr+fmTNnTp/xkvTWW2/5xufm5io7O7vPmKamJr333nu+Mb///e+1Z88elZaWqrS01Ndide3atXr44YcDeo0ITlbdewUFBXK5XCovL/eN6erq0sGDBzVhwoSAXR+Ck1X3XWtrq6TefS0ns9vtvllQhK/huO8GoqCgQNHR0X2OU15erqqqqkEdBxHM6u4UQLBZs2aNcblc5rnnnjOffPKJueWWW0xKSoqprq42xhjzwx/+0CxdutQ3fuvWrcbhcJhVq1aZsrIys3z58n5b86akpJh//etf5oMPPjBXX331aduRG3P6jkAIb1bde3feeacZO3aseeONN8zevXvNT37yEzNq1CjT0NAwchcPy1hx39XV1Zn09HSzcOFCU1paasrLy80999xjoqOjTWlp6ch+A2CJ4bjvjhw5Ynbv3m3WrVtnJJk1a9aY3bt392lxv3jxYjN+/HizceNGs3PnTjNnzhwzZ86ckbtwhDSCE9CPJ554wowfP944nU4ze/Zs8+677/reu+SSS8yNN97YZ/w///lPM23aNON0Os25555r1q1b1+d9t9ttfvGLX5isrCzjcrlMUVGRKS8vP+35CU6Ry4p7r7Oz09x9991m1KhRJjEx0RQXF5uPPvpo2K4RwceK+27Hjh3m0ksvNWlpaSYxMdFccMEFZv369cN2jQg+gb7vnn32WSPplK/ly5f7xrS1tZlbb73VpKammri4OHPttdfy7DAMmM0YY6yb7wIAAACA4MceJwAAAADwg+AEAAAAAH4QnAAAAADAD4ITAAAAAPhBcAIAAAAAPwhOAAAAAOAHwQkAAAAA/CA4AQAAAIAfBCcAQFDavHmzbDabGhsbR/S8zz33nFJSUoZ0jIMHD8pms6m0tPS0Y6y6PgDA2SE4AQBGnM1mO+PXihUrrC4RAIA+HFYXAACIPF988YXv92vXrtUDDzyg8vJy32sJCQnauXPnoI/b2dkpp9MZkBoBADgZM04AgBGXnZ3t+0pOTpbNZuvzWkJCgm/srl27NGvWLMXFxenCCy/sE7BWrFihGTNm6JlnnlFubq5iYmIkSY2NjbrpppuUmZmppKQkLViwQHv27PF9bs+ePZo/f74SExOVlJSkgoKCU4LaG2+8ofz8fCUkJOhb3/pWn7Dndrv10EMPady4cXK5XJoxY4Zef/31M17z+vXrNW3aNMXGxmr+/Pk6ePDgUL6FAIARRnACAAS1ZcuW6bHHHtPOnTvlcDj04x//uM/7//vf//TSSy/p5Zdf9u0p+s53vqPa2lq99tpr2rVrl2bOnKmioiI1NDRIkn7wgx9o3Lhx2rFjh3bt2qWlS5cqOjrad8zW1latWrVKq1ev1pYtW1RVVaV77rnH9/7vfvc7PfbYY1q1apU++OADXXbZZbrqqqu0f//+fq/h8OHDWrhwoa688kqVlpbqpptu0tKlSwP8nQIADCeW6gEAgtrDDz+sSy65RJK0dOlSXXHFFWpvb/fNLnV2dur5559XZmamJOk///mPtm/frtraWrlcLknSqlWr9Morr+jFF1/ULbfcoqqqKt17773Ky8uTJE2dOrXPObu6uvTHP/5RkydPliTdfvvteuihh3zvr1q1Sj//+c/1ve99T5L06KOPatOmTXr88cf15JNPnnINTz/9tCZPnqzHHntMkjR9+nR9+OGHevTRRwP2fQIADC9mnAAAQe2rX/2q7/ejR4+WJNXW1vpemzBhgi80Sb3L8I4fP6709HQlJCT4viorK3XgwAFJ0pIlS3TTTTepuLhYjzzyiO91r7i4OF9o8p7Xe86mpiZ9/vnnmjt3bp/PzJ07V2VlZf1eQ1lZmQoLC/u8NmfOnAF/DwAA1mPGCQAQ1E5eQmez2ST17jHyio+P7zP++PHjGj16tDZv3nzKsbxtxlesWKHvf//7WrdunV577TUtX75ca9as0bXXXnvKOb3nNcYE4nIAACGKGScAQFiZOXOmqqur5XA4NGXKlD5fGRkZvnHTpk3TXXfdpTfffFMLFy7Us88+O6DjJyUlacyYMdq6dWuf17du3apzzjmn38/k5+dr+/btfV579913B3llAAArEZwAAGGluLhYc+bM0TXXXKM333xTBw8e1H//+18tW7ZMO3fuVFtbm26//XZt3rxZhw4d0tatW7Vjxw7l5+cP+Bz33nuvHn30Ua1du1bl5eVaunSpSktLdeedd/Y7fvHixdq/f7/uvfdelZeX6+9//7uee+65AF0xAGAksFQPABBWbDab1q9fr2XLlmnRokWqq6tTdna2Lr74YmVlZSkqKkpHjhzRDTfcoJqaGmVkZGjhwoV68MEHB3yOO+64Q8eOHdPdd9+t2tpanXPOOfr3v/99SpMJr/Hjx+ull17SXXfdpSeeeEKzZ8/Wr371q1M6BAIAgpfNsGgbAAAAAM6IpXoAAAAA4AfBCQAAAAD8IDgBAAAAgB8EJwAAAADwg+AEAAAAAH4QnAAAAADAD4ITAAAAAPhBcAIAAAAAPwhOAAAAAOAHwQkAAAAA/CA4AQAAAIAf/x/+zYk9kt0megAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the accuracy scores\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(list_th_mic, list_ac_mic)\n",
    "plt.yticks(np.arange(min_pt, max_pt + (max_pt * 0.01), max_pt * 0.001))\n",
    "# red dot for the highest accuracy with the corresponding threshold rounded to 5 decimal places\n",
    "plt.plot(round(list_th_mic[list_ac_mic.index(max_ac_mic)], 5), max_ac_mic, 'ro')\n",
    "plt.annotate(f\"(Threshold: {round(list_th_mic[list_ac_mic.index(max_ac_mic)], 5)}\\n, Accuracy: {round(max_ac_mic, 5)})\", (round(list_th_mic[list_ac_mic.index(max_ac_mic)], 5), max_ac_mic))\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Threshold vs Accuracy')\n",
    "plt.savefig('outputs/00_feature_select_29/mutual_info_threshold_vs_accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold for the max accuracy: 0.0025\n"
     ]
    }
   ],
   "source": [
    "# get the threshold for the max accuracy\n",
    "th_max = [i[0] for i in accuracy_scores if i[1] == max_ac_mic][0]\n",
    "print(f\"Threshold for the max accuracy: {round(th_max, 5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.01\n",
      "number of features with scores above the threshold: 3\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4166589836866187 \n",
      "test accuracy: 0.4378 \n",
      "train accuracy: 0.4430 \n",
      "ROAUC: 0.5901404807583298 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.38      0.53      4807\n",
      "           1       0.19      0.75      0.31       945\n",
      "\n",
      "    accuracy                           0.44      5752\n",
      "   macro avg       0.54      0.56      0.42      5752\n",
      "weighted avg       0.77      0.44      0.49      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 0 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4166589836866187 \n",
      "test accuracy: 0.4378 \n",
      "train accuracy: 0.4430 \n",
      "ROAUC: 0.5901404807583298 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.38      0.53      4807\n",
      "           1       0.19      0.75      0.31       945\n",
      "\n",
      "    accuracy                           0.44      5752\n",
      "   macro avg       0.54      0.56      0.42      5752\n",
      "weighted avg       0.77      0.44      0.49      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 0 seconds\n",
      "average test accuracy: 0.43776077885952713\n",
      "Threshold: 0.00925\n",
      "number of features with scores above the threshold: 4\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4858117282708394 \n",
      "test accuracy: 0.5598 \n",
      "train accuracy: 0.5604 \n",
      "ROAUC: 0.5718138120884115 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.56      0.68      4807\n",
      "           1       0.20      0.55      0.29       945\n",
      "\n",
      "    accuracy                           0.56      5752\n",
      "   macro avg       0.53      0.56      0.49      5752\n",
      "weighted avg       0.75      0.56      0.62      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 0 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4858117282708394 \n",
      "test accuracy: 0.5598 \n",
      "train accuracy: 0.5604 \n",
      "ROAUC: 0.5725268375153958 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.56      0.68      4807\n",
      "           1       0.20      0.55      0.29       945\n",
      "\n",
      "    accuracy                           0.56      5752\n",
      "   macro avg       0.53      0.56      0.49      5752\n",
      "weighted avg       0.75      0.56      0.62      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 0 seconds\n",
      "average test accuracy: 0.5598052851182197\n",
      "Threshold: 0.008499999999999999\n",
      "number of features with scores above the threshold: 5\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5637153069456062 \n",
      "test accuracy: 0.7081 \n",
      "train accuracy: 0.6928 \n",
      "ROAUC: 0.6029280491523054 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.77      0.81      4807\n",
      "           1       0.26      0.40      0.31       945\n",
      "\n",
      "    accuracy                           0.71      5752\n",
      "   macro avg       0.56      0.59      0.56      5752\n",
      "weighted avg       0.77      0.71      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 0 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5637153069456062 \n",
      "test accuracy: 0.7081 \n",
      "train accuracy: 0.6928 \n",
      "ROAUC: 0.6022220681259582 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.77      0.81      4807\n",
      "           1       0.26      0.40      0.31       945\n",
      "\n",
      "    accuracy                           0.71      5752\n",
      "   macro avg       0.56      0.59      0.56      5752\n",
      "weighted avg       0.77      0.71      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 0 seconds\n",
      "average test accuracy: 0.7081015299026425\n",
      "Threshold: 0.007749999999999999\n",
      "number of features with scores above the threshold: 6\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.39996979520829107 \n",
      "test accuracy: 0.4145 \n",
      "train accuracy: 0.4191 \n",
      "ROAUC: 0.6097210527416477 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.34      0.49      4807\n",
      "           1       0.19      0.79      0.31       945\n",
      "\n",
      "    accuracy                           0.41      5752\n",
      "   macro avg       0.54      0.56      0.40      5752\n",
      "weighted avg       0.78      0.41      0.46      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 0 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.40011471146862865 \n",
      "test accuracy: 0.4146 \n",
      "train accuracy: 0.4188 \n",
      "ROAUC: 0.6112085219636707 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.34      0.49      4807\n",
      "           1       0.19      0.79      0.31       945\n",
      "\n",
      "    accuracy                           0.41      5752\n",
      "   macro avg       0.54      0.56      0.40      5752\n",
      "weighted avg       0.78      0.41      0.46      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 0 seconds\n",
      "average test accuracy: 0.4145514603616134\n",
      "Threshold: 0.006999999999999999\n",
      "number of features with scores above the threshold: 12\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5244227357895527 \n",
      "test accuracy: 0.6400 \n",
      "train accuracy: 0.6666 \n",
      "ROAUC: 0.5932497030895201 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.68      0.76      4807\n",
      "           1       0.21      0.45      0.29       945\n",
      "\n",
      "    accuracy                           0.64      5752\n",
      "   macro avg       0.54      0.56      0.52      5752\n",
      "weighted avg       0.76      0.64      0.68      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5267794817831803 \n",
      "test accuracy: 0.6424 \n",
      "train accuracy: 0.6670 \n",
      "ROAUC: 0.5924525851299307 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.68      0.76      4807\n",
      "           1       0.22      0.45      0.29       945\n",
      "\n",
      "    accuracy                           0.64      5752\n",
      "   macro avg       0.54      0.57      0.53      5752\n",
      "weighted avg       0.76      0.64      0.68      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "average test accuracy: 0.6411682892906815\n",
      "Threshold: 0.0062499999999999995\n",
      "number of features with scores above the threshold: 17\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5379507626114768 \n",
      "test accuracy: 0.6500 \n",
      "train accuracy: 0.6699 \n",
      "ROAUC: 0.6044594358095502 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.68      0.77      4807\n",
      "           1       0.23      0.48      0.31       945\n",
      "\n",
      "    accuracy                           0.65      5752\n",
      "   macro avg       0.55      0.58      0.54      5752\n",
      "weighted avg       0.76      0.65      0.69      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5387942510458195 \n",
      "test accuracy: 0.6572 \n",
      "train accuracy: 0.6789 \n",
      "ROAUC: 0.6039192183356943 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.70      0.77      4807\n",
      "           1       0.23      0.46      0.31       945\n",
      "\n",
      "    accuracy                           0.66      5752\n",
      "   macro avg       0.55      0.58      0.54      5752\n",
      "weighted avg       0.76      0.66      0.70      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "average test accuracy: 0.6535987482614742\n",
      "Threshold: 0.0055\n",
      "number of features with scores above the threshold: 28\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.5434160960718639 \n",
      "test accuracy: 0.7187 \n",
      "train accuracy: 0.8273 \n",
      "ROAUC: 0.5885058496042479 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83      4807\n",
      "           1       0.23      0.30      0.26       945\n",
      "\n",
      "    accuracy                           0.72      5752\n",
      "   macro avg       0.54      0.55      0.54      5752\n",
      "weighted avg       0.75      0.72      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 1 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.5439804766700445 \n",
      "test accuracy: 0.7191 \n",
      "train accuracy: 0.8278 \n",
      "ROAUC: 0.5894852414303215 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83      4807\n",
      "           1       0.23      0.30      0.26       945\n",
      "\n",
      "    accuracy                           0.72      5752\n",
      "   macro avg       0.54      0.55      0.54      5752\n",
      "weighted avg       0.75      0.72      0.73      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 1 seconds\n",
      "average test accuracy: 0.7188803894297635\n",
      "Threshold: 0.00475\n",
      "number of features with scores above the threshold: 49\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.49837425334085556 \n",
      "test accuracy: 0.8310 \n",
      "train accuracy: 0.9925 \n",
      "ROAUC: 0.6031316763582208 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91      4807\n",
      "           1       0.39      0.05      0.09       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.62      0.52      0.50      5752\n",
      "weighted avg       0.77      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4938458160240281 \n",
      "test accuracy: 0.8305 \n",
      "train accuracy: 0.9924 \n",
      "ROAUC: 0.6081261564099093 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91      4807\n",
      "           1       0.37      0.05      0.08       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.61      0.52      0.49      5752\n",
      "weighted avg       0.76      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8307545201668984\n",
      "Threshold: 0.004\n",
      "number of features with scores above the threshold: 73\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.4811044016627165 \n",
      "test accuracy: 0.8336 \n",
      "train accuracy: 0.9986 \n",
      "ROAUC: 0.6540301126113482 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.41      0.03      0.05       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.62      0.51      0.48      5752\n",
      "weighted avg       0.77      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4791651543747581 \n",
      "test accuracy: 0.8334 \n",
      "train accuracy: 0.9987 \n",
      "ROAUC: 0.6410752397022418 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4807\n",
      "           1       0.40      0.03      0.05       945\n",
      "\n",
      "    accuracy                           0.83      5752\n",
      "   macro avg       0.62      0.51      0.48      5752\n",
      "weighted avg       0.77      0.83      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8335361613351877\n",
      "Threshold: 0.0032500000000000003\n",
      "number of features with scores above the threshold: 100\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47145622263634096 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 0.9999 \n",
      "ROAUC: 0.6513878019598843 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.94      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.89      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4724538500360015 \n",
      "test accuracy: 0.8381 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6586063313752101 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.89      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.86      0.51      0.47      5752\n",
      "weighted avg       0.85      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8381432545201669\n",
      "Threshold: 0.0025000000000000005\n",
      "number of features with scores above the threshold: 134\n",
      "Forest 1/2 trained with \n",
      "F1 score: 0.47302846832323264 \n",
      "test accuracy: 0.8371 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6781684118068558 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.65      0.02      0.04       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.75      0.51      0.47      5752\n",
      "weighted avg       0.81      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 1/2: 0 minutes and 2 seconds\n",
      "Forest 2/2 trained with \n",
      "F1 score: 0.4722473375464208 \n",
      "test accuracy: 0.8376 \n",
      "train accuracy: 1.0000 \n",
      "ROAUC: 0.6786999338486752 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4807\n",
      "           1       0.76      0.02      0.03       945\n",
      "\n",
      "    accuracy                           0.84      5752\n",
      "   macro avg       0.80      0.51      0.47      5752\n",
      "weighted avg       0.83      0.84      0.77      5752\n",
      "\n",
      "\n",
      "Elapsed time to compute Random Forest 2/2: 0 minutes and 2 seconds\n",
      "average test accuracy: 0.8373609179415855\n",
      "Threshold: 0.0017500000000000005\n",
      "number of features with scores above the threshold: 178\n"
     ]
    }
   ],
   "source": [
    "low_min = th_max - min_th_mic\n",
    "high_min = max_th_mic - th_max\n",
    "if low_min < high_min:\n",
    "    low_end = min_th_mic\n",
    "    high_end = th_max + (low_min * 2)\n",
    "    if low_min == 0:\n",
    "        low_end = th_max\n",
    "        high_end = th_max * 4\n",
    "else:\n",
    "    low_end = th_max - (high_min * 2)\n",
    "    high_end = max_th_mic\n",
    "    if high_min == 0:\n",
    "        low_end = th_max / 4\n",
    "        high_end = th_max\n",
    "\n",
    "th = high_end\n",
    "reduction = (high_end - low_end) / 10\n",
    "\n",
    "accuracy_scores_limited = []\n",
    "prev_num_feat = 0\n",
    "while th > 0:\n",
    "    print(f\"Threshold: {th}\")\n",
    "    num_features = len([sc for sc in scores if sc > th])\n",
    "    print(f\"number of features with scores above the threshold: {num_features}\")\n",
    "    if prev_num_feat != num_features:\n",
    "        prev_num_feat = num_features\n",
    "    else:\n",
    "        th -= reduction\n",
    "        continue\n",
    "    if th < low_end:\n",
    "        break\n",
    "    X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test, mutual_info_classif, num_features)\n",
    "    models, test_accuracies = train_random_forests(X_train_fs, y_train, X_test_fs, y_test, 2)\n",
    "    accuracy_scores_limited.append((th,np.mean(test_accuracies),num_features))\n",
    "    print(f\"average test accuracy: {np.mean(test_accuracies)}\")\n",
    "    th -= reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_th_mic_limited = [i[0] for i in accuracy_scores_limited]\n",
    "list_ac_mic_limited = [i[1] for i in accuracy_scores_limited]\n",
    "list_num_feat_mic_limited = [i[2] for i in accuracy_scores_limited]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the min of accuracy or number of features\n",
    "min_ac_mic_limited = min(list_ac_mic_limited)\n",
    "min_num_feat_mic_limited = min(list_num_feat_mic_limited)\n",
    "min_pt_limited = min(min_ac_mic_limited, min_num_feat_mic_limited)\n",
    "# the max of accuracy or number of features\n",
    "max_ac_mic_limited = max(list_ac_mic_limited)\n",
    "max_num_feat_mic_limited = max(list_num_feat_mic_limited)\n",
    "max_pt_limited = max(max_ac_mic_limited, max_num_feat_mic_limited)\n",
    "\n",
    "# min and max of the thresholds RECORDER not corrosponding to the min and max of the accuracy\n",
    "min_th_mic_limited = min(list_th_mic_limited)\n",
    "max_th_mic_limited = max(list_th_mic_limited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_th = round(list_th_mic_limited[list_ac_mic_limited.index(max_ac_mic_limited)], 5)\n",
    "best_nf = round(list_num_feat_mic_limited[list_ac_mic_limited.index(max_ac_mic_limited)], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the accuracy (left y axis) vs threshold\n",
    "# plot the number of features (right y axis) vs threshold\n",
    "# red dot for the highest accuracy with the corresponding threshold rounded to 5 decimal places\n",
    "fig, ax1 = plt.subplots(figsize=(10,10))\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Threshold')\n",
    "ax1.set_ylabel('Accuracy', color=color)\n",
    "ax1.plot(list_th_mic_limited, list_ac_mic_limited, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "# ax1.yaxis.set_ticks(np.arange(min_pt_limited, max_pt_limited + (max_pt_limited * 0.01), max_pt_limited * 0.0001))\n",
    "ax1.plot(round(list_th_mic_limited[list_ac_mic_limited.index(max_ac_mic_limited)], 5), max_ac_mic_limited, 'ro')\n",
    "ax1.annotate(f\"(Threshold: {best_th}\\n, Accuracy: {round(max_ac_mic_limited, 5)})\", (round(list_th_mic_limited[list_ac_mic_limited.index(max_ac_mic_limited)], 5), max_ac_mic_limited))\n",
    "# black dotted line at annotated point vertically\n",
    "plt.axvline(x=best_th, color='black', linestyle='dotted')\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Number of Features', color=color)\n",
    "ax2.plot(list_th_mic_limited, list_num_feat_mic_limited, color=color, linestyle='dashed')\n",
    "# black dotted line at best_nf\n",
    "plt.axhline(y=best_nf, color='black', linestyle='dotted')\n",
    "ax2.annotate(f\"{best_nf}\", (max_th_mic_limited, best_nf +1))\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "# ax2.yaxis.set_ticks(np.arange(min_num_feat_mic_limited, max_num_feat_mic_limited + (max_num_feat_mic_limited * 0.01), max_num_feat_mic_limited * 0.1))\n",
    "plt.title('Threshold vs Accuracy and Number of Features')\n",
    "plt.savefig('outputs/00_feature_select_29/mutual_info_threshold_vs_accuracy_limited.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 100, Threshold: 0.00325\n",
      "Feature 1: 0.003837009843452366, Q4- (7 to 12 years old) In each of the following age groups, how many children live totally or partially with you?\n",
      "Feature 2: 0.0043994445096573465, Q4- (13 to 17 years old) In each of the following age groups, how many children live totally or partially with you?\n",
      "Feature 11: 0.003986409376343536, ('Q2- How old are you?_50 - 55',)\n",
      "Feature 12: 0.003835592647738695, ('Q2- How old are you?_56 - 70',)\n",
      "Feature 19: 0.003275705492899794, ('In which sector of activity do you work?_Construction',)\n",
      "Feature 21: 0.003714204258366216, ('In which sector of activity do you work?_Human health and social action',)\n",
      "Feature 30: 0.0039447405692742965, ('What is the size of your business (in total, all locations combined)? 2009 fake_250 to 999 employees',)\n",
      "Feature 34: 0.005474274949970326, ('Q5- Apart from your children, do you have a dependent or sick family member(s) whom you take care of regularly?_No',)\n",
      "Feature 42: 0.005487813780114648, (\"Would you say that over the last 12 months, your company's activity has:_nan\",)\n",
      "Feature 43: 0.0038341335819733757, ('Q9- Are you working?_Full time',)\n",
      "Feature 46: 0.004314344574737783, ('Q10- Do you have shift work (work organized in successive teams, which take turns at the same workstations) with alternating hours?_No',)\n",
      "Feature 50: 0.0035270402807836554, ('Q12- Do you work most often?_At home teleworking',)\n",
      "Feature 57: 0.004833149171390438, ('Q12- Do you work most often?_In an open space, a tray',)\n",
      "Feature 75: 0.004614717851790573, ('Q13- Is the performance of your work taxing on you?-To work on screen_Most of the time',)\n",
      "Feature 77: 0.0064091919832760524, ('Q13- Is the performance of your work taxing on you?-To work on screen_Occasionally',)\n",
      "Feature 81: 0.00439360418763779, ('Q13- Is the performance of your work taxing on you?-Working in the cold / in the heat_Never',)\n",
      "Feature 90: 0.005411550230164597, ('Q14- During your work, are you in a situation? (Of-breathe toxic products or dust_No',)\n",
      "Feature 91: 0.004851432917536869, ('Q14- During your work, are you in a situation? (Of-breathe toxic products or dust_Yes',)\n",
      "Feature 96: 0.003688191304248134, ('Q14- During your work, are you in a situation? (Of-risk a serious fall_No',)\n",
      "Feature 104: 0.0076906568214896165, ('Q15- Indicate whether each of the following sentences suits you-My work allows me to learn new things_Rather',)\n",
      "Feature 111: 0.003741347873493117, ('Q15- Indicate whether each of the following sentences suits you-My job requires working very quickly or very intensely_nan',)\n",
      "Feature 112: 0.0036921942755754333, ('Q15- Indicate whether each of the following sentences suits you-My job requires long periods of concentration_Completetly',)\n",
      "Feature 137: 0.005837270225999003, ('Q15- Indicate whether each of the following sentences suits you-At times, I have difficulty managing priorities_Completetly',)\n",
      "Feature 139: 0.005228381658532788, ('Q15- Indicate whether each of the following sentences suits you-At times, I have difficulty managing priorities_Rather',)\n",
      "Feature 140: 0.0035841699028675844, ('Q15- Indicate whether each of the following sentences suits you-At times, I have difficulty managing priorities_Rather not',)\n",
      "Feature 143: 0.004466351862421503, ('Q15- Indicate whether each of the following sentences suits you-I feel recognized by my hierarchy_Not at all',)\n",
      "Feature 149: 0.003815188073731157, ('Q15- Indicate whether each of the following sentences suits you-I have the opportunity to develop my professional skills_Rather',)\n",
      "Feature 154: 0.007152764729528416, ('Q15- Indicate whether each of the following sentences suits you-There is good understanding where I work_Rather',)\n",
      "Feature 159: 0.005817168865014377, ('Q15- Indicate whether each of the following sentences suits you-I have a well-suited workstation_Rather',)\n",
      "Feature 162: 0.003503058092069633, ('Q15- Indicate whether each of the following sentences suits you-I systematically seek to improve the way I work_Completetly',)\n",
      "Feature 165: 0.003697801760991881, ('Q15- Indicate whether each of the following sentences suits you-I systematically seek to improve the way I work_Rather not',)\n",
      "Feature 170: 0.005518501743266846, ('Q15- Indicate whether each of the following sentences suits you-My company takes care of the well-being of its employees_Rather not',)\n",
      "Feature 173: 0.00547065664808577, ('Q15- Indicate whether each of the following sentences suits you-Security is a priority for my business_Not at all',)\n",
      "Feature 181: 0.006069559319205942, ('Q15- Indicate whether each of the following sentences suits you-In the event of a problem, I can count on my supervisor_nan',)\n",
      "Feature 183: 0.003358227173217765, ('Would you say that over the last 12 months, your pace of work has:_Do not know',)\n",
      "Feature 187: 0.00424740212002761, ('Q16- And for each of these sentences?-I would recommend my company to a friend_Completetly',)\n",
      "Feature 191: 0.004118945688096787, ('Q16- And for each of these sentences?-I would recommend my company to a friend_nan',)\n",
      "Feature 199: 0.0050493053665401355, ('Q17- At work, does it happen to you: (D-have decreased alertness, lack of attention_Sometimes',)\n",
      "Feature 200: 0.003510552519478516, ('Q17- At work, does it happen to you: (D-have decreased alertness, lack of attention_Very Often',)\n",
      "Feature 209: 0.006870745809717915, ('Q17- At work, does it happen to you: (D-being insulted or attacked by the public or customers_Sometimes',)\n",
      "Feature 212: 0.0032980486064477788, (\"Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-'work organization_Satisfying\",)\n",
      "Feature 214: 0.007306273272225106, (\"Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-'work organization_nan\",)\n",
      "Feature 215: 0.004673344134486834, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-clarity of your role in the companyÔøΩs activity_Satisfying',)\n",
      "Feature 217: 0.005427792790277497, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-clarity of your role in the companyÔøΩs activity_nan',)\n",
      "Feature 218: 0.0041757967994495715, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-access to professional training_Satisfying',)\n",
      "Feature 221: 0.004274133054106954, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a relationship with your direct superior_Satisfying',)\n",
      "Feature 222: 0.0034874807059801505, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a relationship with your direct superior_Unsatisfactory',)\n",
      "Feature 223: 0.006817186557271926, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a relationship with your direct superior_nan',)\n",
      "Feature 224: 0.005023294586823379, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-atmosphere in your team_Satisfying',)\n",
      "Feature 227: 0.0036649426929022955, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-tools or your workstation_Satisfying',)\n",
      "Feature 231: 0.008958012665431836, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-the prospects for development_Unsatisfactory',)\n",
      "Feature 232: 0.009040630392181725, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-the prospects for development_nan',)\n",
      "Feature 233: 0.008095639800604237, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-relationships between services_Satisfying',)\n",
      "Feature 235: 0.004890523871618591, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-relationships between services_nan',)\n",
      "Feature 239: 0.0034704687158642056, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a communication and understanding of business strategy_Satisfying',)\n",
      "Feature 240: 0.003969273603316115, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a communication and understanding of business strategy_Unsatisfactory',)\n",
      "Feature 241: 0.003394584584003324, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a communication and understanding of business strategy_nan',)\n",
      "Feature 242: 0.006604080098967735, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-recognition at work_Satisfying',)\n",
      "Feature 244: 0.0034078130570092124, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-recognition at work_nan',)\n",
      "Feature 245: 0.0054656998551980696, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-has mastery of your position (responsibility, means, skills_Satisfying',)\n",
      "Feature 248: 0.005206814816831162, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-moments of conviviality_Satisfying',)\n",
      "Feature 250: 0.004405320957685088, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-moments of conviviality_nan',)\n",
      "Feature 251: 0.004811970022732481, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a balance between private life and professional life_Satisfying',)\n",
      "Feature 254: 0.004157755439276434, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-The services provided by the company (crÔøΩche, concierge, gym, etc.)_Satisfying',)\n",
      "Feature 256: 0.00631295436334689, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-The services provided by the company (crÔøΩche, concierge, gym, etc.)_nan',)\n",
      "Feature 259: 0.004477571969840444, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-a social protection (mutual health, insurance) offered by your company_nan',)\n",
      "Feature 260: 0.005532671367449282, ('Q19- For each of the following points indicate whether, in your work, you find it satisfactory or unsatisfactory: (L-working hours_Satisfying',)\n",
      "Feature 263: 0.003379547475527822, ('Q22- Over the last 12 months have you personally experienced one or more of the following events:-Loss of job (yourself or your spouse)_I adhere to the directions chosen by my company',)\n",
      "Feature 270: 0.003999382578435462, ('Q22- Over the last 12 months have you personally experienced one or more of the following events:-An imposed change of position or profession_I adhere to the directions chosen by my company',)\n",
      "Feature 281: 0.004816743159405057, ('Q22- Over the last 12 months have you personally experienced one or more of the following events:-A social plan, layoffs in your company_nan',)\n",
      "Feature 284: 0.004122406573936921, ('Q23- Do you have difficulty reconciling your work with your other personal or family commitments?-Yes quite_No, rather not',)\n",
      "Feature 291: 0.003659047559301687, ('Q25-Your workplace-home transportation time (round trip) is:_More than 3 hours per day',)\n",
      "Feature 294: 0.004176280534093246, ('Q31- When you think about the next 3 years, for each of the following points are you:-Your professional situation_Not confident at all',)\n",
      "Feature 298: 0.003635309326740499, ('Q31- When you think about the next 3 years, for each of the following points are you:-The financial situation of your household_Confident',)\n",
      "Feature 300: 0.004962531766782297, ('Q31- When you think about the next 3 years, for each of the following points are you:-The financial situation of your household_Not very confident',)\n",
      "Feature 302: 0.003783010766984285, ('Q31- When you think about the next 3 years, for each of the following points are you:-The financial situation of your household_nan',)\n",
      "Feature 303: 0.0041403074671124696, ('Q31- When you think about the next 3 years, for each of the following points are you:-Your housing conditions_Confident',)\n",
      "Feature 305: 0.0059419313096014115, ('Q31- When you think about the next 3 years, for each of the following points are you:-Your housing conditions_Not very confident',)\n",
      "Feature 310: 0.004314697251895927, ('Q31- When you think about the next 3 years, for each of the following points are you:-Your emotional life_Not very confident',)\n",
      "Feature 317: 0.012077292831049746, ('Q31- When you think about the next 3 years, for each of the following points are you:-Your health_nan',)\n",
      "Feature 322: 0.005913569331370994, ('Q31- When you think about the next 3 years, for each of the following points are you:-The future of your child(ren)_nan',)\n",
      "Feature 325: 0.005307040488927717, ('Q34- In your personal life, would you say:-I feel well surrounded_Rather',)\n",
      "Feature 330: 0.003291237436690686, ('Q34- In your personal life, would you say:-One of my loved ones (child/parent/spouse) is causing me a lot of worry_Rather',)\n",
      "Feature 337: 0.004517192105083279, ('Q34- In your personal life, would you say:-I have personal concerns (emotional life, money, health_nan',)\n",
      "Feature 342: 0.004599674462088199, ('Q34- In your personal life, would you say:-If there is a problem I can talk to a loved one_nan',)\n",
      "Feature 349: 0.005476682705000124, ('Q38- Did you:-A chronic illness (a long-term illness or one that recurs frequently_No',)\n",
      "Feature 355: 0.007476279007448516, ('Q42-During the last 12 months have you had a work accident?_No',)\n",
      "Feature 358: 0.005117143042011829, ('Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the head_Never',)\n",
      "Feature 363: 0.0033170767150139113, ('Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the neck, shoulder, arm_Never',)\n",
      "Feature 364: 0.004222767575348785, ('Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the neck, shoulder, arm_Often',)\n",
      "Feature 375: 0.003267287511244943, ('Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the leg, foot, knee_Permanently',)\n",
      "Feature 376: 0.007266433036261288, ('Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in the leg, foot, knee_Sometimes',)\n",
      "Feature 378: 0.005856950693582386, ('Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in other parts of the body_Never',)\n",
      "Feature 381: 0.0036400434316994357, ('Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-in other parts of the body_Sometimes',)\n",
      "Feature 385: 0.004069442170203219, ('Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-to the eyes_Permanently',)\n",
      "Feature 386: 0.003418446800458552, ('Q44- Over the last 12 months have you experienced the following difficulties (excluding traumatic accident)? (Wrong-to the eyes_Sometimes',)\n",
      "Feature 391: 0.003348498482282025, ('Q57- How do you most frequently eat your midday meal?_When returning home',)\n",
      "Feature 397: 0.004988887067993719, ('Q58- For each of these drinks, indicate whether you consume them:-Every day_None',)\n",
      "Feature 403: 0.003995158124863396, ('Q58- For each of these drinks, indicate whether you consume them:-At least once a week_nan',)\n",
      "Feature 409: 0.005589826340909543, ('Q61- Do you smoke cannabis, hashish, marijuana?_Never',)\n",
      "Feature 412: 0.003437219267125924, ('Q61- Do you smoke cannabis, hashish, marijuana?_nan',)\n",
      "Feature 422: 0.005486294699812655, ('Q63- Over the past 12 months have you experienced the following difficulties?-Sleep disorders (difficulty falling asleep, waking up at night, waking up early without being able to go back to sleep, etc.)_sometimes',)\n",
      "Feature 424: 0.00415144023806735, ('Q63- Over the past 12 months have you experienced the following difficulties?-A lack of tone_Never',)\n"
     ]
    }
   ],
   "source": [
    "# print the features with scores above best threshold\n",
    "print(f\"Number of features: {best_nf}, Threshold: {best_th}\")\n",
    "for i in range(len(fs.scores_)):\n",
    "    if fs.scores_[i] > best_th:\n",
    "        print(f\"Feature {i}: {fs.scores_[i]}, {fs.feature_names_in_[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".sick",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
